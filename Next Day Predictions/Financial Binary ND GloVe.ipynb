{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial Index Prediction\n",
    "This notebook seeks to predict the direction of a financial index from day k to day k+1 given financial news headlines from day k. A range of different combinations between statistical and NLP-models are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.utils import parallel_backend\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, LSTM, Embedding, Lambda, LSTM, Bidirectional\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load financial news data and financial index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONEDRIVE_PATH = Path(r\"C:\\Users\\gusta\\Kidbrooke Advisory Ab\\KidbrookeOneDrive - Gustaf Backman exjobb\")\n",
    "\n",
    "# Read the financial data \n",
    "fin_path = ONEDRIVE_PATH / \"Input Data/stock_data.pkl\"\n",
    "fin_data = pd.read_pickle(fin_path)\n",
    "fin_data = fin_data.loc['2006-10-20' : '2013-11-20']\n",
    "\n",
    "news_path = ONEDRIVE_PATH / \"Input Data/financial_headlines_20061020-20131119.pkl\"\n",
    "news_data = pd.DataFrame(pd.read_pickle(news_path))\n",
    "news_data.set_index('date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1846/1846 [00:08<00:00, 223.66it/s]\n"
     ]
    }
   ],
   "source": [
    "news_dates = news_data.index.drop_duplicates()\n",
    "fin_dates = fin_data.index.drop_duplicates()\n",
    "\n",
    "# Find the dates which are present in both the financial data and news data\n",
    "valid_dates = []\n",
    "for date in news_dates: \n",
    "    if date in fin_data.index: \n",
    "        valid_dates.append(date)\n",
    "valid_dates.append(fin_data.index[-1]) # Add the last index in fin_data and remove after creating targets\n",
    "# Create targets for all 3 time series \n",
    "targets = pd.DataFrame(dtype='int8')\n",
    "prev_vals = fin_data.iloc[0]\n",
    "for date in tqdm(valid_dates[1:]): # The first date is fin_data.iloc[0] \n",
    "    y_temp = []\n",
    "    # If the value has increased since yesterday, y = 1\n",
    "    if prev_vals['1 YEAR'] < fin_data.loc[date]['1 YEAR']: \n",
    "        y_temp.append(1)\n",
    "    else:\n",
    "        y_temp.append(0)\n",
    "        \n",
    "    if prev_vals['3 YEAR'] < fin_data.loc[date]['3 YEAR']: \n",
    "        y_temp.append(1)\n",
    "    else:\n",
    "        y_temp.append(0)\n",
    "        \n",
    "    if prev_vals['S&P'] < fin_data.loc[date]['S&P']: \n",
    "        y_temp.append(1)\n",
    "    else:\n",
    "        y_temp.append(0)\n",
    "    targets = targets.append({'1 YEAR':y_temp[0], '3 YEAR':y_temp[1], 'S&P':y_temp[2]}, ignore_index=True)\n",
    "    prev_vals = fin_data.loc[date]\n",
    "valid_dates.remove(fin_data.index[-1]) # Remove since this date is not present in news data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_word(word): \n",
    "    \"\"\" A method for formatting words to be more similar to those in the \n",
    "    pre-trained glove embeddings. For example, won't -> will not, removing 's etc. \n",
    "    \"\"\"\n",
    "    if word == \"n't\":\n",
    "        return \"not\"\n",
    "    if word == \"'s\": \n",
    "        return \"\"\n",
    "    if word == \"wo\":\n",
    "        return \"will\"\n",
    "    if len(word) > 1 and word[0] == \"'\":\n",
    "        return word[1:]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of texts: 1846\n",
      "Length of targets: 1846\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the news for each day in the valid indices, i.e. the indices that are present in both \n",
    "# the financial data and the news data \n",
    "texts = []\n",
    "for date in valid_dates: \n",
    "    temp_texts = \"\"\n",
    "    for i,text in enumerate(news_data.loc[date]['title']): \n",
    "        words = word_tokenize(text.lower())\n",
    "        for j,word in enumerate(words): \n",
    "            if j < len(words) - 1:\n",
    "                temp_texts += format_word(word) + \" \"\n",
    "            else:\n",
    "                temp_texts += format_word(word) + \". \"\n",
    "    texts.append(temp_texts)\n",
    "texts = np.asarray(texts)\n",
    "print(\"Length of texts:\",len(texts))\n",
    "print(\"Length of targets:\",len(targets))\n",
    "n = len(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize the news titles using GloVe\n",
    "The headlines are tokenized, and a vector of length 300 is constructed by the elementwise average of the GloVe-embeddings for one review. This is used as input to the models where the embeddings are not jointly trained with the model. For the bidirectional LSTM however, the news titles are tokenized and fed into an embedding layer where the initial embeddings are given by the pre-trained GloVe embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 22107 words loaded, 308 not found.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 300)) # Need one extra row since '0' is not an index\n",
    "glove_path = ONEDRIVE_PATH / \"Embeddings\\GloVe\\glove.42B.300d\\glove.42B.300d.txt\"\n",
    "found_words = []\n",
    "f = open(glove_path,'r', encoding='UTF-8')\n",
    "for line in f:\n",
    "    splitLine = line.split()\n",
    "    word = splitLine[0]\n",
    "    if word in tokenizer.word_index.keys():\n",
    "        found_words.append(word)\n",
    "        embedding_matrix[tokenizer.word_index[word]] = np.array([float(val) for val in splitLine[1:]])\n",
    "print(\"Done.\",len(found_words),\"words loaded,\",len(tokenizer.word_index) - len(found_words),\"not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1846it [00:28, 63.95it/s]\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((len(texts), 300))\n",
    "title_lengths = np.zeros(len(texts))  # Record the length of every concatenated title to determine suitable maxlength for sequential data. \n",
    "for i,title in tqdm(enumerate(texts)):\n",
    "    tokenized_title = tokenizer.texts_to_sequences(word_tokenize(title))\n",
    "    temp_array = np.zeros((300))\n",
    "    n_words = 0\n",
    "    title_lengths[i] = len(tokenized_title)\n",
    "    for word in tokenized_title:     \n",
    "        if len(word) == 1:\n",
    "            temp_array += embedding_matrix[word[0]]\n",
    "            n_words += 1\n",
    "    x[i] = temp_array / n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize sequences using GloVe\n",
    "We'll also try a recurrent approach with sequences as input. Instead of taking the average of the GloVe-embedding in one review, a sequence of word indices is fed into an embedding layer where the embeddings are initialized as pretrained GloVe-embeddings. However, using all of the words in the vocabulary gives a too slow model so we have to re-tokenize with a restricted vocabulary size. We'll also restrict the maximum word length from one review to cover the majority of the training samples without being too inefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(title_lengths,50)\n",
    "plt.xlabel('Number of words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maximum sentence length of 800 seems reasonable to cover the majority. Furthermore, we restrict the size of the vocabulary to make the task computationally feasible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data \n",
    "maxlen = 800\n",
    "# Restrict size of the vocabulary\n",
    "vocab_size = 20000\n",
    "restricted_tokenizer = Tokenizer(num_words=vocab_size,lower=True)\n",
    "restricted_tokenizer.fit_on_texts(texts)\n",
    "x_restr = restricted_tokenizer.texts_to_sequences(texts)\n",
    "# Pad the data with zeroes so all samples are of equal length\n",
    "x_padded = pad_sequences(x_restr,maxlen=maxlen)\n",
    "\n",
    "# Create a new embedding matrix for the restricted vocabulary ('embedding_matrix' includes the full vocabulary)\n",
    "trainable_embeddings = np.zeros((vocab_size + 1, 300))    \n",
    "for i,word in enumerate(list(restricted_tokenizer.word_index.keys())[:vocab_size]):\n",
    "    trainable_embeddings[i] = embedding_matrix[tokenizer.word_index[word]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition into training and test set\n",
    "The data is somewhat imbalanced to a various degree for the different time series. The partition is made so that the distribution of labels is respected in both the training and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----- 1 YEAR RATE -----\n",
      "Ratio neg labels 1 year rate: 0.6885157096424702\n",
      "Neg labels: 1271 Pos labels: 575\n",
      " ----- 3 YEAR RATE -----\n",
      "Ratio neg labels 3 year rate: 0.594257854821235\n",
      "Neg labels: 1097 Pos labels: 749\n",
      " -----     S&P     -----\n",
      "Ratio neg labels S&P: 0.4647887323943662\n",
      "Neg labels: 858 Pos labels: 988\n"
     ]
    }
   ],
   "source": [
    "zero_indices_1yr = np.where(targets['1 YEAR'] == 0)[0]\n",
    "one_indices_1yr = np.where(targets['1 YEAR'] == 1)[0]\n",
    "\n",
    "zero_indices_3yr = np.where(targets['3 YEAR'] == 0)[0]\n",
    "one_indices_3yr = np.where(targets['3 YEAR'] == 1)[0]\n",
    "\n",
    "zero_indices_sp = np.where(targets['S&P'] == 0)[0]\n",
    "one_indices_sp = np.where(targets['S&P'] == 1)[0]\n",
    "\n",
    "print(\" ----- 1 YEAR RATE -----\")\n",
    "print(\"Ratio neg labels 1 year rate:\",len(zero_indices_1yr) / len(targets))\n",
    "print(\"Neg labels:\", len(zero_indices_1yr), \"Pos labels:\",len(one_indices_1yr))\n",
    "print(\" ----- 3 YEAR RATE -----\")\n",
    "print(\"Ratio neg labels 3 year rate:\",len(zero_indices_3yr) / len(targets))\n",
    "print(\"Neg labels:\", len(zero_indices_3yr), \"Pos labels:\",len(one_indices_3yr))\n",
    "print(\" -----     S&P     -----\")\n",
    "print(\"Ratio neg labels S&P:\",len(zero_indices_sp) / len(targets))\n",
    "print(\"Neg labels:\", len(zero_indices_sp), \"Pos labels:\",len(one_indices_sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----- 1 YEAR RATE -----\n",
      "Train data shape (x,y): (1200, 300) , (1200,)\n",
      "Train data label ratio (0 / 1): 826 / 374\n",
      "Test data shape (x,y): (646, 300) , (646,)\n",
      "Test data label ratio (0 / 1): 445 / 201\n",
      " ----- 3 YEAR RATE -----\n",
      "Train data shape (x,y): (1200, 300) , (1200,)\n",
      "Train data label ratio (0 / 1): 713 / 487\n",
      "Test data shape (x,y): (646, 300) , (646,)\n",
      "Test data label ratio (0 / 1): 384 / 262\n",
      " -----     S&P     -----\n",
      "Train data shape (x,y): (1200, 300) , (1200,)\n",
      "Train data label ratio (0 / 1): 558 / 642\n",
      "Test data shape (x,y): (646, 300) , (646,)\n",
      "Test data label ratio (0 / 1): 300 / 346\n"
     ]
    }
   ],
   "source": [
    "n_train = 1200\n",
    "\n",
    "\n",
    "np.random.shuffle(zero_indices_1yr)\n",
    "np.random.shuffle(one_indices_1yr)\n",
    "part_zeros_1yr = len(zero_indices_1yr) / n\n",
    "train_indices_1yr = np.zeros((n_train),dtype=int)\n",
    "train_indices_1yr[:round(part_zeros_1yr * n_train)] = zero_indices_1yr[:round(part_zeros_1yr * n_train)]\n",
    "train_indices_1yr[round(part_zeros_1yr * n_train):] = one_indices_1yr[:round((1 - part_zeros_1yr) * n_train)]\n",
    "np.random.shuffle(train_indices_1yr)\n",
    "# All indices not in train is in test. \n",
    "test_indices_1yr = np.setdiff1d(np.arange(len(targets)), train_indices_1yr)\n",
    "np.random.shuffle(test_indices_1yr)\n",
    "\n",
    "np.random.shuffle(zero_indices_3yr)\n",
    "np.random.shuffle(one_indices_3yr)\n",
    "part_zeros_3yr = len(zero_indices_3yr) / n\n",
    "train_indices_3yr = np.zeros((n_train),dtype=int)\n",
    "train_indices_3yr[:round(part_zeros_3yr * n_train)] = zero_indices_3yr[:round(part_zeros_3yr * n_train)]\n",
    "train_indices_3yr[round(part_zeros_3yr * n_train):] = one_indices_3yr[:round((1 - part_zeros_3yr) * n_train)]\n",
    "np.random.shuffle(train_indices_3yr)\n",
    "# All indices not in train is in test. \n",
    "test_indices_3yr = np.setdiff1d(np.arange(len(targets)), train_indices_3yr)\n",
    "np.random.shuffle(test_indices_3yr)\n",
    "\n",
    "np.random.shuffle(zero_indices_sp)\n",
    "np.random.shuffle(one_indices_sp)\n",
    "part_zeros_sp = len(zero_indices_sp) / n\n",
    "train_indices_sp = np.zeros((n_train),dtype=int)\n",
    "train_indices_sp[:round(part_zeros_sp * n_train)] = zero_indices_sp[:round(part_zeros_sp * n_train)]\n",
    "train_indices_sp[round(part_zeros_sp * n_train):] = one_indices_sp[:round((1 - part_zeros_sp) * n_train)]\n",
    "np.random.shuffle(train_indices_sp)\n",
    "# All indices not in train is in test. \n",
    "test_indices_sp = np.setdiff1d(np.arange(len(targets)), train_indices_sp)\n",
    "np.random.shuffle(test_indices_sp)\n",
    "\n",
    "\n",
    "x_train_1yr = x[train_indices_1yr]\n",
    "x_train_seq_1yr = x_padded[train_indices_1yr]\n",
    "x_test_1yr = x[test_indices_1yr]\n",
    "x_test_seq_1yr = x_padded[test_indices_1yr]\n",
    "y_train_1yr = targets.iloc[train_indices_1yr]['1 YEAR'].values\n",
    "y_test_1yr = targets.iloc[test_indices_1yr]['1 YEAR'].values\n",
    "\n",
    "\n",
    "x_train_3yr = x[train_indices_3yr]\n",
    "x_train_seq_3yr = x_padded[train_indices_3yr]\n",
    "x_test_3yr = x[test_indices_3yr]\n",
    "x_test_seq_3yr = x_padded[test_indices_3yr]\n",
    "y_train_3yr = targets.iloc[train_indices_3yr]['3 YEAR'].values\n",
    "y_test_3yr = targets.iloc[test_indices_3yr]['3 YEAR'].values\n",
    "\n",
    "\n",
    "x_train_sp = x[train_indices_sp]\n",
    "x_train_seq_sp = x_padded[train_indices_sp]\n",
    "x_test_sp = x[test_indices_sp]\n",
    "x_test_seq_sp = x_padded[test_indices_sp]\n",
    "y_train_sp = targets.iloc[train_indices_sp]['S&P'].values\n",
    "y_test_sp = targets.iloc[test_indices_sp]['S&P'].values\n",
    "\n",
    "# Sanity check of shapes \n",
    "\n",
    "print(\" ----- 1 YEAR RATE -----\")\n",
    "print(\"Train data shape (x,y):\",x_train_1yr.shape,\",\", y_train_1yr.shape)\n",
    "print(\"Train data label ratio (0 / 1):\",np.sum(y_train_1yr == 0),\"/\", np.sum(y_train_1yr == 1))\n",
    "print(\"Test data shape (x,y):\",x_test_1yr.shape,\",\", y_test_1yr.shape)\n",
    "print(\"Test data label ratio (0 / 1):\",np.sum(y_test_1yr == 0),\"/\", np.sum(y_test_1yr == 1))\n",
    "\n",
    "print(\" ----- 3 YEAR RATE -----\")\n",
    "print(\"Train data shape (x,y):\",x_train_3yr.shape,\",\", y_train_3yr.shape)\n",
    "print(\"Train data label ratio (0 / 1):\",np.sum(y_train_3yr == 0),\"/\", np.sum(y_train_3yr == 1))\n",
    "print(\"Test data shape (x,y):\",x_test_3yr.shape,\",\", y_test_3yr.shape)\n",
    "print(\"Test data label ratio (0 / 1):\",np.sum(y_test_3yr == 0),\"/\", np.sum(y_test_3yr == 1))\n",
    "\n",
    "print(\" -----     S&P     -----\")\n",
    "print(\"Train data shape (x,y):\",x_train_sp.shape,\",\", y_train_sp.shape)\n",
    "print(\"Train data label ratio (0 / 1):\",np.sum(y_train_sp == 0),\"/\", np.sum(y_train_sp == 1))\n",
    "print(\"Test data shape (x,y):\",x_test_sp.shape,\",\", y_test_sp.shape)\n",
    "print(\"Test data label ratio (0 / 1):\",np.sum(y_test_sp == 0),\"/\", np.sum(y_test_sp == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models \n",
    "The data has been pre-processed and the models can be evaluated. All of the models are fitted with the three data series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some help functions for plotting the results \n",
    "\n",
    "def plot_results(model,x_test, y_test,save=False, name=''):\n",
    "    y_test_preds = model.predict(x_test)\n",
    "    print(classification_report(y_test, y_test_preds))\n",
    "    print(\"Test accuracy:\",model.score(x_test, y_test))\n",
    "    plot_confusion_matrix(model,x_test,y_test)\n",
    "    if save:\n",
    "        plt.savefig(\"Figs GloVe/\" + name + \"confmat.jpg\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_results_nn(history, model,x_test, y_test,save=False, name=''):\n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history['loss'],label='Loss')\n",
    "    plt.plot(history.history['val_loss'],label='Val loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history['acc'],label='Acc')\n",
    "    plt.plot(history.history['val_acc'],label='Val acc')\n",
    "    plt.legend()\n",
    "    if save: \n",
    "        plt.savefig(\"Figs GloVe/\" + name + \"history.jpg\")\n",
    "    plt.show() \n",
    "    y_test_pred = np.round(model.predict(x_test))\n",
    "    plt.subplot(121)\n",
    "    plt.bar([0,1],[np.sum(y_test == 0), np.sum(y_test == 1)], label='Actual test dist')\n",
    "    plt.legend()\n",
    "    plt.xticks([0, 1])\n",
    "    plt.subplot(122)\n",
    "    plt.bar([0,1],[np.sum(y_test_pred == 0), np.sum(y_test_pred == 1)], label='Pred test dist')\n",
    "    plt.legend()\n",
    "    plt.xticks([0, 1])\n",
    "    plt.show()\n",
    "    conf_mat = confusion_matrix(y_test,y_test_pred,normalize='pred')\n",
    "    ax = sn.heatmap(conf_mat,)\n",
    "    ax.set_ylabel(\"True values\")\n",
    "    ax.set_xlabel(\"Predicted values\")\n",
    "    if save: \n",
    "        plt.savefig(\"Figs GloVe/\" + name + \"confmat.jpg\")\n",
    "    plt.show()\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(\"Test accuracy:\",round(np.sum(y_test == y_test_pred[:,0]) / len(y_test),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Classifier\n",
    "Just for real simple comparison. \n",
    "#### 1 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.72      0.71       445\n",
      "         1.0       0.33      0.31      0.32       201\n",
      "\n",
      "    accuracy                           0.59       646\n",
      "   macro avg       0.52      0.51      0.51       646\n",
      "weighted avg       0.58      0.59      0.59       646\n",
      "\n",
      "Test accuracy: 0.56656346749226\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dummy Classifier\n",
    "dummy_clf_1yr = DummyClassifier().fit(x_train_1yr, y_train_1yr)\n",
    "plot_results(dummy_clf_1yr, x_test_1yr, y_test_1yr,save=True,name='randclf_1yr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.60      0.58       384\n",
      "         1.0       0.36      0.34      0.35       262\n",
      "\n",
      "    accuracy                           0.49       646\n",
      "   macro avg       0.47      0.47      0.47       646\n",
      "weighted avg       0.48      0.49      0.49       646\n",
      "\n",
      "Test accuracy: 0.5154798761609907\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dummy Classifier\n",
    "dummy_clf_3yr = DummyClassifier().fit(x_train_3yr, y_train_3yr)\n",
    "plot_results(dummy_clf_3yr, x_test_3yr, y_test_3yr,save=True,name='randclf_3yr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S&P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.51      0.52       300\n",
      "         1.0       0.59      0.60      0.59       346\n",
      "\n",
      "    accuracy                           0.56       646\n",
      "   macro avg       0.56      0.56      0.56       646\n",
      "weighted avg       0.56      0.56      0.56       646\n",
      "\n",
      "Test accuracy: 0.544891640866873\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dummy Classifier\n",
    "dummy_clf_sp = DummyClassifier().fit(x_train_sp, y_train_sp)\n",
    "plot_results(dummy_clf_sp, x_test_sp, y_test_sp,save=True,name='randclf_sp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with GloVe\n",
    "#### 1 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      1.00      0.82       445\n",
      "         1.0       1.00      0.00      0.01       201\n",
      "\n",
      "    accuracy                           0.69       646\n",
      "   macro avg       0.84      0.50      0.41       646\n",
      "weighted avg       0.79      0.69      0.57       646\n",
      "\n",
      "Test accuracy: 0.6904024767801857\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "logreg_1yr = LogisticRegression(random_state=0).fit(x_train_1yr, y_train_1yr)\n",
    "plot_results(logreg_1yr,x_test_1yr, y_test_1yr,save=True,name='logreg_1yr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.95      0.73       384\n",
      "         1.0       0.39      0.05      0.09       262\n",
      "\n",
      "    accuracy                           0.58       646\n",
      "   macro avg       0.49      0.50      0.41       646\n",
      "weighted avg       0.51      0.58      0.47       646\n",
      "\n",
      "Test accuracy: 0.5835913312693498\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "logreg_3yr = LogisticRegression(random_state=0,max_iter=10000).fit(x_train_3yr, y_train_3yr)\n",
    "plot_results(logreg_3yr,x_test_3yr, y_test_3yr,save=True,name='logreg_3yr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S&P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.25      0.33       300\n",
      "         1.0       0.54      0.78      0.64       346\n",
      "\n",
      "    accuracy                           0.53       646\n",
      "   macro avg       0.52      0.51      0.49       646\n",
      "weighted avg       0.52      0.53      0.50       646\n",
      "\n",
      "Test accuracy: 0.5325077399380805\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "logreg_sp = LogisticRegression(random_state=0).fit(x_train_sp, y_train_sp)\n",
    "plot_results(logreg_sp,x_test_sp, y_test_sp,save=True,name='logreg_sp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine with GloVe\n",
    "#### 1 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      1.00      0.82       445\n",
      "         1.0       0.00      0.00      0.00       201\n",
      "\n",
      "    accuracy                           0.69       646\n",
      "   macro avg       0.34      0.50      0.41       646\n",
      "weighted avg       0.47      0.69      0.56       646\n",
      "\n",
      "Test accuracy: 0.6888544891640866\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_clf_1yr = svm.SVC().fit(x_train_1yr, y_train_1yr)\n",
    "plot_results(svm_clf_1yr, x_test_1yr, y_test_1yr,save=True,name='svm_1yr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      1.00      0.75       384\n",
      "         1.0       0.00      0.00      0.00       262\n",
      "\n",
      "    accuracy                           0.59       646\n",
      "   macro avg       0.30      0.50      0.37       646\n",
      "weighted avg       0.35      0.59      0.44       646\n",
      "\n",
      "Test accuracy: 0.5944272445820433\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_clf_3yr = svm.SVC().fit(x_train_3yr, y_train_3yr)\n",
    "plot_results(svm_clf_3yr, x_test_3yr, y_test_3yr,save=True,name='svm_3yr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S&P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       300\n",
      "         1.0       0.54      1.00      0.70       346\n",
      "\n",
      "    accuracy                           0.54       646\n",
      "   macro avg       0.27      0.50      0.35       646\n",
      "weighted avg       0.29      0.54      0.37       646\n",
      "\n",
      "Test accuracy: 0.5356037151702786\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEGCAYAAAAQZJzmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAdX0lEQVR4nO3deZQV5Z3/8fenm2bfRBAQMKCixjgRDUETsxBXdJKBODGDMYlRR6KDMZlsP5f8fonJmORMtkmCwTGjo8xMNHjUkRiNCzNJMNHghlFUBBcUaUFAFiU0dN/v74+q1kvbS3Vzb3ffW5/XOXX6Vt2qep7Lpb/9rPUoIjAzy7Oans6AmVlPcyA0s9xzIDSz3HMgNLPccyA0s9zr09MZ6Ky+6hf9GdTT2bBOGHlYQ09nwTrpuce3b4iIUV29/qQPDYqNm5oynfvQnxvujIgZXU2rFCouEPZnEEfpuJ7OhnXCWTev7uksWCedcdADe/SlbdzUxNI798t0bu3YlSP3JK1SqLhAaGa9XwAFCj2djcwcCM2s5IJgV2SrGvcGDoRmVhYuEZpZrgVBUwVN33UgNLOyKOBAaGY5FkCTA6GZ5Z1LhGaWawHschuhmeVZEK4am1nOBTRVThx0IDSz0ktmllQOB0IzKwPRhHo6E5k5EJpZySWdJQ6EZpZjyThCB0Izy7mCS4RmlmcuEZpZ7gWiqYJWAnEgNLOycNXYzHItEDujtqezkZkDoZmVXDKg2lVjM8s5d5aYWa5FiKZwidDMcq7gEqGZ5VnSWVI54aVyyq5mVjGaO0uybB2R1F/SUkmPSlou6bL0+AhJd0tamf7cq+iaiyWtkrRC0kkdpeFAaGZl0RTKtGXQABwbEYcDU4AZko4GLgIWR8RkYHG6j6RDgdnAO4AZwM8ktTuWx4HQzEqueWZJlq3DeyVeS3fr0i2AmcB16fHrgFnp65nADRHREBHPAauAae2l4UBoZmVRiJpMGzBS0oNF25yW95JUK2kZsB64OyL+BIyOiHqA9Oc+6enjgBeLLl+THmtT5bRmmlnFSB66kLmctSEiprZ7v4gmYIqk4cAtkg5r5/TW6tvtLhzgQGhmJReIXWWYYhcRmyX9lqTtb52ksRFRL2ksSWkRkhLghKLLxgNr27uvq8ZmVnIR0BQ1mbaOSBqVlgSRNAA4HngKWAScmZ52JnBr+noRMFtSP0mTgMnA0vbScInQzMpApRxQPRa4Lu35rQEWRsRtku4DFko6B3gBOA0gIpZLWgg8ATQCc9OqdZscCM2s5AJKNsUuIv4MHNHK8Y3AcW1cczlwedY0HAjNrCz8YFYzy7VAfjCrmeVbspxn5YSXysmpmVUQL/BuZjkX0DxrpCI4EJpZWbhEaGa5FiGXCM0s35LOEq9iZ2a55jVLzCznks4StxGaWc55ZomZ5ZpnlpiZQaaFmXoLB0IzK7kI2FVwIDSzHEuqxg6EZpZznllinTJ1+lbO+9ZaamuCO64fwcJ5o3s6S7nQ2AB3nDGGpp0immDiSds54sIte3TPlbcM4tH5wwA4/PwtTP7o6wD87ksj2fB4X2rqglF/tZP3fnMjNXV7/BF6rUobPlPWsqukGelK86skXdTK+5L0k/T9P0s6spz56Y1qaoK5336Jr50xiXOnH8yHZm5mv8k7ejpbuVDbF2Zct45Zi+qZ+d/1rFkygPXL+ma69o5PjWbbmt1nTjRsrmHZvGF8ZOHLfOTGl1k2bxgNW5Jfsf3/5jVO/c1aZv2qnsYG8fSNg0v+eXoXdWY5zx5Xtlyk6wtcAZwMHAqcnq5AX+xkkoVVJgNzgPnlyk9vdfAR21n7fF9efqEfjbtq+O2tw3nPSXtWKrFsJKgblKzyWGgUhcbk2NYX+nDXOfuw6NQx3P6J0Wx+JlvF6aV7+7PvMTvoN7xAv2EF9j1mBy8t6Q/AhA/uQEruP+qdDby+rvorY4V03ZKOtt6gnN/GNGBVRDwLIOkGkhXonyg6ZyawICICuF/S8Obl+cqYr15l7zG7eGXtm6WQDfV1HHLk9h7MUb4UmuBXp45l6wt9OOQT2xh1+E5+c+Y+vOeyTQyb2Mgrj/blvsv25uQF6zq81+vr+jBozJtrBA0a3fSWgFfYBatuHcRRl75a8s/SmyS9xp5rDK2vNn9UhnPGAbsFQiUr388B6M/Akme0J6mVP4jR7lLUVko1tTDz1noator/mbsPrz5dx/pH+vHbz49645ymncmXtPKmQTyxYCiQlBrvnrMPtXUweHwjx13xSqtLiEu7H7zvshGMmdrAmKkN5ftQvYAHVL8py2rzmVakj4irgKsAhmpEVYWJDfV1jNp35xv7I8fuYuPLVdyK3kv1GxqMOWoHq+8aSN+hBWbe+tZKyeS/fZ3Jf5t0ftzxqdG87zsbGDK+qAQ4ppH6pf3f2H99XS1jp+16Y/+RecPYsamWY+e9UsZP0nv0lmpvFuVsqcyy2nynV6SvNiuWDWTcpJ2MntBAn7oC02du5v67hvV0tnJhx6YaGrYmv6yNO0T9H/uz9zt2Mnh8I8/dkdQ8ImDTU9n+MI173w7W3juAhi01NGypYe29Axj3vqTj6+kbB/PSvf354A83oN7RP1BWzb3GWbbeoJwlwgeAyelK8y8Bs4FPtDhnEXBB2n54FLAlT+2DAIUmccWl4/j2L56lphbuumEEq5/u3/GFtse2r69lyUUjiaYk4E2asZ0JH/oLww/cxX3fGMGj84dRaIT9T9nOiEM67sDqN7zA4f+wmV99bAwAU+Zupt/wAgB//PoIBu/byK//LnnvbSdsZ8oF1d0pVqoeYUkTgAXAGKAAXBURP5b0DeBcoLmIfUlE3J5eczFwDtAEXBgRd7abRpSxQUrSKcC/ALXANRFxuaTzACLiSkkC5gEzgO3AWRHxYHv3HKoRcZRaXdPZeqmzVqzu6SxYJ51x0AMPRcTUrl6/1yH7xLHXfCzTuTcfM7/dtCSNBcZGxMOShgAPAbOAjwOvRcT3W5x/KHA9SYftvsA9wEER0UQbytqHn0bn21scu7LodQBzy5kHM+sZpar2prXE+vT1NklPknSqtmUmcENENADPSVpFEhTva+uCHLRWmFl362Qb4UhJDxZtc9q6r6SJwBHAn9JDF6STMa6RtFd6rK3RKG2q/lGdZtYjOlEi3JClGi5pMHAT8IWI2CppPvAtkrj7LeAHwNlkHI1SzIHQzEqu1OMIJdWRBMH/ioibASJiXdH7PwduS3c7PRrFVWMzK4tSTbFLO1WvBp6MiB8WHR9bdNpHgcfT14uA2ZL6paNWJgNL20vDJUIzK7kIaCzdg1mPAT4FPCZpWXrsEpLnF0whqfY+D3w2STuWS1pIMp23EZjbXo8xOBCaWZmUsNf4Xlpv97u9lWPN11wOXJ41DQdCMys5zzU2MwPCgdDM8q6SHrrgQGhmJRdRWY/qdyA0szIQTV7O08zyzm2EZpZrlbaKnQOhmZVeVNaSEw6EZlYW7jU2s1wLd5aYmblqbGbmXmMzy7cIB0IzMw+fMTNzG6GZ5VogCu41NrO8q6ACoQOhmZWBO0vMzKioImGbgVDS0PYujIitpc+OmVWLaikRLieJ6cWfpnk/gP3KmC8zq2ABFApVEAgjYkJb75mZtSuACioRZurfljRb0iXp6/GS3lXebJlZpYvItnVE0gRJ/yvpSUnLJX0+PT5C0t2SVqY/9yq65mJJqyStkHRSR2l0GAglzQM+RLLAMsB24MqOs29muRYZt441Al+KiLcDRwNzJR0KXAQsjojJwOJ0n/S92cA7gBnAzyTVtpdAlhLheyPis8AOgIjYBPTNlH0zyykRkW3rSETUR8TD6ettwJPAOGAmcF162nXArPT1TOCGiGiIiOeAVcC09tLIEgh3Saohjd2S9gYKGa4zszzLXiIcKenBom1OW7eUNBE4AvgTMDoi6iEJlsA+6WnjgBeLLluTHmtTlnGEVwA3AaMkXQZ8HLgsw3VmllcBkb3XeENETO3oJEmDSWLRFyJiq9Tm/Vt7o91KeIeBMCIWSHoIOD49dFpEPN7RdWaWd6XrNZZURxIE/ysibk4Pr5M0NiLqJY0F1qfH1wDFo17GA2vbu3/WWdG1wC5gZyeuMbM8K1FniZKi39XAkxHxw6K3FgFnpq/PBG4tOj5bUj9Jk4DJwNL20sjSa3wpcD2wL0lk/YWkizvOvpnlWul6jY8hGbVyrKRl6XYK8F3gBEkrgRPSfSJiObAQeAL4DTA3IpraSyBLG+EngXdFxHYASZcDDwHfyfQRzCx/SjigOiLupe169nFtXHM5cHnWNLIEwtUtzusDPJs1ATPLp6p4MKukH5HE9e3Ackl3pvsnAvd2T/bMrGJVw1xjoLlneDnw66Lj95cvO2ZWLVQNJcKIuLo7M2JmVSR7R0iv0GEboaQDSBodDwX6Nx+PiIPKmC8zq2iquqfPXAv8O0mvzckk3dI3lDFPZlYNSjd8puyyBMKBEXEnQEQ8ExFfI3kajZlZ2woZt14gy/CZhnRk9zOSzgNe4s3JzWZmb1VhD2bNEgj/ERgMXEjSVjgMOLucmTKzylcVvcbNIuJP6cttvPlwVjOz9lVDIJR0C+18lIg4tSw5MjPrZu2VCOd1Wy6sqs0e8mpPZ8E66YwS3KMqqsYRsbg7M2JmVSSomil2ZmZdVw0lQjOzPVFJVePMT5uW1K+cGTGzKlNNM0skTZP0GLAy3T9c0k/LnjMzq2zVFAiBnwAfBjYCRMSjeIqdmbVDkX3rDbK0EdZExOoWS+e1+/x/M7Nq6zV+UdI0ICTVAp8Dni5vtsys0vWW0l4WWQLh+STV4/2AdcA96TEzs7ZVUyCMiPXA7G7Ii5lVi17U/pdFlidU/5xWYntEzClLjsysOpQoEEq6hqTDdn1EHJYe+wZwLvBKetolEXF7+t7FwDkkfRkXNj9PtT1Zqsb3FL3uD3wUeDHjZzCznFLpHrp6LcmzDxa0OP6jiPj+bmlKh5LUYN8B7AvcI+mgPV7gPSJ+2SKh/wDu7jDrZmYlEBG/lzQx4+kzgRsiogF4TtIqYBpwX3sXZZ5ZUmQS8LYuXGdmeVL+AdUXSPqzpGsk7ZUeG8fuNdY16bF2ZZlZ8qqkTem2maQ0eElXcm1mOdG5AdUjJT1YtGXpf5gPHABMAeqBH6THWxu82GG4bbdqnK5VcjjJOiUAhYiooL4gM+sx2SPFhoiY2qlbR6xrfp126N6W7q4BJhSdOh5Y29H92i0RpkHvlohoSjcHQTPLpoxVY0lji3Y/Cjyevl4EzJbUT9IkYDKwtKP7Zek1XirpyIh4uNO5NbNcEqXrNZZ0PTCdpAq9Bvg6MF3SFJJQ+jzwWYCIWC5pIfAE0AjM7ajHGNpfs6RPRDQC7wPOlfQM8DrJZ4yIOHIPPpuZVbMSDqiOiNNbOXx1O+dfTrLiZmbtlQiXAkcCszpzQzMzoGqm2AkgIp7ppryYWTWpkkA4StIX23ozIn5YhvyYWZWolrnGtcBgWh+XY2bWvioJhPUR8c1uy4mZVY8o6VzjsuuwjdDMrEuqpER4XLflwsyqTlW0EUbEpu7MiJlVmWoIhGZmXdaLlurMwoHQzEpOVEnV2MxsTzgQmpk5EJpZ7jkQmlmuVdtynmZmXeJAaGZ5Vy1T7MzMusxVYzPLNw+oNjPDgdDM8s0zS8zMABUqJxI6EJpZ6bmN0MyssqrGNT2dATOrUpFx64CkayStl/R40bERku6WtDL9uVfRexdLWiVphaSTsmTVgdDMykKRbcvgWmBGi2MXAYsjYjKwON1H0qHAbOAd6TU/k1TbUQIOhGZWHiUqEUbE74GWT8yfCVyXvr4OmFV0/IaIaIiI54BVwLSO0nAboZmVXudWsRsp6cGi/asi4qoOrhkdEfUAEVEvaZ/0+Djg/qLz1qTH2uVAaGYl18lxhBsiYmoJk26pw5y4amxm5RGRbeuadZLGAqQ/16fH1wATis4bD6zt6GYOhGZWFiXsLGnNIuDM9PWZwK1Fx2dL6idpEjAZWNrRzVw17gWmTt/Ked9aS21NcMf1I1g4b3RPZ6nq7NwhvnTqgezaWUNTI7z/r7fw6a+8vNs5j/5xMN84axJjJuwE4JhTNvPJL67bs3QbxPcu3I+Vjw1k6F6NXHLlasZM2Mkzjw/gpxeP5/VtNdTWwuwL1zF95uY9SqtXKeGAaknXA9NJ2hLXAF8HvgsslHQO8AJwGkBELJe0EHgCaATmRkRTR2mULRBKugb4MLA+Ig5r5X0BPwZOAbYDn4mIh8uVn96qpiaY++2XuHj2/myor+Ont6/k/juH8cLK/j2dtapS1y/45xufYcCgAo274IuzJvPuY7fy9ndt3+28w456jW8teK7T93/5xb784Av78b2bVu12/M7rRzB4eBPX/vFJfvvfw7n6n8Zy6b+upt+AAl/58WrG7b+TjS/34YIZBzN1+jYGD+vwd7ZilOp5hBFxehtvHdfG+ZcDl3cmjXJWja/lrWN/ip1MUmydDMwB5pcxL73WwUdsZ+3zfXn5hX407qrht7cO5z0nbenpbFUdCQYMSn4zG3eJpl1CrTWrt2HxTXvxuVMmc/7xB/Pjr46nKWO8uu/OYZxwWjLy4/0f3syye4cQAeMPaGDc/knJc+8xjQwb2ciWjR0Od6soKmTbeoOyBcI2xv4UmwksiMT9wPDmxs882XvMLl5Z2/eN/Q31dYwcu6sHc1S9mprg/OMP5u/eeRhHfGAbhxy5/S3nPPnQIM47/mAuPWN/nl+RlMpfWNmP3906nB/dupL596ygphb+5+a93nJtaza8XMeofZPvs7YPDBraxNZNuwe8px4ZSONOMXbizj38hL1IUO7OkpLqyTbCccCLRfvN433qW54oaQ5JqZH+DOyWzHWX1kolveT/RtWprYX596zgtS21XHbORJ5/qj8TD9nxxvsH/tV2/mPpEwwYVGDp4iFcdvYk/v0PT/LIkiGsfGwgnzv5YCBpbxy+dyMAl509MS3Ni/Uv1XH+8ck5s/7+FU6avanV77L4O9+4rg/f+9x+fPnHL1BTZV2XlTTXuCcDYebxPungyqsAhmpEBf3zdmxDfR2j9n2zJDBy7C42vlzXgzmqfoOHNXH4e17jgf8dslsgHDTkzXratOO2Me9iJdXVgBNO28TZl7zlbzRfv+Z5oO02wlFjd/HK2qRU2NQIr2+tZcheSb369W01/L9P7c+Z/6f+LW2VVaGCflN78m9Ql8b7VJsVywYybtJORk9ooE9dgekzN3P/XcN6OltVZ/PGWl7bklRJG/4iHl4yhAkHNux2zqb1fd4owT31yEAKBRg6ookp79/Gkl8PZ/OGpNyw9dVa1q3J9sfq6BO3cveNIwBYcttwDn/fNiTYtVN885xJHHfaq3zgI9XXJtw8oLqMw2dKqidLhIuACyTdABwFbGmeMpMnhSZxxaXj+PYvnqWmFu66YQSrn3aPcaltWlfH9z+/H4WCKBTgAx/ZzNEnbOW2BXsD8OFPb2TJbcO5bcHe1PaBfv0LXDz/eSR420ENnPnVei6efQARUNsnuODbaxg9vuO23Bmnb+SfL3wbn3nv2xkyvJFL5q8G4Pe/Gs5j9w9m66Y+3P3LJFB++V9e4IDD/lK+f4TuFFFRD2ZVlKlBqnjsD7COZOxPHUBEXJkOn5lH0rO8HTgrIh5s/W5vGqoRcZRa7TW3XurOtct6OgvWSbVjVz20J9PehgwfH0d84POZzl3yq6/uUVqlULYSYTtjf5rfD2BuudI3s57VW6q9WXhmiZmVXgAVVDV2IDSz8qicOOhAaGbl4aqxmeVeJfUaOxCaWel5OU8zy7tkQHXlREIHQjMrj17yZJksHAjNrCxcIjSzfHMboZlZZc01diA0s/Jw1djMcq1zC7z3OAdCMysPlwjNLPcqJw46EJpZeahQurqxpOeBbUAT0BgRUyWNAH4JTASeBz4eEa925f5VtlyMmfUKQTKgOsuW3YciYkrRQ1wvAhZHxGRgcbrfJQ6EZlZyIlBk2/bATOC69PV1wKyu3siB0MzKI/u6xiMlPVi0zWntbsBdkh4qen908zpH6c99uppVtxGaWXlkL+1tyLBmyTERsVbSPsDdkp7as8ztziVCMyu9ErcRRsTa9Od64BZgGrBO0liA9Of6rmbXgdDMykKFQqatw/tIgyQNaX4NnAg8TrIk8JnpaWcCt3Y1r64am1kZRCkHVI8GbklWAKYP8IuI+I2kB4CFks4BXgBO62oCDoRmVnpByQJhRDwLHN7K8Y1ASRY5dyA0s/LwXGMzyzs/mNXMzIHQzHItApoqp27sQGhm5eESoZnlngOhmeVaAF6zxMzyLSDcRmhmeRa4s8TMzG2EZmYOhGaWbyV96ELZORCaWekFUMLFm8rNgdDMysMlQjPLN0+xM7O8CwiPIzSz3PPMEjPLPbcRmlmuRbjX2MzMJUIzy7kgmpp6OhOZORCaWen5MVxmZlTUY7hqejoDZlZ9AohCZNqykDRD0gpJqyRdVOr8OhCaWelF+mDWLFsHJNUCVwAnA4cCp0s6tJTZddXYzMqihJ0l04BVEfEsgKQbgJnAE6VKQFFBXdwAkl4BVvd0PspkJLChpzNhmVXz9/W2iBjV1Ysl/Ybk3yeL/sCOov2rIuKqont9DJgREX+f7n8KOCoiLuhq/lqquBLhnnw5vZ2kByNiak/nw7Lx99W2iJhRwtuptSRKeH+3EZpZr7cGmFC0Px5YW8oEHAjNrLd7AJgsaZKkvsBsYFEpE6i4qnGVu6rjU6wX8ffVDSKiUdIFwJ1ALXBNRCwvZRoV11liZlZqrhqbWe45EJpZ7jkQdrOOpgop8ZP0/T9LOrIn8mkJSddIWi/p8Tbe9/dVBRwIu1HGqUInA5PTbQ4wv1szaS1dC7Q3Js7fVxVwIOxeb0wVioidQPNUoWIzgQWRuB8YLmlsd2fUEhHxe2BTO6f4+6oCDoTdaxzwYtH+mvRYZ8+x3sPfVxVwIOxeWaYKlX06kZWUv68q4EDYvbJMFSr7dCIrKX9fVcCBsHtlmSq0CPh02ht5NLAlIuq7O6OWmb+vKuApdt2oralCks5L378SuB04BVgFbAfO6qn8Gki6HpgOjJS0Bvg6UAf+vqqJp9iZWe65amxmuedAaGa550BoZrnnQGhmuedAaGa550BYhSQ1SVom6XFJN0oauAf3mi7ptvT137S3uLak4ZL+oQtpfEPSl7Meb3HOtekqZ1nTmtjWk2QsvxwIq9NfImJKRBwG7ATOK34zHfzb6e8+IhZFxHfbOWU40OlAaNbTHAir3xLgwLQk9KSknwEPAxMknSjpPkkPpyXHwfDGMxOfknQvcGrzjSR9RtK89PVoSbdIejTd3gt8FzggLY1+Lz3vK5IeSJ/Vd1nRvS5Nn8t4D3BwRx9C0rnpfR6VdFOLUu7xkpZIelrSh9PzayV9ryjtz+7pP6RVLwfCKiapD8nz8h5LDx1M8sioI4DXga8Bx0fEkcCDwBcl9Qd+DnwEeD8wpo3b/wT4XUQcDhwJLAcuAp5JS6NfkXQiyXP6pgFTgHdJ+oCkd5FMLzyCJNC+O8PHuTki3p2m9yRwTtF7E4EPAn8NXJl+hnNIpru9O73/uZImZUjHcshT7KrTAEnL0tdLgKuBfYHV6TPzAI4meTjsHyQB9AXuAw4BnouIlQCS/pPkgaMtHQt8GiAimoAtkvZqcc6J6fZIuj+YJDAOAW6JiO1pGlmWZjxM0j+RVL8Hk0xTbLYwIgrASknPpp/hROCdRe2Hw9K0n86QluWMA2F1+ktETCk+kAa714sPAXdHxOktzptC6R4jJeA7EfGvLdL4QhfSuBaYFRGPSvoMyfzfZi3vFWnan4uI4oCJpImdTNdywFXj/LofOEbSgQCSBko6CHgKmCTpgPS809u4fjFwfnptraShwDaS0l6zO4Gzi9oex0naB/g98FFJAyQNIamGd2QIUC+pDjijxXunSapJ87w/sCJN+/z0fCQdJGlQhnQsh1wizKmIeCUtWV0vqV96+GsR8bSkOcCvJW0A7gUOa+UWnweuknQO0AScHxH3SfpDOjzljrSd8O3AfWmJ9DXgkxHxsKRfAsuA1STV9478X+BP6fmPsXvAXQH8DhgNnBcROyT9G0nb4cNKEn8FmJXtX8fyxk+fMbPcc9XYzHLPgdDMcs+B0Mxyz4HQzHLPgdDMcs+B0Mxyz4HQzHLv/wOkTpnzR/fF/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_clf_sp = svm.SVC().fit(x_train_sp, y_train_sp)\n",
    "plot_results(svm_clf_sp, x_test_sp, y_test_sp,save=True,name='svm_sp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest with GloVe\n",
    "#### 1 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.685833 using {'max_depth': 100, 'n_estimators': 750}\n",
      "0.684167 (0.014167) with: {'max_depth': None, 'n_estimators': 250}\n",
      "0.681667 (0.012247) with: {'max_depth': None, 'n_estimators': 500}\n",
      "0.684167 (0.012047) with: {'max_depth': None, 'n_estimators': 750}\n",
      "0.683333 (0.012910) with: {'max_depth': None, 'n_estimators': 1000}\n",
      "0.677500 (0.019021) with: {'max_depth': 50, 'n_estimators': 250}\n",
      "0.680833 (0.013969) with: {'max_depth': 50, 'n_estimators': 500}\n",
      "0.684167 (0.016436) with: {'max_depth': 50, 'n_estimators': 750}\n",
      "0.684167 (0.014167) with: {'max_depth': 50, 'n_estimators': 1000}\n",
      "0.680833 (0.016266) with: {'max_depth': 100, 'n_estimators': 250}\n",
      "0.682500 (0.011456) with: {'max_depth': 100, 'n_estimators': 500}\n",
      "0.685833 (0.010574) with: {'max_depth': 100, 'n_estimators': 750}\n",
      "0.684167 (0.012047) with: {'max_depth': 100, 'n_estimators': 1000}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.99      0.81       445\n",
      "         1.0       0.33      0.01      0.02       201\n",
      "\n",
      "    accuracy                           0.69       646\n",
      "   macro avg       0.51      0.50      0.42       646\n",
      "weighted avg       0.58      0.69      0.57       646\n",
      "\n",
      "Test accuracy: 0.6857585139318886\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_param_grid = dict(max_depth=[None, 50, 100],\n",
    "                  n_estimators=[250, 500, 750, 1000])\n",
    "rf_grid = GridSearchCV(estimator=RandomForestClassifier(), \n",
    "                       param_grid=rf_param_grid, \n",
    "                       n_jobs=-1, \n",
    "                       cv=10, \n",
    "                       scoring='accuracy',\n",
    "                       verbose=1)\n",
    "with parallel_backend('threading'):    # This is a bug work-around mentioned in https://github.com/scikit-learn/scikit-learn/issues/12546\n",
    "    rf_grid_result = rf_grid.fit(x_train_1yr, y_train_1yr)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (rf_grid_result.best_score_, rf_grid_result.best_params_))\n",
    "rf_means = rf_grid_result.cv_results_['mean_test_score']\n",
    "rf_stds = rf_grid_result.cv_results_['std_test_score']\n",
    "rf_params = rf_grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(rf_means, rf_stds, rf_params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Fit the model with the best parameters found in the cross validation. \n",
    "randomforest_1yr = RandomForestClassifier(max_depth=rf_grid_result.best_params_['max_depth'],\n",
    "                                      n_estimators=rf_grid_result.best_params_['n_estimators']).fit(x_train_1yr, y_train_1yr)\n",
    "plot_results(randomforest_1yr,x_test_1yr, y_test_1yr,save=True,name='rf_1yr_md{}_est_{}'.format(rf_grid_result.best_params_['max_depth'],\n",
    "                                                                                rf_grid_result.best_params_['n_estimators']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_param_grid = dict(max_depth=[None, 50, 100],\n",
    "                  n_estimators=[250, 500, 750, 1000])\n",
    "rf_grid = GridSearchCV(estimator=RandomForestClassifier(), \n",
    "                       param_grid=rf_param_grid, \n",
    "                       n_jobs=-1, \n",
    "                       cv=10, \n",
    "                       scoring='accuracy',\n",
    "                       verbose=1)\n",
    "with parallel_backend('threading'):    # This is a bug work-around mentioned in https://github.com/scikit-learn/scikit-learn/issues/12546\n",
    "    rf_grid_result = rf_grid.fit(x_train_3yr, y_train_3yr)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (rf_grid_result.best_score_, rf_grid_result.best_params_))\n",
    "rf_means = rf_grid_result.cv_results_['mean_test_score']\n",
    "rf_stds = rf_grid_result.cv_results_['std_test_score']\n",
    "rf_params = rf_grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(rf_means, rf_stds, rf_params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Fit the model with the best parameters found in the cross validation. \n",
    "randomforest_3yr = RandomForestClassifier(max_depth=rf_grid_result.best_params_['max_depth'],\n",
    "                                      n_estimators=rf_grid_result.best_params_['n_estimators']).fit(x_train_3yr, y_train_3yr)\n",
    "plot_results(randomforest_3yr,x_test_3yr, y_test_3yr,save=True,name='rf_3yr_md{}_est_{}'.format(rf_grid_result.best_params_['max_depth'],\n",
    "                                                                                rf_grid_result.best_params_['n_estimators']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S&P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_param_grid = dict(max_depth=[None, 50, 100],\n",
    "                  n_estimators=[250, 500, 750, 1000])\n",
    "rf_grid = GridSearchCV(estimator=RandomForestClassifier(), \n",
    "                       param_grid=rf_param_grid, \n",
    "                       n_jobs=-1, \n",
    "                       cv=10, \n",
    "                       scoring='accuracy',\n",
    "                       verbose=1)\n",
    "with parallel_backend('threading'):    # This is a bug work-around mentioned in https://github.com/scikit-learn/scikit-learn/issues/12546\n",
    "    rf_grid_result = rf_grid.fit(x_train_sp, y_train_sp)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (rf_grid_result.best_score_, rf_grid_result.best_params_))\n",
    "rf_means = rf_grid_result.cv_results_['mean_test_score']\n",
    "rf_stds = rf_grid_result.cv_results_['std_test_score']\n",
    "rf_params = rf_grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(rf_means, rf_stds, rf_params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Fit the model with the best parameters found in the cross validation. \n",
    "randomforest_sp = RandomForestClassifier(max_depth=rf_grid_result.best_params_['max_depth'],\n",
    "                                      n_estimators=rf_grid_result.best_params_['n_estimators']).fit(x_train_sp, y_train_sp)\n",
    "plot_results(randomforest_sp,x_test_sp, y_test_sp,save=True,name='rf_sp_md{}_est_{}'.format(rf_grid_result.best_params_['max_depth'],\n",
    "                                                                                rf_grid_result.best_params_['n_estimators']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nodes1=100, nodes2=50, dropout_rate=0.3, optimizer='rmsprop', learning_rate=0.001):\n",
    "    if optimizer.lower() == 'rmsprop': \n",
    "        optimizer = RMSprop(learning_rate = learning_rate)\n",
    "    elif optimizer.lower() == 'adam':\n",
    "        optimizer = Adam(learning_rate = learning_rate)\n",
    "    model = Sequential() \n",
    "    if nodes1 == 0: \n",
    "        model.add(Dense(1, input_shape=x_train_1yr.shape[1:], activation='sigmoid'))\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "        return model \n",
    "    model.add(Dense(nodes1, input_shape=x_train_1yr.shape[1:]))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    if nodes2 == 0: \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "        return model\n",
    "    model.add(Dense(nodes2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model \n",
    "\n",
    "def randomize_params(params, n):\n",
    "    test_params = []\n",
    "    for i in range(n):\n",
    "        temp_par = {}\n",
    "        while True: \n",
    "            for par in params: \n",
    "                temp_par.update({par: np.random.choice(params[par])})\n",
    "            if temp_par not in test_params: \n",
    "                test_params.append(temp_par)\n",
    "                break\n",
    "    return test_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 50\n",
    "# Define possible parameters \n",
    "possible_params = dict(batch_size = [8, 16, 32],\n",
    "                       nodes1 = [50, 100, 250, 500],\n",
    "                       nodes2 = [0, 50, 100, 250, 500], # 0 implies only one hidden layer \n",
    "                       dropout_rate = [0.1, 0.3, 0.5],\n",
    "                       learning_rate = [1e-3, 1e-4, 1e-5],\n",
    "                       optimizer = ['RMSprop','Adam'])\n",
    "test_params = randomize_params(possible_params, n_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed forward, pre-trained embeddings\n",
    "#### 1 year rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 864 candidates, totalling 2592 fits\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.660, total=   3.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.683, total=   3.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.702, total=   3.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam, score=0.678, total=   3.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   12.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam, score=0.647, total=   3.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   15.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam, score=0.700, total=   2.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   18.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.673, total=   2.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   21.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.670, total=   3.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   24.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.705, total=   3.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   27.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam, score=0.670, total=   3.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam, score=0.683, total=   3.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam, score=0.705, total=   6.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.678, total=   4.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.678, total=   4.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.650, total=   4.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=adam, score=0.665, total=   4.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=adam, score=0.645, total=   4.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=adam, score=0.705, total=   4.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=rmsprop, score=0.665, total=   4.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=rmsprop, score=0.683, total=   4.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=rmsprop, score=0.647, total=   5.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=adam, score=0.660, total=   4.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=adam, score=0.685, total=   4.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=50, nodes2=500, optimizer=adam, score=0.652, total=   5.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=rmsprop, score=0.663, total=   5.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=rmsprop, score=0.685, total=   6.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=rmsprop, score=0.702, total=   5.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=adam, score=0.673, total=   5.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=adam, score=0.685, total=   4.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=50, optimizer=adam, score=0.700, total=   4.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=rmsprop, score=0.673, total=   5.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=rmsprop, score=0.640, total=   7.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=rmsprop, score=0.690, total=   6.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=adam, score=0.585, total=   5.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=adam, score=0.685, total=   8.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=100, optimizer=adam, score=0.700, total=   7.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=rmsprop, score=0.678, total=   7.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=rmsprop, score=0.665, total=   7.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=rmsprop, score=0.700, total=   6.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=adam, score=0.668, total=   6.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=adam, score=0.680, total=   6.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=250, optimizer=adam, score=0.660, total=   5.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=rmsprop, score=0.678, total=   6.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=rmsprop, score=0.680, total=   9.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=rmsprop, score=0.618, total=   8.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=adam, score=0.675, total=   7.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=adam, score=0.618, total=   7.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=100, nodes2=500, optimizer=adam, score=0.702, total=   8.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=rmsprop, score=0.678, total=   9.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=rmsprop, score=0.635, total=   6.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=rmsprop, score=0.697, total=   6.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=adam, score=0.680, total=   9.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=adam, score=0.655, total=   8.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=50, optimizer=adam, score=0.705, total=   8.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=rmsprop, score=0.678, total=   8.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=rmsprop, score=0.685, total=  10.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=rmsprop, score=0.630, total=  11.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=adam, score=0.613, total=  10.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=adam, score=0.640, total=   8.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=100, optimizer=adam, score=0.700, total=   9.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=rmsprop, score=0.630, total=  10.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=rmsprop, score=0.655, total=  13.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=rmsprop, score=0.685, total=  13.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=adam, score=0.670, total=  12.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=adam, score=0.683, total=  12.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=250, optimizer=adam, score=0.375, total=   9.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=rmsprop, score=0.678, total=  12.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=rmsprop, score=0.618, total=  11.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=rmsprop, score=0.692, total=  12.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=adam, score=0.675, total=   8.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=adam, score=0.642, total=   8.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=250, nodes2=500, optimizer=adam, score=0.598, total=   8.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=rmsprop, score=0.678, total=   9.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=rmsprop, score=0.658, total=   9.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=rmsprop, score=0.663, total=  10.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=adam, score=0.678, total=   8.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=adam, score=0.505, total=   8.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=50, optimizer=adam, score=0.697, total=   9.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=rmsprop, score=0.678, total=  10.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=rmsprop, score=0.680, total=  11.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=rmsprop, score=0.692, total=  14.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=adam, score=0.675, total=   9.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=adam, score=0.620, total=  12.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=100, optimizer=adam, score=0.702, total=  13.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=rmsprop, score=0.678, total=  14.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=rmsprop, score=0.685, total=  16.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=rmsprop, score=0.480, total=  16.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=adam, score=0.673, total=  14.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=adam, score=0.535, total=  13.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=250, optimizer=adam, score=0.623, total=  11.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=rmsprop, score=0.480, total=  18.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=rmsprop, score=0.642, total=  19.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=rmsprop, score=0.663, total=  20.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=adam, score=0.673, total=  15.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=adam, score=0.477, total=  21.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.001, nodes1=500, nodes2=500, optimizer=adam, score=0.705, total=  17.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.678, total=  11.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.685, total=  14.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.702, total=  13.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=adam, score=0.678, total=  10.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=adam, score=0.685, total=  12.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=50, optimizer=adam, score=0.702, total=  13.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.678, total=  13.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.685, total=  13.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.702, total=  14.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=adam, score=0.678, total=  11.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=adam, score=0.685, total=  10.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=100, optimizer=adam, score=0.700, total=  18.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.678, total=  19.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.685, total=  17.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.702, total=  19.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=adam, score=0.678, total=  19.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=adam, score=0.685, total=  18.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=250, optimizer=adam, score=0.702, total=  15.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=rmsprop, score=0.678, total=  24.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=rmsprop, score=0.685, total=  22.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=rmsprop, score=0.702, total=  24.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=adam, score=0.678, total=  27.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=adam, score=0.685, total=  20.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=50, nodes2=500, optimizer=adam, score=0.702, total=  24.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=rmsprop, score=0.678, total=  21.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=rmsprop, score=0.685, total=  24.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=rmsprop, score=0.702, total=  27.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=adam, score=0.678, total=  23.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=adam, score=0.685, total=  22.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=50, optimizer=adam, score=0.702, total=  26.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=rmsprop, score=0.678, total=  27.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=rmsprop, score=0.685, total=  28.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=rmsprop, score=0.702, total=  26.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=adam, score=0.678, total=  21.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=adam, score=0.685, total=  25.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=100, optimizer=adam, score=0.702, total=  20.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=rmsprop, score=0.678, total=  26.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=rmsprop, score=0.685, total=  32.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=rmsprop, score=0.702, total=  30.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=adam, score=0.678, total=  37.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=adam, score=0.685, total=  30.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=250, optimizer=adam, score=0.702, total=  25.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=rmsprop, score=0.678, total=  34.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=rmsprop, score=0.685, total=  28.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=rmsprop, score=0.702, total=  34.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=adam, score=0.678, total=  29.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=adam, score=0.685, total=  32.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=100, nodes2=500, optimizer=adam, score=0.702, total=  33.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=rmsprop, score=0.678, total=  31.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=rmsprop, score=0.685, total=  40.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=rmsprop, score=0.702, total=  33.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=adam, score=0.678, total=  33.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=adam, score=0.685, total=  29.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=50, optimizer=adam, score=0.702, total=  31.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=rmsprop, score=0.678, total=  37.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=rmsprop, score=0.685, total=  38.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=rmsprop, score=0.702, total=  40.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=adam, score=0.673, total=  41.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=adam, score=0.685, total=  38.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=100, optimizer=adam, score=0.702, total=  38.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=rmsprop, score=0.668, total=  42.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=rmsprop, score=0.685, total=  40.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=rmsprop, score=0.702, total=  46.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=adam, score=0.675, total=  30.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=adam, score=0.668, total=  42.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=250, optimizer=adam, score=0.702, total=  41.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=rmsprop, score=0.678, total=  43.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=rmsprop, score=0.685, total=  46.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=rmsprop, score=0.702, total=  42.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=adam, score=0.675, total=  45.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=adam, score=0.685, total=  34.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=250, nodes2=500, optimizer=adam, score=0.702, total=  43.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=rmsprop, score=0.673, total=  50.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=rmsprop, score=0.685, total=  46.0s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=rmsprop, score=0.702, total=  49.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=adam, score=0.678, total=  43.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=adam, score=0.685, total=  48.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=50, optimizer=adam, score=0.702, total=  42.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=rmsprop, score=0.678, total=  57.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=rmsprop, score=0.685, total=  46.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=rmsprop, score=0.702, total=  51.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=adam, score=0.675, total=  44.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=adam, score=0.685, total=  55.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=100, optimizer=adam, score=0.702, total=  54.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=rmsprop, score=0.675, total=  50.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=rmsprop, score=0.663, total=  58.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=rmsprop, score=0.705, total=  48.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=adam, score=0.673, total=  54.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=adam, score=0.627, total=  45.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=250, optimizer=adam, score=0.702, total=  39.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=rmsprop, score=0.670, total= 1.2min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=rmsprop, score=0.685, total= 1.0min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=rmsprop, score=0.702, total= 1.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=adam, score=0.670, total=  50.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=adam, score=0.683, total= 1.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=0.0001, nodes1=500, nodes2=500, optimizer=adam, score=0.702, total=  56.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.678, total=  54.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.685, total=  49.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.700, total=  41.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=adam, score=0.678, total=  49.1s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=adam, score=0.685, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=50, optimizer=adam, score=0.702, total= 1.0min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.678, total=  54.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.685, total= 1.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.702, total=  56.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=adam, score=0.678, total=  55.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=adam, score=0.685, total= 1.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=100, optimizer=adam, score=0.702, total=  53.7s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.678, total=  56.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.685, total=  57.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.702, total=  57.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=adam, score=0.678, total=  59.6s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=adam, score=0.685, total= 1.0min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=250, optimizer=adam, score=0.702, total=  53.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=rmsprop, score=0.678, total= 1.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=rmsprop, score=0.685, total= 1.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=rmsprop, score=0.702, total= 2.0min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=adam, score=0.678, total= 1.2min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=adam, score=0.685, total= 1.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=50, nodes2=500, optimizer=adam, score=0.702, total= 1.4min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=rmsprop, score=0.678, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=rmsprop, score=0.685, total= 1.2min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=rmsprop, score=0.702, total= 1.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=adam, score=0.678, total= 1.2min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=adam, score=0.685, total=  49.8s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=50, optimizer=adam, score=0.700, total= 1.2min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=rmsprop, score=0.678, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=rmsprop, score=0.685, total= 1.0min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=rmsprop, score=0.702, total= 1.2min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=adam, score=0.678, total=  59.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=adam, score=0.685, total= 1.4min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=100, optimizer=adam, score=0.702, total=  53.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=rmsprop, score=0.678, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=rmsprop, score=0.685, total= 2.6min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=rmsprop, score=0.702, total= 1.5min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=adam, score=0.678, total= 1.4min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=adam, score=0.685, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=250, optimizer=adam, score=0.702, total= 2.7min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=rmsprop, score=0.678, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=rmsprop, score=0.685, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=rmsprop, score=0.702, total= 1.5min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=adam, score=0.678, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=adam, score=0.685, total= 1.5min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=100, nodes2=500, optimizer=adam, score=0.702, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=rmsprop, score=0.678, total= 1.6min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=rmsprop, score=0.685, total= 2.7min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=rmsprop, score=0.702, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=adam, score=0.678, total= 1.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=adam, score=0.685, total= 1.6min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=50, optimizer=adam, score=0.702, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=rmsprop, score=0.678, total= 2.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=rmsprop, score=0.685, total= 2.0min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=rmsprop, score=0.702, total= 2.5min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=adam, score=0.678, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=adam, score=0.685, total= 1.6min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=100, optimizer=adam, score=0.702, total= 1.5min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=rmsprop, score=0.678, total= 1.5min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=rmsprop, score=0.685, total=  40.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=rmsprop, score=0.702, total=  40.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=adam, score=0.678, total= 1.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=adam, score=0.685, total= 1.0min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=250, optimizer=adam, score=0.702, total=  41.3s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=rmsprop, score=0.678, total=  52.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=rmsprop, score=0.685, total= 1.7min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=rmsprop, score=0.702, total=  40.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=adam, score=0.678, total=  33.2s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=adam, score=0.685, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=250, nodes2=500, optimizer=adam, score=0.702, total= 3.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=rmsprop, score=0.678, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=rmsprop, score=0.685, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=rmsprop, score=0.702, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=adam, score=0.678, total=  36.9s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=adam, score=0.685, total=  44.5s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=50, optimizer=adam, score=0.702, total= 1.7min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=rmsprop, score=0.678, total= 2.0min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=rmsprop, score=0.685, total= 2.8min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=rmsprop, score=0.702, total= 2.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=adam, score=0.678, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=adam, score=0.685, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=100, optimizer=adam, score=0.702, total= 1.9min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=rmsprop, score=0.678, total= 1.7min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=rmsprop, score=0.685, total= 1.9min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=rmsprop, score=0.702, total= 3.0min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=adam, score=0.678, total= 2.3min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=adam, score=0.685, total= 1.9min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=250, optimizer=adam, score=0.702, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=rmsprop, score=0.678, total= 2.1min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=rmsprop, score=0.685, total= 2.2min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=rmsprop, score=0.702, total= 1.6min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=adam, score=0.678, total=  59.4s\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=adam, score=0.685, total= 2.2min\n",
      "[CV] batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.1, epochs=10, learning_rate=1e-05, nodes1=500, nodes2=500, optimizer=adam, score=0.702, total= 2.4min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.670, total= 1.6min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.660, total= 2.1min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=rmsprop, score=0.702, total= 2.2min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam, score=0.678, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam, score=0.683, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=50, optimizer=adam, score=0.702, total= 1.9min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.670, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.663, total= 1.3min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=rmsprop, score=0.702, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam, score=0.670, total= 3.5min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam, score=0.685, total= 1.4min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=100, optimizer=adam, score=0.673, total= 1.8min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.670, total= 2.4min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop, score=0.668, total= 1.7min\n",
      "[CV] batch_size=8, dropout_rate=0.3, epochs=10, learning_rate=0.001, nodes1=50, nodes2=250, optimizer=rmsprop \n"
     ]
    }
   ],
   "source": [
    "historylist_1yr = []\n",
    "for i,params in enumerate(tqdm(test_params)): \n",
    "    bs = params.pop('batch_size')\n",
    "    model = create_model(**params)\n",
    "    params.update({'batch_size': bs})\n",
    "    history = model.fit(x_train_1yr, y_train_1yr,\n",
    "                        epochs=10000,\n",
    "                        batch_size=params['batch_size'],\n",
    "                        verbose=0,\n",
    "                        callbacks=[EarlyStopping(monitor='val_acc', patience=2, restore_best_weights=True)],\n",
    "                        validation_split=0.2)\n",
    "    historylist_1yr.append(history)\n",
    "max_acc_1yr = -1\n",
    "max_idx_1yr = -1\n",
    "for i,hist in enumerate(historylist_1yr):\n",
    "    if max(hist.history['val_acc']) > max_acc_1yr: \n",
    "        max_acc_1yr = max(hist.history['val_acc'])\n",
    "        max_idx_1yr = i\n",
    "    \n",
    "print(\"Best val acc:\",max_acc_1yr)\n",
    "print(\"For config: \",test_params[max_idx_1yr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = test_params[max_idx_1yr].pop('batch_size')\n",
    "model_ff_1yr = create_model(**test_params[max_idx_1yr])\n",
    "test_params[max_idx_1yr].update({'batch_size': bs})\n",
    "\n",
    "history_1yr = model_ff_1yr.fit(x_train_1yr, y_train_1yr,\n",
    "                               epochs=100000,\n",
    "                               batch_size = bs,\n",
    "                               verbose=1,\n",
    "                               callbacks = [EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)],\n",
    "                               validation_split=0.2)\n",
    "savename_1yr = \"nn_bs{}_n1{}_n2{}_dr{}_lr{}_opt{}\".format(test_params[max_idx_1yr]['batch_size'],\n",
    "                                                          test_params[max_idx_1yr]['nodes1'],\n",
    "                                                          test_params[max_idx_1yr]['nodes2'],\n",
    "                                                          test_params[max_idx_1yr]['dropout_rate'],\n",
    "                                                          test_params[max_idx_1yr]['learning_rate'],\n",
    "                                                          test_params[max_idx_1yr]['optimizer'])\n",
    "plot_results_nn(history_1yr,model_ff_1yr,x_test_1yr, y_test_1yr,save=True, name=savename_1yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1296 candidates, totalling 3888 fits\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop [CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.524, total=   5.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=   5.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.542, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    5.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.483, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.509, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.517, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.465, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.527, total=   9.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=   9.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=   9.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   14.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.476, total=   8.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.526, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.477, total=   9.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.474, total=   9.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   0.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_10719/acc/Cast_1'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   15.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.526, total=   5.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.485, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.502, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.483, total=   5.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.515, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.559, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5368/dense_3_loss/num_elements/Cast'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=nan, total=   0.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.506, total=  19.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   25.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.500, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=   5.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.482, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.474, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.474, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.503, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.456, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.480, total=   6.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.509, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=   5.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.468, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.535, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.476, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.495, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.461, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.471, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.480, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.495, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.518, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.509, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   39.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.453, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5391/dense_6_loss/Mean'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_10785/acc/div_no_nan'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=nan, total=   0.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=nan, total=   0.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.471, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.494, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   5.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.529, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=   5.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.506, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.520, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   45.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.468, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.485, total=   5.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.474, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.503, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.474, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.529, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.532, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   57.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.527, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=   7.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.550, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.524, total=  11.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.506, total=  11.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.535, total=  11.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.495, total=  11.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.495, total=  11.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.512, total=  11.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.505, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.495, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.500, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.503, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.486, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.547, total=  22.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.483, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.544, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.498, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.506, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.517, total=   8.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.544, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.533, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  1.5min\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5443/dense_11_loss/mul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=nan, total=   1.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.495, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.470, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.465, total=   9.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.456, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.497, total=   9.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.494, total=   9.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.450, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.479, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.562, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.450, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.502, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.515, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.477, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.500, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.505, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.453, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.515, total=   8.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.492, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.492, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.491, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=   8.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=   7.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   8.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   8.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.509, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.479, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=   7.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=   8.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.495, total=   8.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.509, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.532, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total=   8.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.497, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.532, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=   8.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=   8.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   8.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.521, total=  10.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=  10.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.506, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.547, total=  10.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.502, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=nan, total=   0.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_10987/acc/Identity'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5494/dense_19_loss/mul_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=nan, total=   0.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.518, total=  10.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5498/dense_21_loss/Mean'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=nan, total=   0.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.492, total=  15.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=  13.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=  14.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.506, total=  14.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.520, total=  13.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.495, total=  13.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=nan, total=   0.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5504/dense_20_loss/weighted_loss/broadcast_weights/ones_like'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.502, total=  13.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.509, total=  10.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=  10.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.521, total=  10.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total=  10.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.474, total=  10.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.518, total=  10.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.517, total=  10.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.494, total=  27.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.462, total=  11.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.494, total=  11.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.492, total=  10.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=  11.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.452, total=  11.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.465, total=  11.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.498, total=  11.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.518, total=  11.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.462, total=  11.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.514, total=  10.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.509, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.471, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.515, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.480, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.486, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.500, total=  10.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.489, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.524, total=  10.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.459, total=  10.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.502, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.462, total=  10.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.500, total=  10.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=  11.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=  11.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=  10.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.509, total=  10.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  10.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.497, total=  10.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=  10.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.523, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=  10.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  3.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=  10.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.508, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.491, total=  10.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total=  10.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.497, total=  11.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.491, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.535, total=  10.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.518, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.480, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.505, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.498, total=   6.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.491, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.520, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.535, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.506, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.489, total=  10.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.536, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.541, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  4.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.426, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.530, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=   5.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.477, total=   5.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.524, total=   5.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.492, total=   5.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=   5.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.488, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.535, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.524, total=   6.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.471, total=  20.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.489, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=   6.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.503, total=   6.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.471, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.515, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.495, total=   6.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.468, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.471, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.518, total=   6.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.468, total=   6.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=   6.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  4.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.536, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.474, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.465, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.509, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.489, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.468, total=   6.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.491, total=   6.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.468, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.477, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.503, total=   6.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.429, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.538, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.494, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.495, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.529, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=   6.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.548, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   6.0s[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=   6.0s\n",
      "\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.506, total=   6.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.529, total=   6.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  4.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.459, total=   6.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.505, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=   6.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=   6.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.482, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=   6.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.497, total=   6.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=   6.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5632/dense_39_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=nan, total=   0.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.529, total=   6.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   6.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.506, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.511, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.495, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.508, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.524, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.492, total=   9.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.495, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  5.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.500, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=  11.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=  11.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.527, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.471, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.500, total=  11.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.471, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.503, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.535, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.527, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.541, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.518, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.548, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.480, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.535, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.498, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.520, total=  24.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.468, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.512, total=   9.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.489, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.506, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.471, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  5.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.465, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.477, total=   8.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.494, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.514, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.480, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.512, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.465, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.538, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.468, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.524, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.492, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.521, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.480, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.489, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.529, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.465, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5684/dense_40_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=nan, total=   0.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.503, total=   8.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.480, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.494, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=   8.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.529, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  6.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.468, total=   8.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=   9.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.497, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.503, total=   8.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.462, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.435, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.529, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   8.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.509, total=  10.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=  10.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.492, total=  10.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.500, total=  10.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.544, total=  10.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.547, total=  10.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.512, total=  11.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.526, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.553, total=  10.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.494, total=  10.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.541, total=  10.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=  10.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   0.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5717/dense_48_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.518, total=  10.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=  10.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.541, total=  15.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  6.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.518, total=  13.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.514, total=  13.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.497, total=  13.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.495, total=  13.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.550, total=  13.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.518, total=  13.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.556, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.518, total=  10.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=  10.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.489, total=  10.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.444, total=  10.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.492, total=  10.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.494, total=  10.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.535, total=  27.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.482, total=  12.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.486, total=  11.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.491, total=  11.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.474, total=  11.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.468, total=  10.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.542, total=  11.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.495, total=  11.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.480, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.505, total=  11.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.506, total=  10.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.486, total=  11.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.495, total=  10.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.503, total=  11.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.474, total=  11.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  11.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  7.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.509, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.477, total=  11.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.474, total=  10.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=  11.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=  11.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=  11.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.483, total=  10.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=  11.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.526, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.527, total=  12.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=  11.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=  11.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=  11.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.541, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=  11.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.529, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_11534/acc/Sum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=nan, total=   0.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.468, total=  12.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=  11.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.449, total=  11.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=  11.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=  11.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=  11.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.479, total=  11.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.529, total=  11.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.515, total=   9.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.529, total=  11.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.532, total=  12.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.526, total=   9.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  8.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.518, total=   9.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.483, total=   9.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=   9.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.544, total=   9.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5784/dense_55_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=nan, total=   1.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.515, total=   8.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.509, total=   7.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.505, total=   8.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.550, total=   8.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=  10.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.532, total=   9.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.503, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=   9.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.512, total=  12.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=  11.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.503, total=  13.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=  13.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.491, total=  12.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=  12.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.471, total=  13.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_58_23/MatMul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=nan, total=   1.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_11600/acc/Cast_3'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.471, total=   9.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.506, total=   9.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.523, total=   8.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.538, total=  24.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=   8.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=   9.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5808/dense_60_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.530, total=  10.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.462, total=   9.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed:  8.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.583, total=   9.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.530, total=   8.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.508, total=   8.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.500, total=   9.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.526, total=   9.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.524, total=   8.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.492, total=   8.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.553, total=   9.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5816/dense_62_loss/weighted_loss/Mul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=nan, total=   1.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.529, total=   9.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.518, total=  10.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.553, total=  11.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.518, total=   9.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.502, total=  10.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.562, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_70_16/Identity'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=nan, total=   1.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=  10.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.520, total=  10.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.529, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=   9.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   9.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   8.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.494, total=   9.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.453, total=   9.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.520, total=   8.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5834/dense_72_loss/Log'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=   9.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.500, total=  10.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=  10.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.506, total=   9.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  9.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.532, total=   9.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.474, total=   9.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.482, total=  10.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.505, total=  11.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=   9.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.535, total=  10.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   9.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.492, total=   9.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.488, total=  12.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.468, total=  12.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.500, total=  10.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.486, total=  12.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=  11.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.538, total=  10.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.512, total=  15.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=  15.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.512, total=  14.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.486, total=  13.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.532, total=  15.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=  15.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.500, total=  15.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.500, total=  11.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.486, total=  13.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.477, total=  11.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.492, total=  11.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.511, total=  28.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.509, total=  14.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.468, total=  15.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.547, total=  16.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.527, total=  13.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=  13.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.492, total=  13.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.503, total=  13.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed: 10.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=  13.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.495, total=  12.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.521, total=  11.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.502, total=  11.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5879/dense_82_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   1.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.541, total=  11.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.536, total=  13.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.523, total=  12.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.483, total=  12.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.488, total=  11.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.514, total=  11.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.500, total=  13.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.526, total=  13.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total=  13.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.506, total=  12.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.492, total=  12.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.544, total=  12.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.494, total=  14.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.523, total=  15.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.509, total=  13.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=  16.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.517, total=  13.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.544, total=  13.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.473, total=  13.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.511, total=  13.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.500, total=  11.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=  12.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.474, total=  10.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.459, total=  11.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.497, total=  12.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.459, total=  12.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=  11.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_11812/acc/div_no_nan/ReadVariableOp_1'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed: 11.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=nan, total=   1.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=  12.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=  11.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=  11.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.521, total=  13.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.453, total=  13.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.539, total=  12.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.517, total=  12.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.480, total=  12.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_11830/acc/Cast_3'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.506, total=  14.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=  19.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.517, total=  19.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.473, total=  16.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.495, total=  16.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.515, total=  18.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.495, total=  18.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.500, total=  16.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.495, total=  12.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.492, total=  12.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.503, total=  15.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.538, total=  15.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.480, total=  32.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.506, total=  14.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=  14.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.535, total=  16.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.489, total=  14.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.497, total=  16.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.538, total=  17.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=  18.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.526, total=  15.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.503, total=  15.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=  15.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.503, total=  19.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.495, total=  19.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.492, total=  19.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed: 12.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.524, total=  17.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.538, total=  16.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.532, total=  16.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.500, total=  17.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_5947/dense_100_loss/add'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.535, total=  17.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=nan, total=   1.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.456, total=  15.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.518, total=  13.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.498, total=  13.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.520, total=  13.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.518, total=  13.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  14.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.518, total=  16.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.480, total=  15.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.505, total=  14.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.497, total=  16.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.486, total=  17.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.583, total=  17.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.524, total=  15.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.541, total=  15.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.502, total=  15.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.521, total=  19.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=  20.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.521, total=  17.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.480, total=  20.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.523, total=  17.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.483, total=  16.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.497, total=  17.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.520, total=  17.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  14.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.509, total=  13.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.505, total=  13.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  13.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.476, total=  16.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.479, total=  13.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 13.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.480, total=  16.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=  13.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.465, total=  15.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.492, total=  18.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.524, total=  20.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.480, total=  21.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.488, total=  18.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.489, total=  18.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.483, total=  21.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.530, total=  22.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.508, total=  18.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.521, total=  16.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.488, total=  11.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.474, total=  19.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.517, total=  32.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=  10.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.495, total=  17.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.535, total=  16.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.477, total=  10.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.509, total=   8.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.486, total=   8.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.492, total=   8.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.503, total=   9.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.535, total=   9.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.474, total=   9.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.491, total=   8.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=   8.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.553, total=   8.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.527, total=  10.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.520, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.535, total=   9.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.500, total=   8.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.553, total=   9.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.556, total=   8.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.497, total=  10.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.529, total=  11.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.512, total=   9.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 669 tasks      | elapsed: 14.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=  11.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=   9.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.535, total=   9.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.518, total=  10.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.465, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.480, total=   9.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.470, total=   8.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=   8.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.468, total=   8.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.512, total=   9.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=   9.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.527, total=   8.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.520, total=   9.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.492, total=   8.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.471, total=   8.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.524, total=   9.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.498, total=   9.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.512, total=   8.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.532, total=   8.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total=  10.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=   8.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.512, total=  10.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  11.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.506, total=   9.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.480, total=  11.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.541, total=   9.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.483, total=   9.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=  10.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.515, total=  10.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=  13.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=  12.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=  11.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.497, total=  12.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  12.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=  11.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.477, total=  12.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=   7.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed: 15.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=   8.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.500, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.500, total=   8.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=   9.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=   9.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=   8.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.538, total=   8.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=  26.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.539, total=  10.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.500, total=   9.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.480, total=   9.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.526, total=   9.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.489, total=  11.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_128_19/MatMul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.489, total=  11.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.488, total=  12.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.492, total=  12.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=  12.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.508, total=  10.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.547, total=  10.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.494, total=  12.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.514, total=  12.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.486, total=  12.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.497, total=  11.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=  11.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.498, total=  11.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  13.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.494, total=  14.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.509, total=  12.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=  12.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.495, total=  14.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.508, total=  12.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.509, total=  14.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=  15.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.503, total=  13.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.505, total=  13.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.483, total=  13.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.474, total=  16.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.512, total=  14.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed: 16.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=  14.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.526, total=  12.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.506, total=   9.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.492, total=  10.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.471, total=  10.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.503, total=  12.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.485, total=  11.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.517, total=  13.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.523, total=  11.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.553, total=  13.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_12200/acc/div_no_nan/ReadVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=nan, total=   1.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.565, total=  11.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.512, total=  13.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.477, total=  13.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.503, total=  11.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.556, total=  14.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.538, total=  12.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.512, total=  19.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.489, total=  19.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.474, total=  19.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.509, total=  15.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total=  15.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=  16.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.477, total=  16.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.532, total=  10.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.485, total=  10.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6117/dense_142_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   1.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=  12.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=  11.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.529, total=  29.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.524, total=  14.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.483, total=  14.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.480, total=  13.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=  11.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.462, total=  11.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.515, total=  13.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.511, total=  13.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.500, total=  11.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.480, total=  14.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 17.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.480, total=  12.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.489, total=  12.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.509, total=  15.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.483, total=  15.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.444, total=  15.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.521, total=  13.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.474, total=  12.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.511, total=  12.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.514, total=  16.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.524, total=  16.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.506, total=  14.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=  13.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.514, total=  16.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_12284/acc/Greater'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_12287/acc/AssignAddVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.480, total=  14.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.512, total=  16.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.511, total=  16.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.527, total=  13.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.483, total=  16.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.533, total=  14.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.503, total=  17.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.495, total=  17.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.538, total=  17.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.474, total=  14.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.517, total=  14.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.503, total=  20.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.509, total=  17.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.502, total=  17.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.526, total=  22.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.535, total=  18.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.492, total=  22.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.500, total=  17.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.535, total=  17.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=  12.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.503, total=  13.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.526, total=  13.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.517, total=  13.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.500, total=  15.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.512, total=  14.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.541, total=  16.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed: 18.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.559, total=  16.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.517, total=  14.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.474, total=  13.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.518, total=  16.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.532, total=  17.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.509, total=  15.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.502, total=  19.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.483, total=  19.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.503, total=  23.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.553, total=  29.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_12362/acc/div_no_nan/ReadVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=nan, total=   0.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  25.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.509, total=  21.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.520, total=  21.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.544, total=  17.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.559, total=  26.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.494, total=  17.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6188/dense_159_loss/Mean'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.527, total=  13.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=  15.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.489, total=  13.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.474, total=  14.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.524, total=  14.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.533, total=  16.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6195/dense_160_loss/clip_by_value/Minimum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=  16.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=  14.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6198/dense_165_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=  14.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.524, total=  16.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.495, total=  17.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=  18.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.477, total=  16.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.509, total=  17.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=  15.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.515, total=  22.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=  22.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.495, total=  22.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.527, total=  10.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=  15.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_12420/acc/div_no_nan/ReadVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 19.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=nan, total=   1.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=  10.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.547, total=  10.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.512, total=  10.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.492, total=  10.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.553, total=  10.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.509, total=  10.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.505, total=  10.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=  12.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.474, total=  12.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   1.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_12440/acc/AssignAddVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.553, total=  10.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.503, total=  13.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.471, total=  15.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=  15.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.468, total=  14.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.474, total=  15.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=  17.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.497, total=  17.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.500, total=  11.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.529, total=  16.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.508, total=  11.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total=  11.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.476, total=  11.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.505, total=  11.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.506, total=  10.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.523, total=  10.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.468, total=  12.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.474, total=  10.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.497, total=  16.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.547, total=  16.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.497, total=  14.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.474, total=  16.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.544, total=  14.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.497, total=  15.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.498, total=  15.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.494, total=  11.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=  13.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=  13.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.556, total=  13.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.471, total=  28.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.518, total=  17.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.474, total=  17.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=  17.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed: 21.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.491, total=  12.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.468, total=  13.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.497, total=  11.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.468, total=  12.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.489, total=  10.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.529, total=   9.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=  10.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.444, total=  10.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.532, total=  10.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.470, total=  10.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.557, total=  13.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.489, total=  13.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  13.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.465, total=  11.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_12536/acc/Size'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=nan, total=   2.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.444, total=  10.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.485, total=  12.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=  11.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.494, total=  11.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.468, total=  16.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.477, total=  13.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.521, total=  18.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.491, total=  15.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.517, total=  15.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.480, total=  19.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.483, total=  18.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6280/dense_193_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=nan, total=   1.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  11.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=  11.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.515, total=  12.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=  13.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.541, total=  12.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=  13.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.509, total=  18.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.527, total=  14.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.511, total=  14.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=  19.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=  19.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6290/dense_188_loss/Neg'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=nan, total=   2.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=  13.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.494, total=  15.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=  15.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.518, total=  22.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 952 tasks      | elapsed: 22.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.508, total=  22.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.526, total=  23.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.497, total=  31.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.471, total=  31.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.509, total=  25.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=  25.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.529, total=  30.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_12608/acc/Cast_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.506, total=  17.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=  19.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.494, total=  13.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.523, total=  14.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.523, total=  16.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.498, total=  25.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.491, total=  19.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  19.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.515, total=  15.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.489, total=  12.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.556, total=  18.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.547, total=  13.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.527, total=  18.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  19.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.497, total=  20.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.511, total=  22.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=  25.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.568, total=  23.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.509, total=  25.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.535, total=  24.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.518, total=  21.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.498, total=  24.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.532, total=  19.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.500, total=  15.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.535, total=  14.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.530, total=  11.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.526, total=  19.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.526, total=  14.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.477, total=   9.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.447, total=  12.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.515, total=  14.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.483, total=  14.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=  14.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.480, total=  19.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=  20.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=  19.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.551, total=  19.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 23.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.505, total=  15.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.518, total=  19.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.498, total=  21.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=  23.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.477, total=  22.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=  21.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.509, total=  28.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=  28.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.562, total=  26.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.562, total=  17.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  18.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.497, total=  19.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=  18.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=  16.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.512, total=  15.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=  15.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=  14.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.515, total=  22.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.512, total=  23.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.520, total=  23.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.486, total=  23.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.523, total=  29.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.511, total=  34.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.474, total=  36.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.500, total=  37.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.489, total=  29.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.515, total=  26.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.508, total=  30.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.498, total=  30.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.527, total=  33.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.526, total=  33.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.506, total=  30.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.500, total=  19.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.468, total=  28.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.474, total=  36.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.553, total=  20.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.495, total=  28.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.547, total=  18.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.500, total=  13.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.517, total=  11.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.544, total=  15.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.521, total=  18.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.495, total=  19.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.571, total=  19.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.533, total=  26.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1042 tasks      | elapsed: 26.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  26.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.535, total=  26.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6390/dense_231_loss/clip_by_value/Minimum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=nan, total=   1.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.509, total=  30.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.517, total=  30.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.518, total=  27.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.517, total=  27.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  32.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.547, total=  28.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  33.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.511, total=  33.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.536, total=  27.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.523, total=  25.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.545, total=  21.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.483, total=  20.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.474, total=  20.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.529, total=  25.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.474, total=  15.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=  15.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.492, total=  13.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.476, total=  19.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=  19.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.508, total=  18.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.470, total=  25.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.489, total=  26.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  25.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_12828/acc/Identity'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.488, total=  30.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.511, total=  30.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.530, total=  26.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.495, total=  30.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=  28.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.505, total=  34.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.526, total=  38.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.477, total=  38.0s[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.500, total=  14.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.511, total=  15.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.491, total=  33.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.574, total=  10.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.502, total=  36.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.497, total=  10.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.523, total=  26.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=  10.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=  11.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.503, total=  13.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.550, total=  13.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=  14.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1089 tasks      | elapsed: 28.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.503, total=  12.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.489, total=  10.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.471, total=  10.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.509, total=  12.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.511, total=  12.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.503, total=  11.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.477, total=  12.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.471, total=  14.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.492, total=  12.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.494, total=  14.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.500, total=  17.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6446/dense_249_loss/mul_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.529, total=  19.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.471, total=  18.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.539, total=  12.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.474, total=  12.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.508, total=  14.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.471, total=  14.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.548, total=  10.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=  10.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=   9.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.497, total=  13.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.497, total=  11.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.480, total=  11.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.468, total=  14.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.477, total=  14.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.514, total=  10.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.497, total=  11.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  11.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.518, total=  11.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.532, total=  14.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.517, total=  13.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.535, total=  14.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.512, total=  18.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.494, total=  15.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.511, total=  12.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.480, total=  20.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total=  18.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.497, total=  11.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.480, total=   9.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.529, total=  12.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6476/dense_257_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=nan, total=   1.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=   9.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=  10.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.505, total=  10.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=  10.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.479, total=  17.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.515, total=  15.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 29.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.526, total=  15.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.574, total=  18.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.517, total=  14.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.468, total=  17.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.456, total=  17.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.480, total=  14.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.491, total=  14.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.495, total=  15.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total=  16.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=  15.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=  31.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.488, total=  12.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.480, total=  14.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.474, total=  12.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.477, total=  12.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.506, total=  14.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.511, total=  14.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.483, total=  14.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.509, total=  12.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=  12.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.559, total=  12.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.494, total=  19.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.468, total=  19.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.515, total=  16.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=  16.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.556, total=  16.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.553, total=  20.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.497, total=  20.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.511, total=  20.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.506, total=  21.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.474, total=  23.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=  25.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=  25.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.503, total=  28.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.468, total=  27.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.515, total=  22.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.553, total=  26.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=  19.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=  19.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.494, total=  15.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.492, total=  15.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.488, total=  12.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.514, total=  12.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.498, total=  14.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.511, total=  10.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.518, total=  15.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.483, total=  15.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.468, total=  15.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1185 tasks      | elapsed: 31.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.476, total=  20.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.492, total=  21.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.474, total=  20.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.503, total=  21.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  21.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.477, total=  20.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.518, total=  23.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.471, total=  23.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.538, total=  23.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.512, total=  26.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.509, total=  33.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.538, total=  32.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=  31.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.517, total=  23.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  21.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.517, total=  22.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.547, total=  24.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.476, total=  13.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.532, total=  12.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.520, total=  15.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=  11.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=  15.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.449, total=  15.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.511, total=  15.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=  16.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=  21.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.526, total=  21.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.527, total=  23.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.489, total=  23.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.474, total=  20.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.506, total=  19.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.474, total=  24.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.477, total=  24.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.530, total=  28.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=  26.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.518, total=  23.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.514, total=  21.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.483, total=  27.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=  20.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.515, total=  19.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=  17.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.512, total=  14.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.477, total=  13.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=  17.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=  14.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.527, total=  22.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.498, total=  23.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.521, total=  21.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.498, total=  21.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 33.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=  20.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.538, total=  27.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.506, total=  34.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.486, total=  32.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.532, total=  32.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.509, total=  28.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.517, total=  30.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.520, total=  31.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=  34.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.477, total=  33.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.497, total=  30.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.512, total=  20.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.517, total=  20.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.518, total=  14.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.489, total=  37.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=  30.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=  20.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.505, total=  29.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6598/dense_319_loss/Log'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   1.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.511, total=  12.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.517, total=  11.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.500, total=  28.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.502, total=  26.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.538, total=  26.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  31.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.532, total=  31.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.512, total=  40.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.495, total=  38.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.547, total=  42.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.506, total=  30.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.492, total=  31.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=  31.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.541, total=  36.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.503, total=  36.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.506, total=  31.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.505, total=  30.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.547, total=  37.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.483, total=  21.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.509, total=  22.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.482, total=  16.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.562, total=  28.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=  19.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.480, total=  12.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  12.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.458, total=  20.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.456, total=  21.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=  20.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.491, total=  27.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  28.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.465, total=  28.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.500, total=  32.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1285 tasks      | elapsed: 36.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=  31.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.494, total=  32.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.477, total=  35.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.489, total=  34.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.480, total=  34.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.491, total=   3.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.471, total=   3.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=  37.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total=  38.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.526, total=   3.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.503, total=   3.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.498, total=   5.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=  31.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.492, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.521, total=   5.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.538, total=   4.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.480, total=  37.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.505, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.492, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.486, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.491, total=   6.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.482, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  24.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=  24.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.495, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.508, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.560, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.497, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.492, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.486, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.503, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.532, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.517, total=   5.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.479, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.523, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.471, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.503, total=   5.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.468, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.506, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.489, total=  10.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.498, total=  10.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.538, total=  10.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.498, total=   9.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.464, total=   9.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.468, total=   9.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=   9.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.486, total=   4.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.497, total=   4.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1336 tasks      | elapsed: 37.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.468, total=   4.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.494, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.441, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.518, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.532, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.480, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.446, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.462, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.530, total=  25.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6694/dense_326_loss/mul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   0.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.503, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=nan, total=   0.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6696/dense_329_loss/mul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.529, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.462, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.503, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.489, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.497, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.526, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.532, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6714/dense_342_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=nan, total=   0.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.515, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.498, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.506, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.500, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.508, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.505, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.512, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.502, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.494, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.495, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.553, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.533, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.502, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=nan, total=   0.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6730/dense_344_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.483, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.474, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1389 tasks      | elapsed: 38.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.532, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.517, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.505, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.515, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.486, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.500, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.538, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.527, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.471, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.506, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.474, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.462, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.544, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.479, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6752/dense_330_loss/add_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=nan, total=   0.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=   7.4s[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.539, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.480, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.471, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.515, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.486, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.500, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.474, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.495, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=nan, total=   0.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6763/dense_348_loss/add_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.503, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.495, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.512, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.529, total=   6.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=  11.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.506, total=  10.9s\n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=  10.6s[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.538, total=  10.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.497, total=  10.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=  10.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.474, total=  10.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.468, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.426, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.518, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.556, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 39.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.518, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.492, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.553, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.500, total=   8.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=  28.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.502, total=   8.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.492, total=   8.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.518, total=   8.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.502, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.523, total=   8.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.494, total=   8.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=   8.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.580, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.506, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.492, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.527, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.521, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.568, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.502, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.489, total=   8.1s[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.479, total=   8.3s\n",
      "\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.474, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.482, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.505, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.473, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.468, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.476, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.465, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.568, total=   8.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.477, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.459, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.521, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.497, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.468, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.459, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.483, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.491, total=   8.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.483, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.503, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6831/dense_357_loss/add_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=nan, total=   0.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.523, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.468, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.532, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.530, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=   8.5s[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1497 tasks      | elapsed: 40.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.497, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.477, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.503, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.503, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=   8.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.518, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.505, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.477, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.500, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.509, total=  10.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.480, total=  10.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.505, total=  10.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.495, total=  10.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.502, total=  10.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.515, total=   9.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.489, total=   9.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.483, total=   4.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.500, total=   5.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.486, total=   5.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.536, total=   4.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.495, total=   4.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.471, total=   4.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.511, total=   5.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.497, total=   5.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.502, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.515, total=   5.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.532, total=   5.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.497, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.545, total=  22.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.468, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.494, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.465, total=   5.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.471, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_6886/dense_364_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   0.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.500, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.465, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.483, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.474, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.497, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.500, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.497, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed: 41.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.511, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.471, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.497, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.500, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.465, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.471, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.508, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.474, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.538, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.503, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.529, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.497, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.497, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.500, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.532, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.492, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.479, total=   6.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.517, total=   6.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.492, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.488, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.520, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.515, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.498, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.535, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.542, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.491, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.498, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.471, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.512, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.492, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.517, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.506, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.489, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.515, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.489, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=   6.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.502, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.497, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1609 tasks      | elapsed: 41.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.465, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.497, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.468, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.508, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.467, total=  12.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.483, total=  11.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.527, total=  11.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.471, total=  10.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.477, total=  10.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.503, total=  10.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.468, total=  10.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.459, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.506, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.468, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.468, total=   6.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.542, total=   6.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.438, total=   6.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.483, total=   6.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.509, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.492, total=  26.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.471, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.497, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.483, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.529, total=   6.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.491, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.503, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.468, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.529, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.515, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.520, total=   8.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.488, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.480, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.520, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.574, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.515, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.495, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.494, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1666 tasks      | elapsed: 42.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.508, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.495, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.521, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.511, total=   8.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.515, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.468, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.532, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.565, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.512, total=   8.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=   8.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.553, total=   8.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.474, total=   8.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.485, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.530, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=   8.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.474, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.520, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.500, total=   8.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.468, total=   8.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.509, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.453, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.508, total=   8.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.455, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.465, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.486, total=   8.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.500, total=   8.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.471, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.477, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.473, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.468, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.495, total=   8.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.458, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.477, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.483, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.491, total=  13.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.495, total=  13.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=  13.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.474, total=  12.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=  12.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.506, total=  12.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=  12.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   6.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=   7.0s[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.529, total=   7.1s\n",
      "\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.523, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.497, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.547, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.514, total=   8.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.509, total=  28.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.506, total=   8.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.520, total=   9.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=   9.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1725 tasks      | elapsed: 43.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=   8.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.477, total=   8.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.515, total=   9.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.529, total=   9.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.511, total=   9.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.488, total=   7.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.498, total=   8.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=   7.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.509, total=   8.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.503, total=   7.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.492, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.505, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.480, total=   9.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.544, total=   7.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.497, total=   7.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=   8.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.518, total=   7.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.520, total=   7.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.532, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.547, total=  10.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.497, total=  11.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.503, total=   9.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.471, total=  12.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_14190/acc/div_no_nan/ReadVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=nan, total=   0.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.544, total=  12.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.498, total=   7.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.509, total=   8.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.505, total=   9.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.541, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_7101/dense_392_loss/mul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.480, total=   6.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.468, total=   7.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.511, total=   7.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_14210/acc/div_no_nan'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=nan, total=   1.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.503, total=   8.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.523, total=   7.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.480, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.502, total=   9.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.532, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.518, total=   8.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.512, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.559, total=   8.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.498, total=   7.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.527, total=  12.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.494, total=  10.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.502, total=  12.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.535, total=  12.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.482, total=   8.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.505, total=   7.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.541, total=  10.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.495, total=  10.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.470, total=   6.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.492, total=   6.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.532, total=   6.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.550, total=   7.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.503, total=   8.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.535, total=   8.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 44.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.483, total=   8.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.480, total=   7.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.465, total=   7.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=   8.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.483, total=   8.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.491, total=   8.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=   8.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=   9.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.482, total=  17.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.536, total=  16.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.480, total=  16.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.483, total=  19.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.477, total=  16.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.511, total=  22.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.506, total=  18.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.511, total=  18.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.515, total=   6.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.474, total=   8.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.520, total=   7.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.535, total=   8.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.533, total=   9.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.521, total=   9.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=   9.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=   9.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.498, total=  11.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.492, total=  11.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.503, total=  10.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.474, total=   9.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.502, total=  10.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.512, total=   9.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.483, total=  10.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.502, total=  10.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.518, total=  15.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=  19.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.512, total=  19.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.491, total=  11.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.526, total=  11.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=  14.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.495, total=  14.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.529, total=  19.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.495, total=   9.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.515, total=   8.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=   8.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_7174/dense_410_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.492, total=   9.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_14354/acc/Sum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=nan, total=   1.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.506, total=   9.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.500, total=  11.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.523, total=  11.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.498, total=  10.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.489, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.479, total=   9.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.485, total=  12.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=  10.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.559, total=  11.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.480, total=  14.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.497, total=  17.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_7190/dense_406_loss/clip_by_value'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=-1)]: Done 1845 tasks      | elapsed: 46.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.520, total=  17.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=nan, total=   0.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.544, total=  14.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.500, total=  11.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.480, total=  11.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.477, total=  15.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.509, total=  15.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total=  14.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.500, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.489, total=   7.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=   6.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.515, total=   8.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=   8.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.524, total=  11.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.544, total=   8.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.462, total=  12.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=  11.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=  10.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.483, total=  10.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.485, total=   8.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.480, total=  10.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.477, total=  10.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=  21.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.485, total=  24.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=  19.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.489, total=  25.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.477, total=  19.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.477, total=  25.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=  18.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.503, total=  19.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.480, total=   8.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.524, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.541, total=  10.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.508, total=  10.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.521, total=  13.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.521, total=  11.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.502, total=  14.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_14454/acc/Identity'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   1.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=  11.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=  10.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_7229/dense_424_loss/clip_by_value/Minimum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   1.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.495, total=  15.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.521, total=  11.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.489, total=  11.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.538, total=  14.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.495, total=  13.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.506, total=  21.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.495, total=  19.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=  19.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=  26.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.494, total=  14.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.506, total=  27.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.492, total=  15.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.538, total=  27.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.500, total=   7.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.520, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.498, total=   9.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.517, total=  10.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.500, total=  10.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.500, total=  14.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.553, total=  15.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.520, total=  10.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.550, total=  11.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.514, total=  15.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1906 tasks      | elapsed: 48.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.515, total=  14.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.526, total=  10.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total=   9.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.512, total=   8.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.526, total=  13.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.514, total=  13.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  25.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.530, total=  21.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.524, total=  26.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.523, total=  20.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.541, total=  20.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.443, total=  15.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  15.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.474, total=  26.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   9.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.515, total=  10.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.462, total=  10.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.474, total=  13.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.494, total=  10.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.491, total=  14.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.520, total=  13.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.505, total=  13.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=   8.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   8.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.524, total=  13.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.479, total=  13.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.477, total=  15.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.465, total=  13.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.495, total=  13.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.511, total=  17.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.536, total=   8.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.465, total=   7.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.521, total=  23.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.511, total=  23.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.491, total=  10.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.471, total=  11.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=  26.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.583, total=  10.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.509, total=  26.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.495, total=  27.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.489, total=  26.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.533, total=   7.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=  14.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=   7.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.535, total=   5.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.515, total=   5.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.538, total=   7.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.544, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.503, total=   7.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=   9.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.509, total=   9.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.468, total=   9.9s[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.508, total=   8.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=   7.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.497, total=   8.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.526, total=  10.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=   9.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.506, total=   9.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.494, total=  11.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.498, total=  11.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.468, total=  13.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.471, total=   7.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed: 49.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.471, total=  11.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.470, total=   4.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_14631/acc/Cast_3'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=nan, total=   1.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_440_12/BiasAdd'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_440_12/Sigmoid'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=nan, total=   1.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   1.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_14640/acc/div_no_nan'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=nan, total=   1.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.468, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.480, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.497, total=   8.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.483, total=   7.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=   9.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.524, total=   7.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.508, total=   8.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.474, total=   7.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.498, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.512, total=  12.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=   8.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.538, total=   8.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.500, total=  12.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.511, total=  12.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.471, total=  12.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.474, total=  14.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.495, total=  14.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_14680/acc/Identity'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=nan, total=   1.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.529, total=   5.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.474, total=   7.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.506, total=   7.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.459, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   7.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.485, total=   9.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.529, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.529, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=   8.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.465, total=   8.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.509, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.541, total=  10.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.517, total=   8.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.495, total=   8.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.482, total=  10.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.477, total=   9.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.521, total=   9.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  10.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.483, total=  11.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  10.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.503, total=   8.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.505, total=  11.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.503, total=  12.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.553, total=  10.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.511, total=   6.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.508, total=   7.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.518, total=  14.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=  15.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.515, total=  13.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.508, total=  14.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.547, total=  15.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.509, total=  15.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  14.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.477, total=   8.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.512, total=   9.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.474, total=   9.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed: 51.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.502, total=   9.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.489, total=  28.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.500, total=  17.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.518, total=  16.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.521, total=  12.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=  20.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.486, total=  20.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.538, total=  15.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.517, total=  15.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=  10.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.505, total=   9.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.494, total=   6.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.489, total=   6.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=   7.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.515, total=   8.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.488, total=  11.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.517, total=   9.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.465, total=   9.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.544, total=  12.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.492, total=  13.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.506, total=  11.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.532, total=   8.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.502, total=   8.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.515, total=  10.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.505, total=  10.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.532, total=  11.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.497, total=  16.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.517, total=  14.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.503, total=  21.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.497, total=  12.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=  11.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.511, total=  22.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.559, total=  21.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_7410/dense_454_loss/Log'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=nan, total=   1.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.486, total=  14.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=   6.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.518, total=   6.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   8.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   9.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.495, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.509, total=  12.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=   9.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.462, total=  13.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=  12.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.494, total=  11.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.480, total=   8.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.545, total=   8.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.523, total=   9.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.505, total=  10.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.477, total=  10.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.455, total=  17.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  15.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.480, total=  14.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.476, total=  21.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=  22.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=  21.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.509, total=  14.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.517, total=  14.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.511, total=   8.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.515, total=   9.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.511, total=  10.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.550, total=  10.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.524, total=  11.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.500, total=  14.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.495, total=   9.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2097 tasks      | elapsed: 52.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.471, total=  15.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.532, total=  14.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.508, total=   9.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.503, total=  17.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  17.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.506, total=  17.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.505, total=  18.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.480, total=  18.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.556, total=  21.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=  30.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.503, total=  21.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=  19.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.494, total=  17.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=  17.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.495, total=  27.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.518, total=  37.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.550, total=  21.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.494, total=   8.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.468, total=  10.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=   8.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.535, total=   9.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.494, total=  11.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.518, total=  11.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  14.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.514, total=  11.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=  11.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.532, total=  15.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.512, total=  14.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.517, total=  14.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.515, total=   9.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.565, total=  12.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.511, total=  10.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.535, total=  12.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.500, total=  16.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.509, total=  25.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.523, total=  25.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.512, total=  23.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.477, total=  16.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.523, total=  23.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.553, total=  22.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.535, total=  26.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=   9.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.524, total=   8.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=   8.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=  11.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.521, total=  11.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.506, total=  15.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=  15.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.505, total=  15.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=  11.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.465, total=  11.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.467, total=  14.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.465, total=  11.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.453, total=   9.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.551, total=  12.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=  13.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.474, total=  14.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.482, total=   7.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=   7.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.515, total=   5.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.547, total=   8.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.500, total=  23.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  22.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.491, total=  30.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=  30.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed: 55.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  21.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=   6.4s[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.505, total=  29.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.471, total=   8.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.515, total=   9.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.506, total=  13.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=  12.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=  10.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.562, total=  10.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=  13.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.518, total=  12.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.474, total=   8.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.471, total=  17.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.520, total=  16.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.509, total=  16.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_7523/dense_495_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=nan, total=   1.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=  17.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.479, total=  10.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.518, total=  23.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.505, total=  10.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.505, total=  10.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.492, total=  27.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.471, total=  26.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_15060/acc/Cast_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=nan, total=   1.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.485, total=  29.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.486, total=  16.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.523, total=   8.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.453, total=   9.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.503, total=   9.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.506, total=  10.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.486, total=  10.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.471, total=  12.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.474, total=  13.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.477, total=  10.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.539, total=  10.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.505, total=  10.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.474, total=  11.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.515, total=   9.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.532, total=   9.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.550, total=  10.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.497, total=  10.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=   9.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.502, total=  22.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.497, total=  22.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.502, total=  21.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.506, total=  21.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=  18.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=   8.7s[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=  24.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.474, total=   9.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.535, total=   6.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   6.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.515, total=  10.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=  10.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=  10.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.506, total=  14.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.526, total=  14.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.459, total=  13.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.474, total=  12.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.485, total=  13.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dropout_233_10/dropout/random_uniform/mul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=nan, total=   2.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dropout_228_15/dropout/random_uniform/mul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=nan, total=   2.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=  11.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.488, total=  11.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.444, total=  15.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  19.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  19.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2229 tasks      | elapsed: 56.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.515, total=  20.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.509, total=  23.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.489, total=  22.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.500, total=  14.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=  14.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.544, total=  13.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.509, total=   9.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.511, total=  10.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.483, total=   9.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.527, total=  13.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=  13.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.498, total=  17.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.494, total=  17.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.480, total=  18.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=  13.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.512, total=  15.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.517, total=  15.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.500, total=  16.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.495, total=  19.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.526, total=  24.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.514, total=  24.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.497, total=  15.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=  15.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.488, total=  42.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.505, total=  41.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.477, total=  41.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.503, total=  41.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.508, total=  33.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.492, total=  33.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.515, total=  11.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.477, total=  12.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=   9.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.495, total=   8.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.512, total=  14.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.498, total=  14.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.556, total=  14.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.517, total=  18.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.530, total=  19.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.486, total=  20.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.503, total=  17.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.480, total=  17.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=  10.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.515, total=  17.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.535, total=  18.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.568, total=  19.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.500, total=  14.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=  14.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.515, total=  35.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.526, total=  31.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.515, total=  40.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.508, total=  40.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.547, total=  40.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.476, total=  11.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.553, total=  29.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.474, total=  13.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=   8.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.438, total=   8.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.485, total=  15.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=  15.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.542, total=  14.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.480, total=  15.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=  14.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.495, total=  19.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=  17.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.468, total=  17.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.518, total=  10.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.483, total=  13.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2296 tasks      | elapsed: 59.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.483, total=  15.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.465, total=  20.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.494, total=  19.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.524, total=  34.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.495, total=  32.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.497, total=  40.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.505, total=  21.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=  32.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=  40.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.492, total=  38.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=  12.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.503, total=   8.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=  11.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=  12.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.506, total=  17.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.502, total=  16.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.492, total=  16.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.508, total=  23.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.536, total=  24.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=  24.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.518, total=  25.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=  30.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=  27.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.521, total=  26.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.544, total=  27.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.465, total=  31.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.518, total=  21.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.492, total=  20.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=  58.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.480, total=  59.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.476, total=  46.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=  52.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=  20.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.491, total=  14.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=  45.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_7677/dense_554_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   1.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.495, total=  45.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_15358/acc/Sum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   1.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.492, total=  12.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.502, total=  12.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.518, total=  17.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.547, total=  17.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.547, total=  18.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.544, total=  21.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.503, total=  20.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.500, total=  26.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.541, total=  26.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.477, total=  26.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.523, total=  24.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.565, total=  24.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  20.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.509, total=  21.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.503, total=  50.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.532, total=  51.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.500, total=  15.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.518, total=  47.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.508, total=  47.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.532, total=  46.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.483, total=  52.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  20.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.550, total=  12.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.505, total=  10.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.521, total=  17.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.500, total=  18.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=  18.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.495, total=  18.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=  24.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.517, total=  24.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.477, total=  22.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2365 tasks      | elapsed: 63.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=  24.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_15424/acc/Identity'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=nan, total=   1.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=  23.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.542, total=  24.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.465, total=  24.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_7716/dense_554_loss/mul_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=nan, total=   1.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.462, total=  25.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.488, total=   6.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.520, total=  10.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=   9.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.520, total=   6.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.495, total=   7.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.515, total=  11.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=  10.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.515, total=  49.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.471, total=  10.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.527, total=  46.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  45.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.518, total=   8.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.492, total=  49.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=   6.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  38.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=   9.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.509, total=  11.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.530, total=  16.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.535, total=  17.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=  20.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.483, total=  17.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.471, total=  20.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.503, total=  25.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=  23.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.518, total=  11.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.492, total=  11.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.506, total=  18.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.462, total=   8.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.471, total=  19.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_15494/acc/Sum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=nan, total=   1.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.529, total=  30.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.471, total=  19.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.488, total=   8.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.489, total=   8.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.459, total=   7.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.509, total=   7.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.527, total=   8.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.505, total=  11.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.474, total=  13.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.474, total=  12.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.497, total=  11.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.495, total=  14.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.488, total=  14.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.550, total=  14.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.474, total=   7.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_7763/dense_593_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=nan, total=   2.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.538, total=   9.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.497, total=  13.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=  11.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=   9.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.521, total=  20.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.486, total=  23.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.506, total=  21.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.568, total=  21.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.520, total=   8.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=   9.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=   8.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=  25.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.491, total=   8.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.474, total=  11.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.506, total=  10.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.477, total=  10.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=  11.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 65.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.495, total=  13.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=  12.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.465, total=  12.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.474, total=  11.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.524, total=   9.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=   9.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.477, total=  10.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.470, total=  22.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.512, total=  16.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.495, total=  15.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.468, total=  21.9s[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.506, total=  22.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=  25.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.474, total=  19.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=  25.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_15592/acc/Cast_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=nan, total=   2.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.492, total=   8.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.506, total=  11.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.502, total=  11.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.505, total=  11.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.503, total=  14.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.514, total=  13.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.565, total=  12.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.512, total=  18.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=  18.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.514, total=  15.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.486, total=  15.7s[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.500, total=  16.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.515, total=  22.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.502, total=  24.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.486, total=  25.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.461, total=  15.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.511, total=  15.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=  43.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=  43.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.509, total=  40.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.527, total=  11.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.477, total=  43.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.492, total=  14.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.547, total=  33.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.544, total=  45.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=  11.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.511, total=  10.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.506, total=   9.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.524, total=  14.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.498, total=  14.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.495, total=  15.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=  18.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.532, total=  18.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.503, total=  17.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.486, total=  17.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total=  15.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_15666/acc/Cast_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=nan, total=   2.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.538, total=  15.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.521, total=  16.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.544, total=  21.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.500, total=  15.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=  14.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=  14.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.521, total=  35.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.517, total=  35.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.471, total=  34.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.512, total=  11.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.477, total=  12.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.508, total=  42.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.500, total=  42.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.483, total=   9.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.482, total=  14.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=  14.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.508, total=  14.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2505 tasks      | elapsed: 68.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.473, total=  18.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=  19.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=  20.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.464, total=  19.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=  17.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.483, total=  11.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.497, total=  11.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.459, total=  15.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.505, total=  20.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.497, total=  21.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.518, total=  36.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.505, total=  21.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.523, total=  34.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.532, total=  33.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.497, total=  42.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.480, total=  43.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=  42.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.556, total=  13.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.521, total=   9.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.511, total=   9.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.550, total=  13.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.509, total=  18.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.509, total=  23.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.471, total=  17.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.492, total=  17.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=  24.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_15751/acc/Cast_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   2.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=  25.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.509, total=  22.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=  18.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.492, total=  28.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=  36.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.535, total=  37.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.503, total=  22.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.517, total=  22.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.506, total=  58.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=  56.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.524, total= 1.1min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total= 1.1min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.471, total= 1.1min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.489, total=  47.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.494, total=  14.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.474, total=  17.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.526, total=  13.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.508, total=  13.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.524, total=  16.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  16.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.503, total=  22.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.480, total=  21.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.492, total=  23.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  17.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.512, total=  19.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.486, total=  20.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.491, total=  27.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.514, total=  28.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.477, total=  27.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=  33.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.515, total=  23.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.541, total=  22.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.509, total=  48.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.494, total=  57.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.520, total=  57.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.547, total=  55.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.476, total=  14.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.532, total=  13.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=  19.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.483, total=  14.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.529, total=  47.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total=  46.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.500, total=  20.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.477, total=  21.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 72.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.464, total=  16.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.477, total=  16.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=  16.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.514, total=  21.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.511, total=  24.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.506, total=  24.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.536, total=  20.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.517, total=  24.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.489, total=  21.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.500, total=   2.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.477, total=   3.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=  27.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.568, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.467, total=   2.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.505, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.471, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.509, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.502, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.471, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.506, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.483, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.491, total=   2.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.517, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.495, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.473, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.471, total=   2.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.520, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.503, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.480, total=   2.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.506, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.468, total=   2.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=   3.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.491, total=  57.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.495, total=  57.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.497, total=   2.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.468, total=   3.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.471, total=   4.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.468, total=   4.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.506, total=   4.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.515, total=  53.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.523, total=   3.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  52.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.453, total=  11.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.503, total=  11.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.471, total=  11.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.492, total=  56.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total= 1.1min\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.497, total=  10.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  10.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.488, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.474, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.476, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.529, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.517, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.529, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_7976/dense_661_loss/Mean'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=nan, total=   0.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.503, total=   4.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.497, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.471, total=   4.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.456, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=   5.7s[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.494, total=   5.3s\n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop [CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "\n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_15971/acc/Cast_1'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_15972/acc/Size'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=nan, total=   1.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=nan, total=   1.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.529, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.474, total=  22.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.535, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2649 tasks      | elapsed: 74.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=   5.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_15992/acc/div_no_nan/ReadVariableOp_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=nan, total=   0.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.500, total=   8.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.503, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.497, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.529, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   5.2s[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.468, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.527, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.486, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.514, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.503, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.486, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.502, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.512, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.489, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.506, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.492, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.502, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.515, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.500, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.517, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.498, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.508, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.494, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.536, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.477, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.497, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.468, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.476, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.474, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.492, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.497, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.538, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.508, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.524, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.477, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.480, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.497, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.468, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.503, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.468, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.535, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.474, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.473, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.532, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.506, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.532, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.471, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.474, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.503, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.474, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=   6.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2722 tasks      | elapsed: 75.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.468, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.474, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.515, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.532, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.520, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.494, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.532, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.474, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.464, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.532, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  11.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.517, total=  12.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.491, total=  11.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.511, total=  12.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=  11.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=  11.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.503, total=  10.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.508, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.547, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.500, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.495, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.495, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.518, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.514, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.517, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.503, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.512, total=  26.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.505, total=   7.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.517, total=   7.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.533, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.527, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.505, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8103/dense_687_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=nan, total=   0.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.508, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.505, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.502, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.512, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.471, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.532, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.492, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.503, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.477, total=   5.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.441, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.497, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.468, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.489, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.498, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.485, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.468, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.491, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.471, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.486, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.497, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.492, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.500, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.465, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.471, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.485, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.538, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.512, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.529, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.497, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.526, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.491, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.532, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.503, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2797 tasks      | elapsed: 76.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=   7.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8147/dense_682_loss/Mean'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=nan, total=   0.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.535, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.497, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.509, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.468, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.529, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.480, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.506, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.477, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.477, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.503, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.482, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.514, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.480, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.477, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.491, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.498, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.502, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.494, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.474, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.453, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8171/dense_695_loss/Neg'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=nan, total=   0.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.491, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.477, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.521, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.494, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.529, total=   5.2s[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.479, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.497, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.468, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.503, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.497, total=  11.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.468, total=  10.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=  10.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.441, total=  10.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.529, total=  10.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.497, total=  10.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.468, total=  10.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.459, total=   4.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.497, total=   4.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.468, total=   4.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.477, total=   4.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=   4.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=   4.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.523, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=   4.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.503, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.492, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.521, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.467, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.512, total=  26.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.532, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2872 tasks      | elapsed: 77.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=   5.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.489, total=   8.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.497, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=   5.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.532, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.509, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.506, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.492, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.512, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.526, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.524, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.514, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.541, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.512, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.503, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.541, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.517, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.498, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.506, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.486, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.486, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.554, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.541, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8250/dense_702_loss/add'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=nan, total=   0.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.506, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.476, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.529, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.544, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.512, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.459, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.497, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.532, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.471, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.497, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.497, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.532, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.486, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.529, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.482, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.502, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.506, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.483, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.523, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.527, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.459, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.520, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.532, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.535, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.503, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.535, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.491, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.444, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.526, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.526, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.509, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2949 tasks      | elapsed: 78.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.464, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.468, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8298/dense_704_loss/weighted_loss/broadcast_weights/ones_like/Shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=nan, total=   0.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.506, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.517, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.526, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.494, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.520, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.526, total=  12.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.495, total=  12.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.489, total=  12.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.524, total=  12.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.492, total=  12.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.480, total=  11.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=  11.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.556, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.491, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.502, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.474, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.503, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.508, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.547, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.509, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.494, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.468, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.532, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.515, total=  29.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.512, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.505, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.497, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.480, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8333/dense_706_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=nan, total=   0.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.465, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.524, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.468, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.497, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.453, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.494, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.541, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.456, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.503, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.517, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.547, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.535, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.512, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.535, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.503, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.520, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.512, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.503, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=   6.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.505, total=   6.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.503, total=   7.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=   7.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=   7.5s\n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=   7.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.468, total=   7.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.529, total=   6.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.524, total=   7.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.483, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3026 tasks      | elapsed: 79.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.506, total=   7.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.559, total=   7.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.550, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_16750/acc/Cast_3'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=nan, total=   1.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.509, total=   7.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_16755/acc/AssignAddVariableOp_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=nan, total=   1.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=   8.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.500, total=   7.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.471, total=   8.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.471, total=   7.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_16766/acc/Greater'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=nan, total=   1.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.518, total=   8.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.518, total=   9.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.498, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.559, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.535, total=   8.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.494, total=   6.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.550, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.498, total=   7.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.535, total=   7.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.482, total=   7.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.480, total=   7.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.477, total=   7.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.500, total=   7.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.508, total=   6.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.477, total=   7.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.503, total=   7.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=   8.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.497, total=   6.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.462, total=   8.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.505, total=   6.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.502, total=   7.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.515, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.517, total=   8.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.577, total=   8.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.559, total=   8.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.494, total=   9.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.474, total=   9.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.506, total=  16.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.495, total=  15.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.477, total=  15.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.505, total=  11.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total=  11.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=  11.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=  11.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   5.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.465, total=   5.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.523, total=   6.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   6.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.494, total=   6.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=   6.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.489, total=   6.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.497, total=   6.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.529, total=   6.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=   6.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8428/dense_730_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.485, total=   8.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.556, total=   8.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.468, total=   9.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.503, total=   8.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.512, total=  32.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.491, total=   9.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.505, total=   9.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.495, total=   9.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.479, total=   8.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.468, total=   8.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=   8.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.521, total=   9.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=   8.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.530, total=   6.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=   8.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=   7.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.541, total=   7.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=   8.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.515, total=   9.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.509, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3105 tasks      | elapsed: 80.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.514, total=   8.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.562, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.556, total=   8.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.512, total=  10.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.477, total=   9.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.509, total=  11.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.511, total=  11.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.535, total=  13.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.514, total=  13.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.533, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=  16.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=  16.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.471, total=  14.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.518, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.489, total=  10.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.508, total=   7.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=  10.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=nan, total=   1.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8467/dense_743_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.486, total=   6.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8470/dense_719_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   1.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.542, total=   6.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.514, total=   6.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_719_14/BiasAdd'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=nan, total=   1.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_16946/acc/div_no_nan'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=nan, total=   1.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=   7.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.524, total=   9.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.486, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.506, total=  11.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.568, total=  12.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=  11.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.508, total=  15.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.491, total=  12.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.515, total=  10.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  13.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.559, total=  13.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.497, total=   9.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.495, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total=  11.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.486, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.485, total=   6.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.541, total=   7.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.480, total=   6.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   6.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.491, total=   9.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.500, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=   8.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  10.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.470, total=  10.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.474, total=   9.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.509, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.465, total=  12.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.480, total=  12.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.505, total=  15.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.533, total=  11.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=  15.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.491, total=  16.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=  13.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.477, total=   8.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.477, total=   8.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.500, total=   9.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.483, total=  16.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.526, total=  15.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.500, total=  15.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.526, total=  15.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=  18.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.506, total=  16.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.508, total=  14.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.497, total=   5.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.492, total=   8.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=   9.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.474, total=  22.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.514, total=  16.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.503, total=  16.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.503, total=  20.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.511, total=  21.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 82.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.544, total=  20.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.486, total=  14.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.518, total=  17.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=  16.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.491, total=  14.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.476, total=  11.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.520, total=  11.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.485, total=   7.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.550, total=  10.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=  16.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.480, total=  18.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total=  15.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.514, total=   8.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.536, total=   9.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.526, total=   9.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.532, total=   9.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.509, total=  13.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.532, total=  13.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.538, total=  13.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.512, total=  13.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.544, total=  13.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.518, total=  16.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.483, total=  17.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.556, total=  16.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.529, total=  20.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.494, total=  20.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.508, total=  20.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.524, total=  15.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.535, total=  18.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.517, total=  10.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.520, total=  15.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.453, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.526, total=  15.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_17130/acc/div_no_nan/ReadVariableOp_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8566/dense_741_loss/add_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   1.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.489, total=  11.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=   7.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.482, total=   7.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=  11.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.465, total=  10.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.452, total=  16.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.483, total=  15.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.515, total=  20.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=  13.9s[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.474, total=  20.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=  21.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.509, total=  17.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.495, total=  17.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=   6.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.506, total=   7.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=   4.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.515, total=   3.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=  14.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.544, total=   4.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.471, total=   4.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.495, total=  17.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.465, total=  15.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.462, total=  15.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.495, total=   6.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.506, total=   6.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.523, total=   7.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.533, total=   6.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.520, total=   7.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=   6.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.530, total=   9.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.497, total=   9.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.465, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.562, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.495, total=   9.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.480, total=   9.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.512, total=   9.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=   8.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=   6.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.491, total=   6.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=  13.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.550, total=  13.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.497, total=  13.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.515, total=  12.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed: 84.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.474, total=  14.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.495, total=  11.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.456, total=  13.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.455, total=   6.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.535, total=   6.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.491, total=   6.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.492, total=   6.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.477, total=   6.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.462, total=   7.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8620/dense_780_loss/clip_by_value/Minimum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=nan, total=   1.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.497, total=   7.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.498, total=   8.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.509, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.544, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.498, total=  27.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.492, total=   9.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.480, total=  10.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.503, total=  11.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.527, total=   7.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=   7.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.494, total=   6.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.535, total=   7.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   7.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=   8.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   7.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.477, total=   7.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_781_10/MatMul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   1.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8639/dense_784_loss/Neg'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   1.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8641/dense_776_loss/clip_by_value'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=nan, total=   1.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.491, total=   7.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=   7.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=   7.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.492, total=   7.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.497, total=   9.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.518, total=  11.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.526, total=   9.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=   9.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.447, total=  11.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.467, total=  10.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.468, total=  10.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=   7.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.515, total=   7.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.468, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.495, total=   8.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.521, total=   8.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.511, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.503, total=  11.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.553, total=   6.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.511, total=  11.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.492, total=  11.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.509, total=   6.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.535, total=   6.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.527, total=   7.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.553, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.505, total=   8.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.508, total=  10.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.530, total=  12.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.542, total=  15.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.514, total=  10.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.511, total=  16.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.477, total=  15.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=  11.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=  12.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.468, total=  12.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.502, total=  10.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.476, total=   6.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.489, total=  12.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.500, total=  12.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.477, total=  10.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.488, total=  11.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.535, total=  12.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.511, total=   9.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.489, total=   5.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=   7.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.491, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.515, total=  10.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.462, total=   8.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.480, total=   8.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3346 tasks      | elapsed: 86.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=  11.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.492, total=  11.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.497, total=  11.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.498, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.477, total=  11.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.497, total=  12.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.526, total=  12.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.514, total=  12.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.536, total=  11.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.506, total=  16.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.538, total=  16.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.468, total=  14.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.517, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.465, total=   9.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.497, total=   9.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.498, total=  10.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.529, total=   6.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.509, total=  12.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.532, total=  12.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.508, total=  12.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.518, total=  13.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.541, total=  12.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=  13.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  15.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.480, total=   7.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.494, total=  11.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.468, total=  11.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=  14.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.505, total=  27.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.533, total=  13.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.450, total=  13.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total=  13.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.509, total=  14.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.477, total=  11.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=  10.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.515, total=   9.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.489, total=  12.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.580, total=  12.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.512, total=   9.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=   9.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.500, total=  14.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.514, total=  14.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.483, total=  13.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.480, total=   8.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.506, total=   6.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=   9.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.503, total=   9.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.523, total=  10.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.538, total=  14.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.512, total=  20.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.541, total=  21.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.547, total=  19.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.506, total=  15.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.520, total=  15.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.505, total=  14.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.509, total=  16.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total=  15.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.515, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.506, total=  13.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.489, total=  13.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.477, total=  12.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.508, total=  18.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.509, total=  18.8s[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.477, total=  19.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=  18.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.477, total=   7.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.541, total=   6.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.503, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.541, total=  10.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.500, total=  10.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.502, total=  10.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.526, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.568, total=  13.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.497, total=  13.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.485, total=  20.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.486, total=  19.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=  18.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=  15.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.547, total=  15.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.506, total=  18.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  17.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=  11.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=  11.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3429 tasks      | elapsed: 88.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=   7.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.512, total=  17.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.498, total=  17.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=  11.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.547, total=  17.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.495, total=  19.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   7.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.505, total=   7.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.446, total=  10.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.503, total=   9.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=   9.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=   9.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=  13.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  14.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.500, total=  18.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=  18.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=  16.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.491, total=  16.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.474, total=  16.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.520, total=  16.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.500, total=  19.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.480, total=  20.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.502, total=   7.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.509, total=   8.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.479, total=  21.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.520, total=  20.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.474, total=  24.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.518, total=  13.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.541, total=  13.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.474, total=  21.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.474, total=  14.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.503, total=   7.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.532, total=   8.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.506, total=   9.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.474, total=   9.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.562, total=  10.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=  10.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.512, total=  11.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.520, total=  10.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.550, total=  28.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.471, total=  11.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=  13.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.515, total=  13.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=  13.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.509, total=  18.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.505, total=  12.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.480, total=  18.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.512, total=  14.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.520, total=   8.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.476, total=   9.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.565, total=  18.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.538, total=  11.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.562, total=   9.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.474, total=   9.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.505, total=   9.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.497, total=   9.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.512, total=  11.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.500, total=   9.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.471, total=  11.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.508, total=  10.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.535, total=   8.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.492, total=   8.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.509, total=  14.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.468, total=  15.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.523, total=  14.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.548, total=  15.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.541, total=  14.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_17685/acc/Sum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=nan, total=   1.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=  17.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.511, total=  14.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.491, total=  16.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.491, total=   9.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=  11.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.485, total=  10.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.480, total=  11.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.526, total=  10.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.529, total=  10.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   9.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.506, total=   9.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=   8.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.506, total=  10.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.476, total=   8.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3512 tasks      | elapsed: 90.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.459, total=  11.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.453, total=  10.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  12.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.456, total=  10.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.485, total=  14.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=  13.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_17728/acc/Cast_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=nan, total=   1.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=  12.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.527, total=   9.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.489, total=  11.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.483, total=  11.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.477, total=  11.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.491, total=  12.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.461, total=  13.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.500, total=  12.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.495, total=  13.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  13.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=   8.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.521, total=   8.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=  11.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.468, total=  11.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.477, total=   8.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.486, total=  13.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.533, total=  16.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.527, total=  14.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=  21.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.538, total=  23.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x90 in position 0: invalid start byte\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   0.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.494, total=  25.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=  20.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=  32.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.512, total=  26.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.495, total=  21.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=  31.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.524, total=   8.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.512, total=  25.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.512, total=  30.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.483, total=  30.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=   8.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.474, total=  23.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.471, total=  29.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.480, total=   7.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.547, total=  17.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.524, total=   8.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.471, total=  10.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=  10.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.518, total=  14.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.526, total=  15.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.545, total=  12.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.498, total=  12.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.559, total=  15.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.502, total=  11.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.495, total=  13.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.521, total=  13.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.494, total=  22.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.514, total=  22.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.486, total=  22.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.532, total=  24.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8915/dense_867_loss/weighted_loss/broadcast_weights'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=nan, total=   1.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=  26.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.491, total=  27.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 1: invalid start byte\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=nan, total=   0.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.515, total=  22.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.474, total=  24.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.508, total=  10.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.526, total=   9.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.518, total=   9.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.489, total=   9.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.526, total=  19.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.494, total=  12.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.474, total=  20.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.482, total=  10.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=  13.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.505, total=  12.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=   8.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=   8.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_17863/acc/Mean'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=nan, total=   2.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.485, total=  19.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.548, total=  22.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.480, total=  23.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.465, total=  26.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=  26.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=  26.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.506, total=  28.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.495, total=  27.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3597 tasks      | elapsed: 93.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.515, total=  19.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.494, total=  13.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=  12.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.518, total=  10.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=  10.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_8946/dense_872_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=nan, total=   1.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  20.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.526, total=  14.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  20.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.483, total=  10.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=  11.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.518, total=  11.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.512, total=  12.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.489, total=  12.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.541, total=  14.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.517, total=  26.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.509, total=  27.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.488, total=  34.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.511, total=  34.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.532, total=  32.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.517, total=  27.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.497, total=  29.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.483, total=  27.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.491, total=  14.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.512, total=  15.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.474, total=  17.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.468, total=  25.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.492, total=  16.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.538, total=  11.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.524, total=  40.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.485, total=  16.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=  41.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.480, total=  41.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.477, total=  15.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.541, total=  45.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.483, total=  14.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.503, total=  11.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.523, total=   9.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.492, total=  10.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.512, total=  31.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.506, total=  34.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.517, total=  34.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.502, total=  32.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.492, total=  32.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.474, total=  36.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.515, total=  34.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  32.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   9.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.497, total=  15.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=  14.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.465, total=  12.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  11.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=  11.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.506, total=  33.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.508, total=  34.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.512, total=  16.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.526, total=  33.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.523, total=  35.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.489, total=  17.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   2.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_17998/acc/div_no_nan/ReadVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dropout_424_12/dropout/random_uniform/RandomUniform'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=nan, total=   3.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.500, total=  11.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  12.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.477, total=  10.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.503, total=  31.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.480, total=  31.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.483, total=  31.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_18016/acc/div_no_nan/ReadVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=nan, total=   1.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.459, total=  37.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop [CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.480, total=  37.1s\n",
      "\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.497, total=   8.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.553, total=   7.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=   8.2s[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.480, total=  39.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.527, total=  40.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.480, total=  37.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_18028/acc/Equal'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=nan, total=   2.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9017/dense_900_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=nan, total=   2.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.503, total=   9.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.518, total=  22.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.524, total=   9.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.505, total=   9.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  24.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.547, total=  13.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.503, total=  13.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.483, total=  13.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3682 tasks      | elapsed: 97.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=   6.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.524, total=   6.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=  15.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.509, total=  15.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.544, total=  15.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.474, total=  16.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.471, total=  18.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=  18.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.494, total=  19.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.471, total=  16.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.533, total=   8.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.553, total=  12.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.468, total=   8.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.505, total=  13.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.527, total=   9.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.477, total=  12.3s[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.479, total=  12.4s\n",
      "\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.538, total=   7.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.462, total=  11.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.483, total=   8.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.483, total=   9.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.491, total=  10.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.514, total=  12.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.536, total=  13.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.471, total=  13.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_18104/acc/AssignAddVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=nan, total=   1.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.509, total=  13.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.489, total=  13.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_18110/acc/div_no_nan'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=nan, total=   8.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.535, total=  16.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=  16.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.477, total=  19.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.494, total=   8.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=   7.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=   5.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.477, total=  23.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  26.1s[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   5.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   6.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.506, total=  31.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.474, total=  17.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.508, total=  27.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=   7.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.529, total=  11.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.491, total=  12.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.506, total=  10.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.477, total=  11.8s[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=  11.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.529, total=  14.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9073/dense_930_loss/weighted_loss/broadcast_weights'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=nan, total=   2.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=  10.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.530, total=  14.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.494, total=  15.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.474, total=  15.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.511, total=  15.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.480, total=  15.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.494, total=  16.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.465, total=  19.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.527, total=  20.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.477, total=  20.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9086/dense_906_loss/weighted_loss/Mul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=nan, total=   2.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.524, total=  10.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.508, total=  10.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=   9.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.506, total=   9.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.498, total=  10.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.477, total=  10.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.494, total=  14.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.515, total=  13.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=  15.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.511, total=  14.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.556, total=  16.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.550, total=  13.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.506, total=  20.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.498, total=  19.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.544, total=  18.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.502, total=  22.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.497, total=  22.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=  21.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.502, total=  27.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.512, total=  28.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.494, total=  10.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=  10.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.488, total=  23.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.474, total=  21.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=  25.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3769 tasks      | elapsed: 99.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.527, total=   8.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.465, total=  10.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.565, total=  19.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.498, total=   9.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.456, total=   9.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9116/dense_948_loss/weighted_loss/broadcast_weights/ones_like/Shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   2.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.497, total=  10.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.526, total=  12.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.465, total=  13.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.545, total=  12.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.541, total=  12.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.500, total=  19.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.517, total=  18.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.498, total=  25.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.491, total=  26.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.477, total=  26.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.523, total=  19.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.506, total=  22.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total=  22.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.468, total=  10.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=  11.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.529, total=   8.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   7.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.535, total=  22.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.447, total=  15.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.471, total=  14.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.477, total=  31.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.574, total=  31.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.497, total=  31.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.476, total=  17.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=  17.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.512, total=   7.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.453, total=   7.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=  11.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.529, total=  31.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.515, total=  23.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.471, total=  27.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=  23.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.459, total=  24.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.527, total=  28.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.477, total=  28.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.533, total=  21.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.471, total=  16.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.515, total=   8.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.506, total=  16.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=  15.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=  13.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.494, total=  25.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=  25.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  26.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.474, total=  28.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.495, total=  13.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.547, total=  13.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=  14.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.518, total=  14.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.491, total=  11.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=  14.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.483, total=  14.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=  17.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.503, total=  28.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.506, total=  34.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.526, total=  27.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=  35.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.517, total=  34.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.553, total=  28.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.515, total=  12.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.486, total=  11.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.526, total=  38.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.503, total=  39.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.521, total=  10.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.547, total=  10.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.505, total=  10.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=  14.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.483, total=  33.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.509, total=  32.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.486, total=  33.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.535, total=  32.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.533, total=  15.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.545, total=  18.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.526, total=  18.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.505, total=  19.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  17.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.480, total=  16.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.497, total=  26.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  27.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.518, total=  31.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.541, total=  31.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed: 103.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.553, total=  31.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.583, total=  35.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  39.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.521, total=  40.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.497, total=  13.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=  12.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.512, total=  34.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=  37.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=  10.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.462, total=  13.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=  11.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.571, total=  11.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.494, total=  14.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.544, total=  32.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.532, total=  33.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.462, total=  15.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.509, total=  12.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.523, total=  14.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=  12.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.535, total=  11.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.491, total=  22.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.551, total=  32.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.474, total=  32.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total=  32.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.456, total=  35.8s\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.462, total=  37.8s\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.542, total=  46.9s\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=  46.8s\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.492, total=  38.1s\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.530, total=  28.9s\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.514, total=  28.1s\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  28.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3888 out of 3888 | elapsed: 105.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.539024 using {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.502994 (0.014135) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.519996 (0.004621) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.510969 (0.032864) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.531004 (0.003120) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.485980 (0.014201) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.498013 (0.009502) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.519004 (0.030782) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.479998 (0.003950) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.479977 (0.019002) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.501993 (0.025012) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.502026 (0.024319) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.471010 (0.007928) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.494977 (0.018984) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.477969 (0.023130) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.498993 (0.020230) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.485998 (0.011126) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.499997 (0.024611) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.475991 (0.006846) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.501999 (0.022079) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.500003 (0.024611) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.535008 (0.010303) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.517994 (0.016485) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.516010 (0.022013) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.503992 (0.006738) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.517017 (0.012280) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.490988 (0.008578) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.519004 (0.018609) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.522016 (0.015817) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.497965 (0.027599) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.471001 (0.012278) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.502008 (0.045712) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.476998 (0.020892) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.499985 (0.016204) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.490976 (0.026874) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.494995 (0.003539) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498007 (0.025012) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.480978 (0.015616) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.493985 (0.016210) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.494015 (0.026708) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.509006 (0.014140) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.523014 (0.009998) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499002 (0.025784) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.481979 (0.014860) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.530009 (0.011711) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507001 (0.004956) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497003 (0.003238) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.504984 (0.021582) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498981 (0.025829) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.490997 (0.003249) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.472020 (0.019503) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.497980 (0.025180) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.486978 (0.015988) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.490976 (0.018040) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.482983 (0.017178) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.495972 (0.025406) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.500000 (0.025745) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.499997 (0.024611) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.482974 (0.018431) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.498001 (0.019628) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.513010 (0.011127) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497006 (0.023675) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.501004 (0.025900) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.489972 (0.020132) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498007 (0.005517) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.515024 (0.018048) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.488983 (0.014096) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.500965 (0.052740) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.511982 (0.024405) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.512989 (0.014505) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.510022 (0.019071) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.508985 (0.014429) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.489987 (0.013446) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.484970 (0.021249) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.498981 (0.021789) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.491956 (0.031310) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.488980 (0.016544) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.478988 (0.009268) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.489987 (0.045083) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.506012 (0.015933) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.479977 (0.016275) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.514967 (0.033818) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.497992 (0.028759) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.513010 (0.013111) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.519022 (0.015616) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.473992 (0.005819) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.478982 (0.012804) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.500998 (0.023336) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.515009 (0.009736) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.503980 (0.014175) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.531031 (0.021942) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500974 (0.022785) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.516016 (0.011907) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.503000 (0.025745) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.532005 (0.006070) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.510993 (0.022611) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.504957 (0.032749) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.490979 (0.016569) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.482977 (0.016994) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.496002 (0.013559) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.504993 (0.029835) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.494971 (0.022719) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.496976 (0.017352) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498996 (0.025900) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.499997 (0.024611) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.499005 (0.022348) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.498001 (0.024530) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.478982 (0.012804) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.466964 (0.027764) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.499002 (0.023336) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.502994 (0.007450) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.530030 (0.021270) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.530018 (0.016867) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.527033 (0.023478) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.521003 (0.014868) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.527030 (0.022097) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.523005 (0.024777) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.496979 (0.015040) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.476983 (0.023017) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.480999 (0.004958) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.484994 (0.011827) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.508967 (0.025279) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.495990 (0.007969) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.497995 (0.017524) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.486978 (0.015607) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.480978 (0.015616) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.502005 (0.017524) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.533006 (0.005647) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.500998 (0.023336) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.499997 (0.024611) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.463014 (0.009913) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.513034 (0.024067) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.523008 (0.005814) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.514997 (0.024609) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.521006 (0.016499) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.521018 (0.012804) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.526014 (0.010586) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.497995 (0.019931) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.497006 (0.023675) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.524995 (0.049163) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.526026 (0.021457) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.514991 (0.016018) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.527009 (0.025340) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.512024 (0.017365) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.472979 (0.016592) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.498996 (0.018606) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.503998 (0.023336) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.507025 (0.021506) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.486990 (0.011127) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.480993 (0.008878) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.518018 (0.015361) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.528016 (0.011923) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.502991 (0.011686) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.504004 (0.016187) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.489990 (0.009364) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.507999 (0.031883) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.514988 (0.015917) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.510007 (0.015525) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.521000 (0.015938) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.513978 (0.022247) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.521021 (0.015652) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.514008 (0.021599) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.496002 (0.020889) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.523014 (0.014839) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.484011 (0.018831) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.477978 (0.016735) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.495999 (0.029432) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.480993 (0.008878) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.511973 (0.024074) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.507001 (0.007391) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.496982 (0.014119) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.495996 (0.003085) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.525022 (0.015624) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.507001 (0.014729) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.513016 (0.017607) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.519016 (0.011395) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.496994 (0.004416) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.531007 (0.005559) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.496997 (0.031946) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.511994 (0.009564) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.516999 (0.009831) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.522025 (0.043035) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.521998 (0.015997) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.504984 (0.017591) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.508988 (0.018046) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.505008 (0.010279) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.499991 (0.009723) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.473998 (0.006299) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.495016 (0.014186) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.495972 (0.019823) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.498010 (0.013100) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.503974 (0.022781) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.516996 (0.016182) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.500012 (0.024788) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.495987 (0.009510) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.504001 (0.024530) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.526035 (0.025830) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.527000 (0.006130) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.536036 (0.025511) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.519022 (0.015616) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.520008 (0.010291) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.487970 (0.022077) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.474004 (0.006734) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.520008 (0.006766) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.496970 (0.022868) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.519996 (0.016181) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.517005 (0.010433) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.502991 (0.016025) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510004 (0.023466) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.484970 (0.021249) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.479983 (0.012037) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.481985 (0.010901) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.481979 (0.015061) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.480981 (0.013448) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.502002 (0.028233) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.505967 (0.023303) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.502002 (0.018444) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501013 (0.015319) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.498004 (0.011389) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.504007 (0.008867) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.499005 (0.006043) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.521012 (0.018066) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.496988 (0.015931) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.496994 (0.009573) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.506995 (0.017521) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.489984 (0.014203) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.524021 (0.020917) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.524039 (0.032488) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.515003 (0.031947) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.491980 (0.015411) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.525016 (0.011919) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.497995 (0.015130) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.505020 (0.019536) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.495972 (0.019823) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.501987 (0.015316) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.489990 (0.007977) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.478970 (0.026540) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.501981 (0.019912) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.516993 (0.004921) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.504999 (0.019628) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.501990 (0.013100) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.512009 (0.018309) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.507975 (0.024618) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.507004 (0.013781) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.515006 (0.014142) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.522022 (0.015620) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.515012 (0.009260) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.533033 (0.024489) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.500989 (0.018840) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.534016 (0.014230) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497989 (0.010702) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.526023 (0.023659) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.524015 (0.014463) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.496970 (0.022065) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.488965 (0.024740) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.505982 (0.012766) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.492978 (0.019067) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.499991 (0.009723) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.532005 (0.010440) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.519007 (0.025018) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.522013 (0.021672) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.499997 (0.022169) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.515018 (0.013257) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.509009 (0.008039) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.483007 (0.015513) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.500995 (0.019931) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.506009 (0.030104) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.504007 (0.029837) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.488992 (0.012404) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.519025 (0.026412) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.487970 (0.021244) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.475985 (0.010630) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.505008 (0.016912) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.492990 (0.036250) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.505949 (0.036761) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.459990 (0.011151) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.474990 (0.007204) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.494974 (0.018414) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.493002 (0.018443) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.528013 (0.009543) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.530021 (0.014877) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.522996 (0.009025) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.516999 (0.007387) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499002 (0.023336) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510001 (0.000721) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.509003 (0.010037) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.525034 (0.026463) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.517002 (0.023338) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.506980 (0.025173) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.525028 (0.030581) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.514005 (0.015134) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.525007 (0.005551) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.520020 (0.014626) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.484955 (0.034090) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.489001 (0.007388) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.488974 (0.019377) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.522972 (0.020086) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497980 (0.016533) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.528019 (0.023790) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510013 (0.037912) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517020 (0.014622) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.518006 (0.007467) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.516001 (0.004958) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.505994 (0.014133) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.487988 (0.010475) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.506992 (0.006734) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.508982 (0.024407) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.489984 (0.015805) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.533033 (0.023486) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.520020 (0.017948) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.531999 (0.002540) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.529008 (0.031173) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.516007 (0.005540) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.527009 (0.013828) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.528993 (0.005483) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.500956 (0.031297) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.489987 (0.011777) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.487017 (0.012955) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.499023 (0.016430) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.498010 (0.009351) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.506977 (0.017826) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.505014 (0.013099) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.528028 (0.032490) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.513016 (0.012874) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.527024 (0.019036) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.487985 (0.012913) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.496988 (0.018054) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.490988 (0.010471) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.500000 (0.023293) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.490997 (0.014865) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.505958 (0.029686) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.480984 (0.011911) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.497000 (0.013486) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.517020 (0.014622) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.523005 (0.008174) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.506995 (0.019929) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.511017 (0.014096) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.482986 (0.010574) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507004 (0.004644) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.519004 (0.004654) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.473977 (0.017006) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.488998 (0.006294) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.501990 (0.015222) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.479992 (0.005810) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.499994 (0.011820) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.530021 (0.020923) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.505011 (0.035197) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.532017 (0.017193) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.493997 (0.014865) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.517011 (0.007794) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.508005 (0.034510) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.517002 (0.003949) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.495001 (0.002550) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.504016 (0.011374) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.481005 (0.008148) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.489972 (0.020721) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500998 (0.018444) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.508991 (0.027708) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.520011 (0.012530) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.525013 (0.015339) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.516004 (0.003101) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.502026 (0.022788) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.500012 (0.018052) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.478029 (0.025196) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.496970 (0.022065) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.485980 (0.014201) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499970 (0.021227) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.505988 (0.013909) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.524009 (0.006392) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.506995 (0.022347) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.520994 (0.016484) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.515995 (0.012752) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.508002 (0.018445) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.515006 (0.004433) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.493979 (0.015632) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.509012 (0.012071) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.520008 (0.008357) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.514997 (0.003227) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.520020 (0.014209) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.518006 (0.021273) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.501996 (0.006749) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.530027 (0.019272) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.524018 (0.026554) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.507999 (0.019628) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.483001 (0.002545) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.475985 (0.010909) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.461003 (0.005321) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.496997 (0.014864) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.487994 (0.005625) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.487976 (0.017365) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.490994 (0.014140) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.496005 (0.022347) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.497995 (0.004302) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.521000 (0.013486) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.489999 (0.002556) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.494012 (0.009233) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.529970 (0.022020) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.491995 (0.004309) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.517014 (0.011656) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.491012 (0.022495) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.499997 (0.024611) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.497992 (0.006745) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.521992 (0.016900) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.485021 (0.026578) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.483987 (0.011784) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.468975 (0.021534) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.509992 (0.021590) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.460014 (0.010498) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.499002 (0.023336) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.521018 (0.012804) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.492990 (0.007179) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.497000 (0.023293) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.513010 (0.013111) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.513999 (0.012279) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.504004 (0.003085) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.509998 (0.006287) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.514020 (0.027253) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.505973 (0.020434) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.500986 (0.018756) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501987 (0.011764) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507007 (0.022617) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.490964 (0.025473) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.503998 (0.033131) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.473995 (0.003569) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.496958 (0.029900) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.489990 (0.011124) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.480978 (0.015616) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.478982 (0.012804) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.504993 (0.022613) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.501999 (0.024530) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.503998 (0.028232) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.479983 (0.012284) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.465963 (0.031309) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.537019 (0.015351) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.521003 (0.024613) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.497998 (0.003941) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.513996 (0.009029) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.534040 (0.035150) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.507001 (0.012281) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.539012 (0.020272) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.511991 (0.008016) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.481002 (0.006285) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.490008 (0.010268) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.468996 (0.003120) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.507031 (0.042810) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.479959 (0.028991) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.482986 (0.011656) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.496005 (0.012757) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.497995 (0.022349) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501999 (0.024530) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.510981 (0.027945) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.481985 (0.010901) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500998 (0.023336) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.499997 (0.024611) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.479977 (0.016275) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.484985 (0.011695) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.499982 (0.016835) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.497989 (0.012515) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.513969 (0.022016) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.495981 (0.013649) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.498999 (0.009833) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.500965 (0.026597) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.503006 (0.005615) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.520005 (0.008172) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.479983 (0.012284) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.476983 (0.012288) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.482983 (0.014103) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.487988 (0.012074) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.492996 (0.016188) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.518021 (0.014860) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.478979 (0.015065) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.489001 (0.014728) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.503006 (0.026093) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.499997 (0.024611) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.478982 (0.012804) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.499002 (0.023336) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.498001 (0.024530) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.501001 (0.024530) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.488986 (0.013106) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.496017 (0.015501) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507019 (0.013653) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.516001 (0.014730) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.533992 (0.006702) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.486996 (0.011394) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.506995 (0.010421) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.494989 (0.007777) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.513999 (0.009832) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.491995 (0.019933) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.490994 (0.016495) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.481014 (0.010526) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.491965 (0.024857) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.476974 (0.018763) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.480975 (0.017687) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.487946 (0.042362) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.505997 (0.027054) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501999 (0.024530) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.480978 (0.015616) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.507010 (0.017437) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.505002 (0.018444) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.516013 (0.011784) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.496005 (0.024772) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.480978 (0.015616) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.498001 (0.024530) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.504990 (0.017430) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.527039 (0.035328) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.508994 (0.009566) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.499005 (0.006043) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.499979 (0.022686) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.525010 (0.007204) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.529014 (0.025322) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.529017 (0.017190) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.495966 (0.024303) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.493008 (0.019235) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.492993 (0.017864) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.489981 (0.025836) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.469014 (0.013061) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.482983 (0.012280) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.479006 (0.011809) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.473015 (0.010839) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.484994 (0.011827) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.484976 (0.017019) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.500995 (0.024772) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.480978 (0.015616) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.498996 (0.021032) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.519022 (0.020596) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.498993 (0.020230) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.501004 (0.021032) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.520005 (0.010434) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.505017 (0.017166) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.493985 (0.011683) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.517014 (0.018769) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.522025 (0.020228) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.523005 (0.006062) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.504007 (0.029837) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.516013 (0.017355) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.495987 (0.011770) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.494992 (0.010279) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.505994 (0.005605) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.520994 (0.014127) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510016 (0.021593) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.512030 (0.028071) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498028 (0.025399) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.507004 (0.021033) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.477990 (0.009376) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.499002 (0.023336) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.486996 (0.003097) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.492010 (0.013095) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.497962 (0.026874) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.496991 (0.016028) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.523008 (0.008359) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.507975 (0.017818) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.521000 (0.003678) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.492990 (0.013107) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.498987 (0.011767) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.518006 (0.007467) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.513996 (0.013774) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.504013 (0.015321) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.497983 (0.012259) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.507007 (0.010988) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.519040 (0.032464) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.520023 (0.019002) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.507999 (0.024529) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.495996 (0.004641) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.492969 (0.025105) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.510996 (0.028337) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.493997 (0.007657) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.480996 (0.003105) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.483999 (0.004958) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.492990 (0.011121) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.496994 (0.011821) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.524000 (0.013486) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.505985 (0.010868) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.524003 (0.007664) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.515995 (0.019927) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.522016 (0.012885) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510004 (0.013781) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.495001 (0.002550) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.512012 (0.008582) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.522022 (0.022282) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.523023 (0.020380) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.526011 (0.009220) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.517005 (0.006057) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.507984 (0.023704) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.531001 (0.007394) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.473030 (0.023859) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.481967 (0.023465) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.505014 (0.011641) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.487994 (0.014141) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.503980 (0.019527) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.480001 (0.012278) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.509989 (0.009176) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.497989 (0.008151) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.490955 (0.031895) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.535044 (0.037464) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.528996 (0.006733) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.532017 (0.012301) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.494986 (0.018760) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.519016 (0.019554) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.497000 (0.023293) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.487994 (0.011826) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.486981 (0.014307) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.473003 (0.005327) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.498975 (0.020202) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.493982 (0.015347) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.493994 (0.016494) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.523020 (0.014630) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.479974 (0.019389) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.521018 (0.012804) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.501004 (0.030779) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.506998 (0.008696) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.480999 (0.002559) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.487967 (0.023328) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.520017 (0.023014) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507004 (0.003089) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.527009 (0.013828) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.503989 (0.010696) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.497989 (0.014516) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.495984 (0.015799) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.500000 (0.011034) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.524006 (0.009586) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.512992 (0.006727) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.488995 (0.004312) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.508020 (0.025185) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.498984 (0.023710) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.513007 (0.013226) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.517002 (0.011127) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.524021 (0.024614) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.500003 (0.012442) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.510013 (0.015326) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.489981 (0.019924) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.489987 (0.013446) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.499005 (0.017523) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.508964 (0.027709) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.481005 (0.012751) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.473018 (0.012736) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.512003 (0.003252) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.525010 (0.017447) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.501001 (0.024530) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.508985 (0.011664) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.522019 (0.023785) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.496991 (0.011690) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.508991 (0.009714) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.526023 (0.019009) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.491998 (0.018445) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.519025 (0.017856) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.518024 (0.017023) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.513996 (0.003062) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.531019 (0.023793) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.520005 (0.010434) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.522013 (0.010438) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.529017 (0.017190) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.503003 (0.022169) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498975 (0.021499) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.492987 (0.017348) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.486966 (0.024316) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.461995 (0.006075) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.508958 (0.031642) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.487997 (0.014866) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.488989 (0.007786) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.521039 (0.028012) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.505991 (0.025328) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.522016 (0.014216) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.537022 (0.019102) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.487970 (0.021244) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.519010 (0.007988) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.482998 (0.008701) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.496017 (0.012003) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.492990 (0.029071) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.489984 (0.011899) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.505967 (0.026331) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.532017 (0.014121) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.489993 (0.013225) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.507001 (0.004956) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.479983 (0.012284) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.503000 (0.025745) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.496991 (0.027711) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.499985 (0.020171) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.467983 (0.017193) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.489975 (0.018342) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.522022 (0.017780) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.500992 (0.012396) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.490997 (0.007659) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.527000 (0.001227) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.507996 (0.009031) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.513013 (0.010427) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.490002 (0.011122) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.500998 (0.006290) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.495999 (0.014729) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.497983 (0.012974) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.510981 (0.018167) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.522010 (0.024350) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.484982 (0.013257) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.539024 (0.021706) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.523008 (0.016921) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.531016 (0.015827) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.502002 (0.023336) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.466991 (0.020635) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.489004 (0.004629) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.497956 (0.031301) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.482986 (0.011656) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.488971 (0.021781) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.497000 (0.003678) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.501978 (0.015967) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.512018 (0.018546) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.514011 (0.008167) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.520985 (0.011649) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.499994 (0.005612) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.523005 (0.004326) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.509989 (0.032805) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.508994 (0.021266) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.498022 (0.019057) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.507990 (0.011108) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.495004 (0.004634) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.536018 (0.012825) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.506006 (0.026093) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.530027 (0.025690) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.506003 (0.019731) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.519001 (0.009835) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501993 (0.004942) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.518018 (0.022372) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.507987 (0.015311) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.498999 (0.002552) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.493991 (0.011693) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.489948 (0.036767) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.497971 (0.020488) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.501013 (0.013437) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.504990 (0.024339) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.525007 (0.004980) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500992 (0.021594) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.515986 (0.023059) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.518015 (0.010901) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.482977 (0.016271) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.490973 (0.022684) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.478991 (0.013824) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.501975 (0.021496) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.511023 (0.027413) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.503006 (0.026093) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.492972 (0.020717) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.505008 (0.019240) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.517014 (0.010574) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.486996 (0.009041) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.483978 (0.015992) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.480978 (0.015996) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.489966 (0.024312) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.468999 (0.000750) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.482977 (0.016455) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.499988 (0.008565) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.503998 (0.001866) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.527024 (0.026890) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500000 (0.011034) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.500986 (0.011634) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.522007 (0.015530) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.511002 (0.028233) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.488027 (0.020426) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507981 (0.016614) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.511005 (0.015133) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.505982 (0.012766) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.509006 (0.021271) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.534013 (0.009551) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.502982 (0.022355) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.479980 (0.014209) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.490979 (0.015048) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.499026 (0.024316) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.492010 (0.011108) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.478014 (0.009934) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.486990 (0.019706) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.487991 (0.006830) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.524006 (0.005637) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.519022 (0.026014) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.527006 (0.016501) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.522013 (0.013457) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.490982 (0.015351) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.507999 (0.012279) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.503980 (0.023187) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.502997 (0.010033) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.497995 (0.017524) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.509015 (0.012909) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.491989 (0.009198) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.527003 (0.002157) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.489978 (0.016719) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.494003 (0.014862) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.520026 (0.021450) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.525016 (0.011919) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.529014 (0.010590) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.497021 (0.024591) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.496997 (0.014864) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.472008 (0.005744) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.511005 (0.004312) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497962 (0.028184) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.485995 (0.010431) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.492978 (0.017762) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.515015 (0.038281) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.481014 (0.016707) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.493985 (0.016210) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.501996 (0.013778) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.501010 (0.011116) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.488015 (0.022286) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499997 (0.014863) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.498993 (0.022615) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.478982 (0.012804) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498993 (0.022615) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.475973 (0.020474) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.500003 (0.022169) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.507031 (0.022450) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497009 (0.022964) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.474978 (0.016739) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.497003 (0.024610) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.501001 (0.024530) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.503000 (0.025745) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.481979 (0.014860) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499002 (0.023336) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.480978 (0.015616) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.508982 (0.016825) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.496994 (0.007455) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.509998 (0.015999) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.499994 (0.005612) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.519004 (0.004654) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.502002 (0.003941) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.509015 (0.011687) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510975 (0.024615) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.492996 (0.018607) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.481005 (0.008148) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.514017 (0.017175) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.493970 (0.021236) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.477981 (0.013453) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.504001 (0.024530) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.507034 (0.024797) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.502997 (0.024610) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.481979 (0.015061) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498001 (0.024530) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.503000 (0.023293) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.501999 (0.024530) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.479983 (0.012284) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.522007 (0.006986) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.500006 (0.023676) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.489025 (0.030208) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.513001 (0.002557) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.509018 (0.013249) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.519016 (0.019554) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.496997 (0.002123) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.515998 (0.001854) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.508005 (0.006050) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.514982 (0.012753) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.512986 (0.009947) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.494983 (0.017166) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.473971 (0.025251) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.484988 (0.012077) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.483999 (0.012281) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.482992 (0.008354) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.501004 (0.009035) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.478979 (0.015065) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501999 (0.024530) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.474990 (0.007204) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.526014 (0.010586) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.518021 (0.015061) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.517026 (0.018431) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.523020 (0.014213) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.498001 (0.024530) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.505997 (0.019729) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.486981 (0.013440) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.498996 (0.013779) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.502020 (0.031540) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.497006 (0.004408) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.473980 (0.016562) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.494003 (0.014862) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.518024 (0.017023) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.497018 (0.022355) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.498001 (0.024530) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.514011 (0.010714) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.478982 (0.012804) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.493982 (0.037761) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.474978 (0.016005) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.480984 (0.011911) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.513010 (0.007980) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.494992 (0.019240) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.480978 (0.015616) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.489987 (0.011777) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.513993 (0.017856) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.490023 (0.029406) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.478982 (0.012804) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.501999 (0.024530) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.518009 (0.013822) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.504999 (0.009833) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.527015 (0.012930) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.526002 (0.011129) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.527015 (0.011710) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.506003 (0.007657) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.492987 (0.009193) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.534981 (0.018142) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.522016 (0.011400) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.488977 (0.021930) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.500003 (0.024611) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.484988 (0.010478) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.519022 (0.015616) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.485003 (0.012438) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.503998 (0.016000) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501975 (0.030216) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.521024 (0.017027) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.501999 (0.024530) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.500998 (0.025784) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.493991 (0.037326) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.514023 (0.016267) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.482974 (0.018431) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.468004 (0.003039) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.516010 (0.007984) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.513019 (0.013662) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.498975 (0.018330) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.525010 (0.022017) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.488998 (0.011126) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.517002 (0.003949) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.519016 (0.019554) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.491983 (0.012020) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498004 (0.025900) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.503992 (0.006738) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.480984 (0.012881) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.487964 (0.025477) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.497003 (0.034392) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.522019 (0.018201) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.503000 (0.025745) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.525013 (0.009539) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.518015 (0.011699) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.480978 (0.015616) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.504993 (0.025012) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.492990 (0.015228) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.491989 (0.014521) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.499997 (0.024611) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.518995 (0.027198) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.532026 (0.021465) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.502994 (0.023675) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.516999 (0.014727) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.509015 (0.018138) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.479998 (0.001892) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.494995 (0.012760) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.491989 (0.021103) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.501004 (0.003081) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.536021 (0.028684) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.509015 (0.035929) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.492987 (0.011774) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.518006 (0.014144) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498996 (0.021032) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.491995 (0.019933) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.491998 (0.001879) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.519022 (0.015616) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.503018 (0.037760) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.497006 (0.005608) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.482003 (0.012437) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.521000 (0.011034) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.527998 (0.011119) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.531016 (0.021608) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.526017 (0.020969) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.507996 (0.023463) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.511002 (0.001882) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.497983 (0.018992) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.514982 (0.018520) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.503986 (0.013090) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.513972 (0.022631) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.527021 (0.028677) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.525034 (0.027576) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.512998 (0.020888) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.511014 (0.020888) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.478994 (0.005634) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.476986 (0.009998) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.479980 (0.014209) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.483013 (0.015303) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.484976 (0.018048) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.477987 (0.009214) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.495963 (0.026143) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.506006 (0.021270) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.517017 (0.012033) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.495990 (0.015226) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.512015 (0.024487) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.519016 (0.017613) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.500998 (0.011124) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.505988 (0.018048) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.507016 (0.011895) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.515039 (0.030174) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.509024 (0.018040) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.526017 (0.012293) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.530995 (0.004264) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.528016 (0.012892) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.519001 (0.029432) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.512018 (0.016848) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.522999 (0.002543) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.503000 (0.011034) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.490002 (0.030681) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.483001 (0.012279) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.495981 (0.016628) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.468016 (0.012818) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499991 (0.006358) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.474978 (0.015624) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517011 (0.007794) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.509995 (0.029633) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.508002 (0.011125) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.533000 (0.011034) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.518989 (0.039988) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.490994 (0.007460) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.519007 (0.008878) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.517026 (0.024335) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.475979 (0.016588) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.502988 (0.008561) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.484029 (0.035839) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.486996 (0.006757) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.513016 (0.021595) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.491989 (0.009198) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.524998 (0.008692) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.499005 (0.024772) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.480984 (0.011911) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.476986 (0.009998) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497000 (0.023293) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.469002 (0.001838) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.492978 (0.019067) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501999 (0.007389) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.528007 (0.017873) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.517008 (0.012408) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.528001 (0.019630) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.509968 (0.026310) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.521992 (0.006717) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.494980 (0.019536) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.508008 (0.019242) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.492004 (0.013776) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.483007 (0.005498) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.500986 (0.009964) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.477987 (0.011790) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.490994 (0.009577) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.512015 (0.011691) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.503998 (0.028232) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.516981 (0.015284) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.497000 (0.025745) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.516007 (0.010994) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.497980 (0.019533) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.508005 (0.024774) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.491998 (0.018445) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.503971 (0.037887) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.490982 (0.013249) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.528013 (0.037918) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498999 (0.012280) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507996 (0.021031) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.520014 (0.013115) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.517014 (0.009989) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.533021 (0.015082) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.510004 (0.006756) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.500992 (0.016909) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.514005 (0.008168) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.490985 (0.011687) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.510996 (0.025898) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.537034 (0.026478) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.509009 (0.011695) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.488003 (0.003230) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.517020 (0.021314) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.506000 (0.008582) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.519007 (0.020236) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501999 (0.024530) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.492990 (0.015228) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.468022 (0.016664) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.483981 (0.013444) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.485986 (0.011652) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.495004 (0.018604) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.484985 (0.010897) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.491012 (0.020244) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.494986 (0.014822) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.536018 (0.013285) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.532029 (0.023913) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.502997 (0.022169) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500989 (0.021098) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.530015 (0.012934) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.518009 (0.034916) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.518006 (0.014144) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.519043 (0.034912) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.491995 (0.012761) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.496985 (0.018133) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.509009 (0.018308) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.489981 (0.016635) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.536989 (0.010662) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.491000 (0.015938) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.513028 (0.019836) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.482977 (0.016271) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.478973 (0.019722) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.461986 (0.010019) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.490005 (0.006035) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.499973 (0.019230) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.480019 (0.014263) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.491992 (0.016914) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.508988 (0.022495) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.533000 (0.003678) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.509983 (0.017151) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.515021 (0.015057) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.488977 (0.016986) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510999 (0.029431) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.505982 (0.018529) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.493970 (0.022069) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.534016 (0.017627) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.514970 (0.021206) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.515995 (0.015124) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.498004 (0.011389) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.478988 (0.008594) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.504990 (0.022004) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.497003 (0.005341) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.474993 (0.005551) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.483999 (0.014730) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.500995 (0.004298) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.489975 (0.018342) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517023 (0.016455) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.505988 (0.015924) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.514002 (0.020891) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.510022 (0.017765) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.514005 (0.003552) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.507010 (0.024344) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.508985 (0.020164) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.477987 (0.009535) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.514002 (0.018445) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.481997 (0.003258) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.506003 (0.012443) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.498993 (0.017862) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.501990 (0.007962) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.521006 (0.004441) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.513007 (0.008874) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498001 (0.026981) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.484988 (0.010478) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.490979 (0.016569) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.488986 (0.009981) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.495969 (0.021904) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.528031 (0.023138) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.511008 (0.026362) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.519996 (0.011383) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.507984 (0.025886) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.509000 (0.028197) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499005 (0.024772) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.529997 (0.019725) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.472994 (0.007474) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.510984 (0.030372) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.506971 (0.026718) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.485995 (0.003552) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.511002 (0.018445) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.496991 (0.013812) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.477984 (0.011400) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498001 (0.024530) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.516025 (0.017683) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.504999 (0.022079) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.492999 (0.014729) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.489963 (0.026607) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.494000 (0.011034) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.509986 (0.010538) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.531037 (0.026636) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.525010 (0.017447) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.516010 (0.019708) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.509012 (0.013922) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.515003 (0.012445) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.509021 (0.039663) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.480987 (0.011787) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.493967 (0.028955) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.495999 (0.024530) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.488998 (0.008700) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.513013 (0.009523) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.523017 (0.012288) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.516019 (0.041471) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.499997 (0.024611) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.471975 (0.020235) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.491015 (0.026706) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.478967 (0.024473) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.491965 (0.024857) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.481967 (0.023846) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.492960 (0.028293) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.487994 (0.004428) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.524018 (0.013269) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.519004 (0.021036) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.529011 (0.009223) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.502011 (0.021100) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.509003 (0.005347) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.527024 (0.020260) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.504001 (0.017178) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510001 (0.019629) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.494980 (0.014188) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.524003 (0.017298) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.524980 (0.016500) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.513981 (0.023757) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.534037 (0.035873) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.537019 (0.014339) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.505985 (0.024476) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.529017 (0.013009) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.476980 (0.014630) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.522025 (0.034332) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.492999 (0.024530) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.503995 (0.027201) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.469979 (0.015078) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497947 (0.037522) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.506965 (0.024836) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.508979 (0.019235) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100000\n",
      "800/800 [==============================] - 1s 1ms/sample - loss: 0.7559 - acc: 0.4988 - val_loss: 0.6900 - val_acc: 0.5500\n",
      "Epoch 2/100000\n",
      "800/800 [==============================] - 1s 692us/sample - loss: 0.7143 - acc: 0.5063 - val_loss: 0.7899 - val_acc: 0.4750\n",
      "Epoch 3/100000\n",
      "800/800 [==============================] - 1s 732us/sample - loss: 0.7039 - acc: 0.5375 - val_loss: 0.7499 - val_acc: 0.4750\n",
      "Epoch 4/100000\n",
      "800/800 [==============================] - 1s 732us/sample - loss: 0.7060 - acc: 0.5250 - val_loss: 0.6883 - val_acc: 0.5350\n",
      "Epoch 5/100000\n",
      "800/800 [==============================] - 1s 705us/sample - loss: 0.6971 - acc: 0.5250 - val_loss: 0.6910 - val_acc: 0.5350\n",
      "Epoch 6/100000\n",
      "800/800 [==============================] - 1s 714us/sample - loss: 0.6949 - acc: 0.5512 - val_loss: 0.6931 - val_acc: 0.4950\n",
      "Epoch 7/100000\n",
      "800/800 [==============================] - 1s 722us/sample - loss: 0.6910 - acc: 0.5537 - val_loss: 0.7247 - val_acc: 0.4700\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAcB0lEQVR4nO3de3iU1b328e/PgALiCYlsJGqwLx4QMLCjUFAUlJOoqIAisAVFKXsDHti+Ct19t7ae0IsqrdpNKSq8VaFIRahaDyjUAxQNiApGKgpCBCGCCCggCb/9xzzQgYRkEjJksub+XJfXzLPyzMxysuZmZc1a6zF3R0REwnJYdVdARESqnsJdRCRACncRkQAp3EVEAqRwFxEJUK3qrgBAw4YNPTs7u7qrIQFbtGjRN+6eeahfV21bkqmsdp0S4Z6dnU1eXl51V0MCZmZfVsfrqm1LMpXVrjUsIyISIIW7iEiAFO4iIgFKiTH3VLNr1y4KCgrYsWNHdVdFKqhOnTpkZWVRu3bt6q5KjaX2n3oq064TCnczOxaYBLQAHLgBWA78CcgGVgFXu/u30fljgCFAMXCzu7+acI1SQEFBAUcddRTZ2dmYWXVXRxLk7mzcuJGCggKaNm1a3dWpsdT+U0tl23WiwzK/AV5x9zOAs4F8YDTwhrs3A96IjjGz5kA/4CygO/A7M8tIuEYpYMeOHRx//PFq2DWMmXH88cerx3mQ1P5TS2XbdbnhbmZHAx2BJwDc/Ud33wz0AqZEp00Broju9wKmuftOd18JrADOrVCtUoAads2k31vV0PuYWirz+0ik534qUAg8ZWYfmNkkMzsSaOTu6wCi2xOi85sAa+IeXxCV7V/ZoWaWZ2Z5hYWFFa64iIgcWCJj7rWANsBId19oZr8hGoI5gNL+iSmxaby7TwQmAuTm5qb0pvLZo1+q0udbNbZnQufNnDmTq666ivz8fM4444wyzx0/fjxDhw6lXr16larT5MmTycvL47HHHtunfN68eRx++OG0b9++ws+5atUq5s+fT//+/cs9d/DgwVx66aX06dOHG2+8kVGjRtG8efMD1rVr166ceOKJFa6TVFx1tP+MjAxatmxJUVERZ555JlOmTKl0245vW/EOph1V5HOxZyFbw4YNad++PfPnzz/guffffz8///nPK1yf0iQS7gVAgbsvjI5nEAv39WbW2N3XmVljYEPc+SfFPT4LWFvZClZ1w0rEHy5vzK6CzUl7/o8SeO5WWccydepUzjvvPKZNm8bdd99d5vnjx49n4MCBlf4AHMi8efOoX79+pcP92WefTSjc402aNKnMn0+ePJkWLVoo3ANWt25dlixZAsCAAQOYMGECo0aN2vvZKS4uJiMjsa/yvv3+R77c+H2Jz93jv5/EEZmncNbuin9m/jT7FerVO5L6J5feAYm3q3g3y9Z+x3E7ajFh+stlfv7vve9+Lr3uP/Ypa5V1bIXrBwkMy7j718AaMzs9KroI+ASYDQyKygYBs6L7s4F+ZnaEmTUFmgHvVap2aWzbtm28++67PPHEE0ybNm1veXFxMbfffjstW7akVatWPProo/z2t79l7dq1dOrUiU6dOgFQv379vY+ZMWMGgwcPBuAvf/kLbdu2pXXr1lx88cWsX7/+gHVYtWoVEyZM4JFHHiEnJ4e3336bwsJCevfuzTnnnMM555zDu+++C8Df/vY3cnJyyMnJoXXr1mzdupXRo0fz9ttvk5OTwyOPPLLPc7s7I0aMoHnz5vTs2ZMNGzbs/dmFF15IXl4excXFDB48mBYtWtCyZUseeeQRZsyYQV5eHgMGDCAnJ4ft27cf9Hstqe38889nxYoVzJs3jyFXX8boETfSp0sHiouLefje/0f/np3p06UDzz39FBBrW/f/4v9yZed2jBh0NZs2lhz2ff2lWSz7aAljbh7K1d3OZ8f27Xzy0RJu6NOTfpdcyLABvSlc/zUAzzz5e67s3I4+XTpwx3/cwFdrVvPc00/xx0n/w9Xdzmfxwn174pu/3cTP+l/F1d078qvRtxJ/tbt2p2cBULj+a67vfQlXdzufqy76KYsXzmf8A3ezc8d2ru52PmNG3nTQ71ui89xHAs+Y2eHAF8D1xP5hmG5mQ4DVQF8Ad19mZtOJ/QNQBAx39+KDrmmaeeGFF+jevTunnXYaDRo0YPHixbRp04aJEyeycuVKPvjgA2rVqsWmTZto0KABDz/8MHPnzqVhw4ZlPu95553H3//+d8yMSZMm8dBDD/HrX/+61HOzs7MZNmwY9evX5/bbbwegf//+3HbbbZx33nmsXr2abt26kZ+fz7hx43j88cfp0KED27Zto06dOowdO5Zx48bx4osvlnjumTNnsnz5cj7++GPWr19P8+bNueGGG/Y5Z8mSJXz11VcsXboUgM2bN3Psscfy2GOPMW7cOHJzcyvz1koNUlRUxF//+le6d+8OwNIli/nznPlknXwKM56ZTP2jjuHZl97kx507GXRld37asTOfLvuIL79YwYzX32Vj4QauuqgdV1wzcJ/n7dKzF9Mm/4FRv7iHs85uza5duxj733cw/olnaXB8Q16Z/TyPPnQvv/r1Yzz1+Hhenr+Ew484gi3ffcfRxxxD34HXU6/ekQwaNrJEnSc88iCtz23HsFvv4K03XuXPz0wpcc7LL8yg/QWduenm2ykuLmbH9h9o07Y90yZPYvqrb1fJe5dQuLv7EqC0T9JFBzj/PuC+g6hX2ps6dSq33norAP369WPq1Km0adOGOXPmMGzYMGrViv3qGjRoUKHnLSgo4JprrmHdunX8+OOPFZ4PPmfOHD755JO9x1u2bGHr1q106NCBUaNGMWDAAK666iqysrLKfJ633nqLa6+9loyMDE488UQ6d+5c4pxTTz2VL774gpEjR9KzZ0+6du1aobpKzbV9+3ZycnKAWM99yJAhzJ8/nxY5bcg6+RQAFrw1l3/kL2POy7FBg61bt7B65ecsXjif7pf3JiMjgxP+pTHntO9Y7uut+vwzViz/lGH9rwRifyE3POFfAGh25lmMuXkonbpdQudu5X9fsHjhfB6e+EcAOl7UjaOPKTms0uLs1tx1+0iKioro1K0nZ5zVMoF3pWK0QjUFbf52E2+++SZLly7FzCguLsbMeOihh3D3hKZFxZ8TPz925MiRjBo1issvv5x58+aVO5a/v927d7NgwQLq1q27T/no0aPp2bMnL7/8Mu3atWPOnDkVqmNpjjvuOD788ENeffVVHn/8caZPn86TTz5ZofpKzRQ/5r5Pedx3Su7O6F89SIcL9+1jvjP39YpPHXTnJ6edwR9nvVbiR49N+ROLFs7nb6/9lYm/Gcfzbywo//nKef1/bdeBJ2e8xNtvvsZ/3fIzBg+7mcv69KtYncuhvWVS0OsvzeK6667jyy+/ZNWqVaxZs4amTZvyzjvv0LVrVyZMmEBRUREAmzZtAuCoo45i69ate5+jUaNG5Ofns3v3bmbOnLm3/LvvvqNJk9jM1ClTSv65uL/9n7dr1677zKjZ8wH8/PPPadmyJXfeeSe5ubl8+umnJR4br2PHjkybNo3i4mLWrVvH3LlzS5zzzTffsHv3bnr37s0999zD4sWLS62TpKf2F3TmuT8+ya5duwBY9cUKfvjhe9q0bc8rs5+nuLiYwvVf8/6C0oc56tWvz/ffbwMg+yfN+HbjN3y4KPb14K5du1ixPPb5+XrtV5zb/nxu/a9fsnXLd/zw/ffUO/Kfj91fm7bteXnmc0DsH5ot35X8AnVtwWoaNMykd/9BXNnv38hf+iEAtWrX2vv/c7DUc0/A7BEdDunrvTLrz9xz1y/2KevduzfPPvssjz76KP/4xz9o1aoVtWvX5qabbmLEiBEMHTqUHj160LhxY+bOncvYsWO59NJLOemkk2jRogXbtsUa4t13303fvn1p0qQJ7dq1Y+XKlWXW5bLLLqNPnz7MmjVr75e3w4cPp1WrVhQVFdGxY0cmTJjA+PHjmTt3LhkZGTRv3pwePXpw2GGHUatWLc4++2wGDx7Mbbfdtvd5r7zySt58801atmzJaaedxgUXXFDitb/66iuuv/56du/eDcADDzwAxKa2DRs2jLp165b6V0SizOw24EZiU3U/JvZdUj0C3VajshKdunuoXXXtdaxds5p+PS7A3Tnu+IaMn/Q0F3W/lPfefYs+XTpwStOfkNu29M9vr779uXfMKOrUqcP/f+E1xv1+Cg/+951s27qFouJiBg4Zximn/h9+fstQtm3Zgrsz8MZ/5+hjjuGCLt25/WeDmPfay4z+1YO0afvP2WTDbruTO4ffyDU9LiC3bQcaNyk5RJm34F0mT/gttWrXpl69I7l3/AQAevcfRN+u53Fmi1Y88OgfDur9sfhvcqtLbm6uH+iCBtU1FbLRyace8teNV9npTwL5+fmceeaZ+5SZ2SJ3z407bgK8AzR39+3RJICXgebAJncfa2ajgePc/c5oW42pxFZbnwjMAU4rb7JAWW07VZX2/qWKRKYRh2ZPFiTSruNpWEbSWS2grpnVItZjX0vg22pI+lC4S1py96+AccSm8a4DvnP31zjIbTVAW2tIalC4l8JxUmG4Siou0d+bmR1HrDfelNgwy5FmNrCsh5T2cgeow0R3z3X33MzMQ35N7iqh9p9aKvP7ULiX4svNuyj6YYsaeA2zZ9/rOnXqJHL6xcBKdy90913A80B7om01AJK5rUYqq1OnDhs3blT7TxEVbNd7abZMKR5d+C0jgVOO/QYrtcOWfPlbKzcDJN3tuWJNAlYD7cysHrCd2IK8POB7YttpjKXkthrPmtnDxHr6wW6rkZWVRUFBAak4pLT+2/TbbqL21roVadd7KdxLsWXnbu57a2O11iFVp5+FItrhdAawmNg2GR8Q26W0Pmm+rUbt2rVT9kpWPaph9lx1q2wWKNwlbbn7XcBd+xXvRNtqSAA05i4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuIiIBSijczWyVmX1sZkvMLC8qa2Bmr5vZZ9HtcXHnjzGzFWa23My6JavyIiJSuor03Du5e46750bHo4E33L0Z8EZ0jJk1B/oBZwHdgd+ZWUYV1lmkSpjZ6VGHZc9/W8zsVnVcJAQHMyzTC5gS3Z8CXBFXPs3dd7r7SmAFcO5BvI5IUrj78qjDkgP8K/ADMBN1XCQAiYa7A6+Z2SIzGxqVNXL3dQDR7QlReRNgTdxjC6KyfZjZUDPLM7O8VLwQr6Sdi4DP3f1L1HGRACQa7h3cvQ3QAxhuZh3LONdKKfMSBe4T3T3X3XMzMzMTrIZI0vQDpkb31XGRGi+hcHf3tdHtBmJ/tp4LrDezxgDR7Ybo9ALgpLiHZwFrq6rCIlXNzA4HLgeeK+/UUsrUcZGUVG64m9mRZnbUnvtAV2ApMBsYFJ02CJgV3Z8N9DOzI8ysKdAMeK+qKy5ShXoAi919fXSsjovUeIn03BsB75jZh8RC+iV3fwUYC3Qxs8+ALtEx7r4MmA58ArwCDHf34mRUXqSKXMs/h2RAHRcJQK3yTnD3L4CzSynfSOxLqNIecx9w30HXTiTJzKwesc7Jz+KKxwLTzWwIsBroC7GOi5nt6bgUoY6LpLByw10kZO7+A3D8fmXquEiNp+0HREQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKd0lrZnasmc0ws0/NLN/MfmpmDczsdTP7LLo9Lu78MWa2wsyWm1m36qy7SFkU7pLufgO84u5nELviWD4wGnjD3ZsBb0THmFlzoB9wFtAd+J2ZZVRLrUXKoXCXtGVmRwMdgScA3P1Hd98M9AKmRKdNAa6I7vcCprn7TndfCawAzj20tRZJjMJd0tmpQCHwlJl9YGaTzOxIoJG7rwOIbk+Izm8CrIl7fEFUJpJyFO6SzmoBbYD/cffWwPdEQzAHYKWUeYmTzIaaWZ6Z5RUWFlZNTUUqSOEu6awAKHD3hdHxDGJhv97MGgNEtxvizj8p7vFZwNr9n9TdJ7p7rrvnZmZmJq3yImVRuEvacvevgTVmdnpUdBHwCTAbGBSVDQJmRfdnA/3M7Agzawo0A947hFUWSVit6q6ASDUbCTxjZocDXwDXE+v0TDezIcBqoC+Auy8zs+nE/gEoAoa7e3H1VFukbAp3SWvuvgTILeVHFx3g/PuA+5JaKZEqoGEZEZEAJRzuZpYRTRd7MTrWKj4RkRRVkZ77LcRW7+2hVXwiIikqoXA3syygJzAprlir+EREUlSiPffxwB3A7riyg1rFp4UeIiLJU264m9mlwAZ3X5Tgcya0ik8LPUREkieRqZAdgMvN7BKgDnC0mT1NtIrP3ddVZhWfiIgkT7k9d3cf4+5Z7p5N7IvSN919IFrFJyKSsg5mEdNYtIpPRCQlVSjc3X0eMC+6vxGt4hMRSUlaoSoiEiCFu4hIgBTuIiIBUriLiARI4S4iEiCFu4hIgBTuktbMbJWZfWxmS8wsLyrTdtZS4yncRaCTu+e4+54rMmk7a6nxFO4iJWk7a6nxFO6S7hx4zcwWmdnQqEzbWUuNpwtkS7rr4O5rzewE4HUz+7SMcxPezhqYCJCbm1vi5yKHgnruktbcfW10uwGYSWyYZX20jTXazlpqKoW7pC0zO9LMjtpzH+gKLEXbWUsANCwj6awRMNPMIPZZeNbdXzGz99F21lLDKdwlbbn7F8DZpZRrO2up8TQsIyISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAyg13M6tjZu+Z2YdmtszMfhmV61JkIiIpKpGe+06gs7ufDeQA3c2sHboUmYhIyio33D1mW3RYO/rP0aXIRERSVkJj7maWYWZLiF204HV3X8hBXopMRESSJ6Fwd/did88hduWZc82sRRmnJ3QpMl1nUkQkeSo0W8bdNwPziI2lH9SlyNx9orvnuntuZmZmJaouIiIHkshsmUwzOza6Xxe4GPgUXYpMAhANOX5gZi9Gx5oFJkFIpOfeGJhrZh8B7xMbc38RGAt0MbPPgC7RMe6+DNhzKbJX0KXIJLXdAuTHHWsWmASh3MvsuftHQOtSynUpMqnRzCwL6EmsrY6KinsBF0b3pxAbhryTuFlgwEoz2zMLbMEhrLJIwrRCVdLZeOAOYHdc2UHPAtNkAUkFCndJS2Z2KbDB3Rcl+pBSykrMAgNNFpDUUO6wjEigOgCXm9klQB3gaDN7mmgWmLuvq8wsMJFUoZ67pCV3H+PuWe6eTeyL0jfdfSCaBSaBUM9dZF9jgelmNgRYDfSF2CwwM9szC6wIzQKTFKdwl7Tn7vOIzYrRLDAJhoZlREQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQpkIGKHv0S9VdhWqxamzP6q6CSMpQz11EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKdxGRACncRUQCpHAXEQmQwl1EJEAKd0lbZlbHzN4zsw/NbJmZ/TIqb2Bmr5vZZ9HtcXGPGWNmK8xsuZl1q77ai5RN4S7pbCfQ2d3PBnKA7mbWDhgNvOHuzYA3omPMrDmx662eBXQHfmdmGdVSc5FyKNwlbXnMtuiwdvSfA72AKVH5FOCK6H4vYJq773T3lcAK4NxDWGWRhCncJa2ZWYaZLQE2AK+7+0KgkbuvA4huT4hObwKsiXt4QVS2/3MONbM8M8srLCxM7v+AyAGUG+5mdpKZzTWz/Ghc8paoXOOSUuO5e7G75wBZwLlm1qKM0620pyjlOSe6e66752ZmZlZVVUUqJJGeexHwn+5+JtAOGB6NPWpcUoLh7puBecTa7HozawwQ3W6ITisATop7WBaw9hBWUyRh5Ya7u69z98XR/a1APrE/RTUuKTWamWWa2bHR/brAxcCnwGxgUHTaIGBWdH820M/MjjCzpkAz4L1DW2uRxFToYh1mlg20BkqMS5pZ/Ljk3+MedsBxSWAowMknn1zReotUhcbAlOgvy8OA6e7+opktAKab2RBgNdAXwN2Xmdl04BNif9EOd/fiaqq7SJkSDnczqw/8GbjV3beYlTb8GDu1lLJSxyWBiQC5ubklfi6SbO7+EbHOyv7lG4GLDvCY+4D7klw1kYOW0GwZM6tNLNifcffno2KNS4qIpKhEZssY8ASQ7+4Px/1I45IiIikqkWGZDsC/AR9H84EBfg6MReOSIiIpqdxwd/d3KH0cHTQuKSKSkrRCVUQkQAp3EZEAKdxFRAKkcBcRCZDCXUQkQAp3EZEAKdxFRAKkcBcRCZDCXUQkQAp3EZEAKdxFRAKkcJe0pesDS8gU7pLOdH1gCZbCXdKWrg8sIVO4i1D29YGB+OsDr4l72AGvD2xmeWaWV1hYmMxqixyQwl3S3v7XBy7r1FLKSr0+sLvnuntuZmZmVVVTpEIU7pLWdH1gCZXCXdKWrg8sIUvkGqoiodL1gSVYCndJW7o+sIRMwzIiIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBKjccDezJ81sg5ktjSvTlqgiIikskZ77ZGLbm8bTlqgiIims3HB397eATfsVa0tUEZEUVtkx94PaEhW0LaqISDJV9ReqCW2JCtoWVUQkmSob7toSVUQkhVU23LUlqohICit3V0gzmwpcCDQ0swLgLrQlqohISis33N392gP8SFuiioikKK1QFREJkMJd0pZWX0vIFO6Sziaj1dcSKIW7pC2tvpaQKdxF9qXV1xIEhbtIYrT6WmoUhbvIvrT6WoKgcBfZl1ZfSxDKXcQkEiqtvpaQKdwlbWn1tYRMwzIiIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAFO4iIgFSuIuIBEjhLiISIIW7iEiAkhbuZtbdzJab2QozG52s1xE5lNSupaZIypWYzCwDeBzoQuzCwu+b2Wx3/yQZrydyKFR1u84e/VJVVq9GWDW2Z3VXIW0kq+d+LrDC3b9w9x+BaUCvJL2WyKGidi01RrKuodoEWBN3XAC0jT/BzIYCQ6PDbWa2PEl1ORgNgW+q44Xtwep41SqRqu/ZKVXwEuW2a1DbLovadcVVtl0nK9ytlDLf58B9IjAxSa9fJcwsz91zq7seNUng71m57RrUtkNUE9+vZA3LFAAnxR1nAWuT9Foih4ratdQYyQr394FmZtbUzA4H+gGzk/RaIoeK2rXUGEkZlnH3IjMbAbwKZABPuvuyZLxWkqX0n9YpKtj3LKB2DQH/npKkxr1f5l5iyFBERGo4rVAVEQmQwl1EJEAK91JoiXnFmdmTZrbBzJZWd13kwNS2K6Ymt2uF+37ilpj3AJoD15pZ8+qtVY0wGehe3ZWQA1PbrpTJ1NB2rXAvSUvMK8Hd3wI2VXc9pExq2xVUk9u1wr2k0paYN6mmuohUJbXtNKJwLymhJeYiNZDadhpRuJekJeYSKrXtNKJwL0lLzCVUattpROG+H3cvAvYsMc8HptfgJeaHjJlNBRYAp5tZgZkNqe46yb7UtiuuJrdrbT8gIhIg9dxFRAKkcBcRCZDCXUQkQAp3EZEAKdxFRAKkcBcRCZDCXUQkQP8Lt2d+Wf9yCmsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.03       596\n",
      "         1.0       0.30      1.00      0.46       250\n",
      "\n",
      "    accuracy                           0.30       846\n",
      "   macro avg       0.65      0.51      0.24       846\n",
      "weighted avg       0.79      0.30      0.15       846\n",
      "\n",
      "Test accuracy: 0.305\n"
     ]
    }
   ],
   "source": [
    "historylist_3yr = []\n",
    "for i,params in enumerate(tqdm(test_params)): \n",
    "    bs = params.pop('batch_size')\n",
    "    model = create_model(**params)\n",
    "    params.update({'batch_size': bs})\n",
    "    history = model.fit(x_train_3yr, y_train_3yr,\n",
    "                        epochs=10000,\n",
    "                        batch_size=params['batch_size'],\n",
    "                        verbose=0,\n",
    "                        callbacks=[EarlyStopping(monitor='val_acc', patience=2, restore_best_weights=True)],\n",
    "                        validation_split=0.2)\n",
    "    historylist_3yr.append(history)\n",
    "max_acc_3yr = -1\n",
    "max_idx_3yr = -1\n",
    "for i,hist in enumerate(historylist_3yr):\n",
    "    if max(hist.history['val_acc']) > max_acc_3yr: \n",
    "        max_acc_3yr = max(hist.history['val_acc'])\n",
    "        max_idx_3yr = i\n",
    "    \n",
    "print(\"Best val acc:\",max_acc_3yr)\n",
    "print(\"For config: \",test_params[max_idx_3yr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = test_params[max_idx_3yr].pop('batch_size')\n",
    "model_ff_3yr = create_model(**test_params[max_idx_3yr])\n",
    "test_params[max_idx_3yr].update({'batch_size': bs})\n",
    "\n",
    "history_3yr = model_ff_3yr.fit(x_train_3yr, y_train_3yr,\n",
    "                               epochs=100000,\n",
    "                               batch_size = bs,\n",
    "                               verbose=1,\n",
    "                               callbacks = [EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)],\n",
    "                               validation_split=0.2)\n",
    "savename_3yr = \"nn_bs{}_n1{}_n2{}_dr{}_lr{}_opt{}\".format(test_params[max_idx_3yr]['batch_size'],\n",
    "                                                          test_params[max_idx_3yr]['nodes1'],\n",
    "                                                          test_params[max_idx_3yr]['nodes2'],\n",
    "                                                          test_params[max_idx_3yr]['dropout_rate'],\n",
    "                                                          test_params[max_idx_3yr]['learning_rate'],\n",
    "                                                          test_params[max_idx_3yr]['optimizer'])\n",
    "plot_results_nn(history_3yr,model_ff_3yr,x_test_3yr, y_test_3yr,save=True, name=savename_3yr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S&P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1296 candidates, totalling 3888 fits\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop [CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop [CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "\n",
      "\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.524, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.566, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.515, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.526, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop [CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=   7.2s\n",
      "\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.541, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.538, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.544, total=   6.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.509, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   14.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.587, total=   6.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.599, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.523, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.514, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.498, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   14.9s\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9248/dense_2_loss/mul_1'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9250/dense_2_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.517, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=   6.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.518, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.495, total=   6.9s\n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.539, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.553, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.505, total=   6.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   22.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.518, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.455, total=   6.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.532, total=   6.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.489, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.498, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.480, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.443, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=   6.8s[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.494, total=   6.6s\n",
      "\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.502, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.526, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.479, total=   6.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=   6.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.514, total=   6.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.550, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.512, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9275/dense_5_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9274/dense_6_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=nan, total=   1.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=nan, total=   1.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.488, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:   42.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.498, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.447, total=   6.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.517, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.551, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.511, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:   50.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=   6.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.509, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.488, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.524, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9300/dense_9_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:   58.8s\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_18603/acc/AssignAddVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=nan, total=   1.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.514, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=   9.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.521, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.557, total=   9.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.553, total=   9.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.535, total=   9.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.541, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.509, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.486, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.544, total=   9.3s[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.518, total=   9.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.514, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.500, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.532, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.503, total=   9.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.550, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.553, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.530, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.550, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.587, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.556, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.491, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.511, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.456, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.509, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.520, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.532, total=   9.8s[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   0.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9333/dense_12_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.557, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.502, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.508, total=   9.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.486, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.477, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.505, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.483, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.494, total=  16.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.560, total=  14.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  2.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.523, total=  14.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=  14.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total=  14.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.545, total=  14.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  14.7s[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.535, total=   7.6s\n",
      "\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.515, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.505, total=   9.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.541, total=   8.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.515, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.492, total=   8.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   8.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.485, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.511, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed:  2.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.479, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.512, total=  38.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.498, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.485, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.523, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.491, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=  10.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.488, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.502, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.542, total=  11.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.520, total=  11.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=  11.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.575, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.547, total=  14.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.544, total=  13.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.557, total=  14.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.532, total=  14.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=  14.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.569, total=  14.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=  14.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.556, total=  15.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.527, total=  14.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.535, total=  13.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9392/dense_20_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=nan, total=   1.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.559, total=  14.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.524, total=  13.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.562, total=  13.2s\n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.541, total=  13.2s[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "\n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.578, total=  13.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=  13.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed:  3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.548, total=  11.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.544, total=  11.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.538, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.497, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.535, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.495, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.524, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.535, total=  12.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.520, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.518, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.483, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.492, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.518, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.483, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.477, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.530, total=  13.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.502, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.471, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.485, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.505, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.514, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.461, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  12.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.511, total=  13.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.536, total=  11.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=  11.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=  11.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9425/dense_24_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=nan, total=   1.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.495, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=  12.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.527, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=  11.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.514, total=  12.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=  11.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.488, total=  12.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed:  4.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=  13.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.485, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.511, total=  11.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.498, total=  11.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=  12.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.485, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.526, total=   7.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.482, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=  11.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=   8.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.512, total=   7.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=  11.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.511, total=   8.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.520, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.548, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.535, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.566, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed:  4.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.538, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.560, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.532, total=  14.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=  14.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.566, total=  13.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.508, total=  13.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.538, total=  13.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.541, total=  13.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=  13.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.509, total=   5.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total=   5.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.512, total=   6.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.520, total=   6.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=   6.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.485, total=   6.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.492, total=   6.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.517, total=   6.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.506, total=   6.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=   6.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.498, total=   7.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.512, total=   6.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed:  5.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.477, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.426, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.482, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.486, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.508, total=   7.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.488, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.502, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.494, total=  35.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.486, total=   8.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.503, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.471, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.505, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.530, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.502, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.502, total=   7.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.458, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.511, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.515, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.524, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  5.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.495, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.482, total=   7.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=   7.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.512, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.512, total=   7.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.514, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.488, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.512, total=   7.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=   7.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=   7.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.572, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.526, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.551, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.538, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.566, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.538, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.511, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed:  5.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.556, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.581, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.523, total=   9.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.527, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.545, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.544, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.539, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.572, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.532, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.547, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.515, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.495, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.508, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.485, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.541, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.575, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  10.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.526, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.536, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:  6.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.517, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.508, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.509, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.511, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.535, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.551, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.477, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.465, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.479, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.532, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.508, total=  10.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.482, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.498, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.508, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.485, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.483, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.491, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  10.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.514, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.470, total=   9.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.511, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.488, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  6.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=  10.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.467, total=   9.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.480, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.450, total=   9.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.488, total=  10.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=   9.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.488, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=   9.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=   9.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.533, total=  18.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.511, total=  17.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=  17.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=  16.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.538, total=  17.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.554, total=  17.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=  17.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.527, total=  10.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.505, total=  10.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.562, total=  11.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=  11.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.491, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.514, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.550, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.569, total=  12.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.550, total=  14.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:  7.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.554, total=  41.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.556, total=  13.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.560, total=  12.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.547, total=  13.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=  13.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.578, total=  12.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.562, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.479, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.498, total=  12.4s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.508, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.521, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.508, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.544, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.533, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.544, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.483, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.509, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.486, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.526, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.500, total=  12.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.495, total=  12.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.465, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.512, total=  11.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.517, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.477, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.503, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=  12.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.477, total=  12.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed:  8.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.500, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.511, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.511, total=  11.8s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.515, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.512, total=  12.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.541, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.489, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=  12.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  12.1s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=  12.3s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=  11.9s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=  11.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=  12.6s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.488, total=  12.5s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=  12.2s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.511, total=  11.7s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.488, total=  12.0s\n",
      "[CV] batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.498, total=  11.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=  12.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.488, total=  12.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=nan, total=   1.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9660/dense_56_loss/clip_by_value/Minimum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=  13.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=  12.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.569, total=  12.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=  12.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.529, total=  12.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.548, total=  11.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  9.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=  13.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.526, total=  14.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.559, total=  10.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.538, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.563, total=  13.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.560, total=  10.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=  14.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=  10.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.508, total=  10.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=  15.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.521, total=  12.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=  11.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.514, total=  12.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.563, total=  12.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.495, total=  13.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.508, total=  12.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.551, total=  11.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.512, total=  18.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total=  18.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.562, total=  11.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=  16.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.544, total=  12.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.494, total=  13.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.541, total=  12.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.530, total=   8.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.568, total=   7.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=  11.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.535, total=   7.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.500, total=   9.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.535, total=  11.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.545, total=  11.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed: 10.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.523, total=  11.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  11.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.523, total=  14.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.539, total=   8.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.517, total=  15.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.560, total=  17.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.529, total=  14.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.535, total=  10.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.541, total=  10.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.557, total=  13.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.532, total=  13.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.529, total=  20.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.533, total=  21.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.529, total=  20.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.511, total=  24.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  20.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.476, total=  21.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.518, total=  16.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.520, total=  18.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.505, total=   9.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.468, total=   9.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=  13.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=  11.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.489, total=  11.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=  11.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.459, total=  16.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.526, total=  16.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=  15.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.521, total=  16.1s[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.527, total=  10.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.523, total=  10.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 10.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.532, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.474, total=  14.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.473, total=  13.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.517, total=  13.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.470, total=  13.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=  14.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.517, total=  13.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.474, total=  19.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.491, total=  13.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.505, total=  22.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.542, total=  23.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=  20.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.508, total=  15.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.526, total=  16.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.521, total=  21.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.538, total=  20.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=  15.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.554, total=  16.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.523, total=  20.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.520, total=  15.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.560, total=  17.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.482, total=  27.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.535, total=  28.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=  19.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=  19.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.544, total=  26.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.488, total=  31.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.571, total=  30.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.548, total=  20.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.547, total=  20.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.508, total=  20.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.529, total=  21.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.566, total=  23.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed: 12.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=  30.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.512, total=  13.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.523, total=  20.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=  15.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.538, total=  15.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.560, total=  20.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.548, total=  16.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.520, total=  16.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.523, total=  21.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.547, total=  22.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.526, total=  15.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.557, total=  16.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=  16.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.572, total=  27.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.547, total=  27.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.523, total=  17.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.541, total=  25.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.554, total=  25.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.538, total=  25.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.560, total=  19.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.526, total=  20.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.550, total=  20.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.491, total=  23.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.544, total=  21.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.494, total=  13.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  29.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.562, total=  19.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.523, total=  13.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.492, total=  14.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.494, total=  21.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.506, total=  17.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.511, total=  16.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.538, total=  15.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=  22.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed: 13.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.495, total=  22.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.518, total=  26.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.515, total=  17.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total=  17.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.544, total=  26.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9802/dense_92_loss/Log'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=nan, total=   1.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.517, total=  18.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.538, total=  27.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.545, total=  29.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.529, total=  28.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.524, total=  20.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.538, total=  20.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.577, total=  30.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.527, total=  30.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.517, total=  29.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.530, total=  20.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.480, total=  35.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=  26.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.544, total=  31.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.521, total=  34.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.581, total=  25.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.568, total=  25.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.562, total=  34.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.538, total=  20.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=  33.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.560, total=  22.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.479, total=  37.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=  37.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.538, total=  23.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.517, total=  23.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.489, total=  35.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.485, total=  37.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=  38.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.509, total=  28.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.517, total=  28.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 597 tasks      | elapsed: 15.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=  28.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9833/dense_101_loss/clip_by_value'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.563, total=  33.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total=  40.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.541, total=  31.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.536, total=  19.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.556, total=  28.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.514, total=  22.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.566, total=  29.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=  29.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.575, total=  22.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.541, total=  22.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.535, total=  22.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=  28.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.566, total=  35.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.521, total=  24.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.532, total=  25.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.544, total=  35.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.532, total=  26.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.532, total=  38.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.551, total=  41.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.508, total=  41.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.557, total=  28.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total=  28.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.550, total=  28.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.533, total=  33.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=  19.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=  30.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  45.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.529, total=  20.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.511, total=  29.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.523, total=  20.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.527, total=  28.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.517, total=  28.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 17.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.563, total=  22.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.547, total=  22.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.523, total=  21.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  28.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9870/dense_107_loss/add_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=nan, total=   0.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.587, total=  24.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.515, total=  40.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.523, total=  39.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.526, total=  25.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.538, total=  25.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.520, total=  38.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.566, total=  13.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.571, total=  14.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=  12.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.550, total=  43.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.483, total=  43.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.503, total=   8.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.574, total=   8.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.554, total=  29.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.523, total=  29.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.517, total=  29.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=   9.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.572, total=  10.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.494, total=  15.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=  10.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.526, total=  15.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.523, total=  15.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9893/dense_117_loss/Neg'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.538, total=  11.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.515, total=  14.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.502, total=  13.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  11.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.527, total=  12.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.553, total=  13.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.554, total=  11.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=  12.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.530, total=  18.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 669 tasks      | elapsed: 19.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=  11.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.502, total=  19.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=  18.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.533, total=  11.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.505, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.485, total=   8.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.480, total=  11.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.565, total=  10.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.544, total=  10.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.503, total=   9.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.517, total=   7.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.554, total=  15.7s\n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.538, total=  15.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.532, total=  14.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.532, total=   9.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.515, total=   8.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.533, total=  21.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.514, total=  19.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.559, total=  19.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=  20.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.505, total=  25.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.524, total=  23.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total=  22.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.500, total=  11.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.523, total=  11.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.553, total=  23.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.532, total=  13.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=   9.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.495, total=  14.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=  14.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.520, total=   8.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_9933/dense_117_loss/Mean'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=nan, total=   1.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   9.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=  12.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.467, total=   9.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.527, total=  10.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.535, total=  10.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 706 tasks      | elapsed: 20.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.492, total=  10.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=  14.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.476, total=  10.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.500, total=  16.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.495, total=  16.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.541, total=  17.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.559, total=  11.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=  12.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.506, total=  15.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.538, total=  15.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.483, total=  15.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.458, total=  12.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.541, total=  13.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.523, total=  13.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=  20.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.509, total=  14.1s[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.569, total=  20.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.568, total=  15.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.480, total=  15.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.520, total=  19.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=  20.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.560, total=  20.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.550, total=  16.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.521, total=  16.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.562, total=  16.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=  21.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.563, total=  18.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.545, total=  28.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.532, total=  29.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.550, total=  19.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=  19.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.553, total=  29.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.548, total=  31.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.502, total=  32.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.527, total=  23.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.517, total=  22.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=  23.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.584, total=  24.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.544, total=  33.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 745 tasks      | elapsed: 21.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.556, total=  24.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.518, total=  16.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.544, total=  18.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.498, total=  18.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.541, total=  25.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.584, total=  20.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.554, total=  29.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.532, total=  19.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  18.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.541, total=  32.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  32.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.488, total=  31.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.575, total=  18.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.553, total=  19.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  31.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.526, total=  28.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.529, total=  21.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.550, total=  32.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.542, total=  33.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.551, total=  23.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.541, total=  23.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.511, total=  23.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=  22.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.492, total=  22.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.508, total=  33.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.527, total=  15.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=  14.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.495, total=  15.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  21.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.485, total=  21.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=  14.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.474, total=  20.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.495, total=  14.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.505, total=  21.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=  14.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.506, total=  16.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.556, total=  17.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.554, total=  26.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.556, total=  27.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 23.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.511, total=  18.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.483, total=  26.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.527, total=  30.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.508, total=  30.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.515, total=  21.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.538, total=  21.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.532, total=  21.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.529, total=  32.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.557, total=  39.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.514, total=  38.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.521, total=  28.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.495, total=  28.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.559, total=  28.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.480, total=  36.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.572, total=  35.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.527, total=  19.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.544, total=  19.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.553, total=  37.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.565, total=  19.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.483, total=  28.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.548, total=  22.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.572, total=  37.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=  22.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  37.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.544, total=  22.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.483, total=  37.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.479, total=  39.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.550, total=  39.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.548, total=  30.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.553, total=  30.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.486, total=  30.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.527, total=  33.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.538, total=  31.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.527, total=  20.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total=  46.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.495, total=  30.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.547, total=  22.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.553, total=  22.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.530, total=  29.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.575, total=  23.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.532, total=  29.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 825 tasks      | elapsed: 26.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.565, total=  23.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.514, total=  30.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.547, total=  22.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.533, total=  26.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.571, total=  26.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.541, total=  26.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.566, total=  42.8s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.562, total=  43.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  41.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.572, total=  44.4s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.532, total=  44.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.515, total=  29.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total=  29.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.517, total=  28.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.536, total=  32.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.517, total=  31.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.515, total=  21.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.520, total=  49.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.495, total=  22.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  29.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.495, total=  24.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.467, total=  31.7s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  31.3s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.512, total=  24.9s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.511, total=  24.6s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.459, total=  31.5s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.508, total=  24.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.512, total=  26.1s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.512, total=  44.0s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.538, total=  26.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.477, total=  44.2s\n",
      "[CV] batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.511, total=  27.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.474, total=  42.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.566, total=  13.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.520, total=  13.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.569, total=  49.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.523, total=  48.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=  13.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.509, total=  10.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.527, total=  34.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.535, total=  33.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 866 tasks      | elapsed: 28.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.556, total=  34.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.559, total=  11.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.538, total=  10.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.563, total=  15.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.532, total=  50.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.502, total=  20.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.482, total=  21.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.511, total=  21.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.502, total=  20.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=  20.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.581, total=  29.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=  26.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.514, total=  27.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.524, total=  25.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=  28.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=  28.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=  31.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.498, total=  31.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_20236/acc/AssignAddVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=nan, total=   1.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.488, total=  24.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total=  30.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.502, total=  24.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.506, total=  16.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.535, total=  16.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.535, total=  23.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=  12.2s[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.497, total=  13.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_10127/dense_177_loss/clip_by_value'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   2.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.523, total=   8.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.548, total=  28.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.536, total=  28.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.498, total=  30.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.535, total=  30.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.538, total=  29.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.488, total=  40.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.514, total=  38.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=  42.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.569, total=  22.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=  22.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.517, total=  25.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.488, total=  30.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  30.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.485, total=  15.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 909 tasks      | elapsed: 31.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.488, total=  24.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.505, total=  15.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.547, total=  24.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.532, total=  30.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=  12.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=  24.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dropout_69_27/dropout/mul_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=nan, total=   1.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.535, total=  15.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=  11.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.505, total=  10.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.482, total=  13.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.508, total=  19.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.468, total=  18.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.494, total=  19.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.580, total=  19.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.497, total=  23.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.523, total=  28.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.544, total=  30.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.509, total=  31.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=  24.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.550, total=  25.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.494, total=  30.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.532, total=  30.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.506, total=  28.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total=  28.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.532, total=  28.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.489, total=  32.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.569, total=  25.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=  24.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.563, total=  20.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.544, total=  25.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=  24.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=  25.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.536, total=  30.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=  29.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.514, total=  29.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.551, total=  31.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.559, total=  31.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=  29.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.569, total=  43.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.498, total=  53.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.521, total=  54.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.568, total=  45.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 952 tasks      | elapsed: 33.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=  52.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.483, total=  46.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.476, total=  54.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.505, total=  54.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.563, total=  25.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=  26.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.506, total=  18.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.538, total=  25.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.527, total=  46.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.562, total=  46.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.508, total=  45.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=  53.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.526, total=  20.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.505, total=  20.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.551, total=  31.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.523, total=  31.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.532, total=  30.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.547, total=  31.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.518, total=  32.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.547, total=  30.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.560, total=  56.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.556, total=  56.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.563, total=  43.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.556, total=  44.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.520, total=  53.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.526, total=  47.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.485, total=  57.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.553, total=  57.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.509, total=  27.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.541, total=  25.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.563, total=  45.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.509, total=  19.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.550, total=  44.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.502, total=  52.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.523, total=  26.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.541, total=  44.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.538, total=  21.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.559, total=  22.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.494, total=  38.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  37.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=  38.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.518, total=  38.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.526, total=  37.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.547, total=  36.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.488, total= 1.0min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 37.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.512, total=  43.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.526, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.562, total=  44.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=  45.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.511, total=  53.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.545, total=  50.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.532, total=  52.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.554, total=  37.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=  37.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.521, total=  29.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.524, total=  48.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.544, total=  37.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.483, total=  49.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=  48.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=  57.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.535, total=  31.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.556, total=  32.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.497, total=  40.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=  40.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.514, total=  41.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.553, total=  43.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.548, total=  44.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=  45.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.560, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.485, total= 1.3min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.532, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total= 1.3min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.535, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.535, total= 1.3min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.560, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.544, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.560, total=  37.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.535, total=  37.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.533, total=  27.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.523, total=  37.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.563, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.556, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.526, total=  30.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.514, total=  30.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.560, total=  46.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.532, total=  44.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=  41.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.568, total=  42.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1042 tasks      | elapsed: 42.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.536, total=  44.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  41.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.545, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.544, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.521, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.538, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.553, total= 1.3min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.511, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.569, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.574, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.467, total=  37.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.489, total=  37.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.533, total=  28.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.505, total=  36.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.506, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.553, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.538, total=  31.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.498, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.508, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.483, total=  32.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.533, total=  44.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.456, total=  43.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.505, total=  44.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.575, total=  43.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.529, total=  42.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.495, total=  42.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.533, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.524, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.535, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.526, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.568, total= 1.3min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=  15.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.488, total=  16.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.545, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.553, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.590, total=  12.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=  16.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.498, total=  12.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=  12.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.515, total=  18.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.495, total=  17.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.515, total=  18.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.523, total=  19.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.539, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.553, total= 1.3min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.505, total=  23.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1089 tasks      | elapsed: 47.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.553, total= 1.3min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.508, total= 1.5min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.514, total=  24.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.535, total=  35.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.485, total=  37.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.548, total=  23.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.502, total=  39.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=  24.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.520, total=  25.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.502, total=  27.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.488, total=  28.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.560, total=  16.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=  15.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.500, total=  13.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.560, total=  26.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.498, total=  15.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=  27.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.532, total=  28.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.489, total=  31.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.489, total=  13.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.495, total=  13.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.524, total=  18.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.474, total=  18.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.535, total=  18.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.547, total=  18.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.518, total=  18.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=  17.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.557, total=  29.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.489, total=  29.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=  26.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.502, total=  24.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.512, total=  24.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.502, total=  27.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.502, total=  30.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.542, total=  31.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.524, total=  17.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  14.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.560, total=  26.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.518, total=  12.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=  30.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.508, total=  27.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=  27.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.480, total=  17.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=  12.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.483, total=  11.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.527, total=  16.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.508, total=  15.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed: 49.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.446, total=  18.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  20.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=  19.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=  19.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.509, total=  30.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.492, total=  29.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.449, total=  24.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.505, total=  29.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.556, total=  28.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.514, total=  28.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total=  33.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=  34.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.533, total=  27.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.508, total=  27.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.492, total=  32.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.544, total=  25.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.515, total=  25.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.544, total=  25.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.551, total=  20.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=  25.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.535, total=  21.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=  22.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.523, total=  30.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.491, total=  31.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.550, total=  30.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.560, total=  31.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.495, total=  30.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.541, total=  29.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.521, total=  56.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=  56.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.551, total=  47.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.580, total=  47.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  56.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.532, total=  49.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.524, total=  59.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total= 1.0min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.515, total=  26.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.562, total=  26.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.503, total=  19.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.541, total=  25.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.502, total=  47.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.491, total=  49.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=  47.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=  57.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.526, total=  22.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=  22.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.551, total=  38.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  38.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.548, total=  39.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1185 tasks      | elapsed: 52.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.505, total=  40.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.532, total=  37.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.538, total=  38.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.581, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.542, total=  44.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.544, total=  45.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.505, total=  45.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.508, total=  54.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.575, total=  55.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total=  56.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.542, total=  26.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.474, total=  26.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.467, total=  20.2s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  26.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.491, total=  47.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.502, total=  47.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  57.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.517, total=  47.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.517, total=  21.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.489, total=  21.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.542, total=  31.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.511, total=  29.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.508, total=  30.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.491, total=  30.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.492, total=  30.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.471, total=  32.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.509, total= 1.0min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.508, total= 1.0min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.521, total=  45.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.483, total=  46.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.517, total=  55.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=  47.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.530, total=  58.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.505, total=  59.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=  37.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.524, total=  38.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.488, total=  50.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.535, total=  49.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.511, total=  58.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.538, total=  49.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.563, total=  29.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=  36.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.550, total=  36.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=  36.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.548, total=  42.0s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.502, total=  41.1s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=  43.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.572, total=  45.5s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 57.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.523, total=  45.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.483, total=  43.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.551, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.533, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.517, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.571, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.514, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.557, total= 1.5min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total= 1.5min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.539, total=  37.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.523, total=  37.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.551, total=  28.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.526, total=  36.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.548, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.544, total=  30.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.520, total=  31.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.547, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.550, total= 1.3min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.505, total= 1.5min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.554, total=  46.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.514, total=  45.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.502, total=  45.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.569, total=  48.6s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  48.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.523, total=  48.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.551, total= 1.6min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total= 1.5min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.524, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.535, total= 1.4min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.526, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.544, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.563, total= 1.6min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.498, total= 1.6min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.575, total=  38.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.523, total=  38.3s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.578, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.500, total=  29.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.541, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.456, total=  37.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.535, total= 1.5min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.465, total=  30.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.526, total= 1.2min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.544, total=  31.4s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.560, total=  43.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.465, total=  43.7s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.511, total=  51.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.554, total=  52.9s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=  51.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=  52.8s\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.551, total= 1.6min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1285 tasks      | elapsed: 64.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.508, total= 1.6min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.539, total= 1.3min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total= 1.1min\n",
      "[CV] batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.535, total= 1.5min\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.541, total= 1.2min\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.467, total=   5.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.498, total=   5.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.498, total=   4.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.530, total=   5.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.494, total= 1.4min\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=   4.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.523, total= 1.3min\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.538, total=   4.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.548, total=   4.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.547, total=   5.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.498, total=   5.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.482, total=   5.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.505, total=   4.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=   5.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.497, total=   5.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.550, total=   5.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.532, total=   4.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.578, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.538, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.550, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.512, total=   5.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=   5.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.498, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop [CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.533, total=   5.8s\n",
      "\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.479, total=   5.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.486, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.500, total= 1.0min\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.515, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.489, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.514, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.485, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.502, total=   5.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.523, total=  57.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.477, total= 1.2min\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=8, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.517, total=  55.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.514, total=   5.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.512, total=   5.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.489, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.517, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.482, total=   6.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.511, total=   6.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=   6.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.488, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1336 tasks      | elapsed: 65.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.505, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.512, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.498, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.486, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.512, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.465, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.461, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.517, total=   6.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.489, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.515, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.511, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.515, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.492, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.539, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_10593/dense_335_loss/Neg'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=nan, total=   0.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.511, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.514, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.545, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.514, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.498, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.587, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.551, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.508, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.578, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.566, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.514, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.517, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.548, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.562, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.535, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.563, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.529, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1389 tasks      | elapsed: 66.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.539, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.535, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.550, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.536, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.474, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.506, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.505, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.505, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.536, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.477, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.523, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.458, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.462, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.505, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.503, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.444, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.518, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.480, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.517, total=  15.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.548, total=  15.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.465, total=  14.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.511, total=  14.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.491, total=  13.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.520, total=  13.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  13.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=   6.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.495, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.515, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=   7.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   6.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=   7.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.488, total=   7.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.474, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.515, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.498, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_10666/dense_338_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=nan, total=   0.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.503, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.488, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.492, total=  39.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.511, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.518, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.544, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 67.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.541, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.548, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.556, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.547, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.542, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.547, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.578, total=   8.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.515, total=   9.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.541, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.520, total=   9.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.557, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.535, total=   9.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.548, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.587, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.500, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.511, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.512, total=   8.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.559, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.524, total=   9.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.474, total=   9.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=  10.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.590, total=  10.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.541, total=   9.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.502, total=  10.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.554, total=  10.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.483, total=  10.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.502, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.491, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.541, total=   8.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.562, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.539, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.532, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.503, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.462, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.511, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.509, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.520, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.485, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.514, total=   8.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1497 tasks      | elapsed: 68.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.512, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.505, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.521, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.511, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.512, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.489, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.511, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.511, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.520, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.488, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.575, total=   6.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.562, total=   6.6s\n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=   8.9s[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "\n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.536, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.505, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.571, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.508, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.563, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.563, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.550, total=   6.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_10756/dense_369_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   0.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.508, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.485, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.536, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.535, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.520, total=   6.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.554, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.495, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.545, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.550, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.515, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.502, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.523, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.515, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.508, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.521, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.502, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.548, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.486, total=   6.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.465, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.498, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.458, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.502, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.486, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.494, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed: 69.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.486, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.502, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.488, total=  14.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.502, total=  13.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=  13.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.458, total=  13.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total=  13.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.486, total=  12.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.511, total=  12.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=   5.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=   5.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=   5.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=   5.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.512, total=   5.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.508, total=   5.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.446, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.517, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.425, total=   6.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=   6.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.500, total=   5.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_10809/dense_356_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=nan, total=   0.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.498, total=   5.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.514, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.500, total=   6.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=   6.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.480, total=   6.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.560, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.547, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  35.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.536, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.569, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.550, total=  11.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.526, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.506, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.495, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.523, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.542, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.553, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.532, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.521, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.553, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.517, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.575, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.526, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.529, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.542, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.532, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.545, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop [CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.498, total=   7.8s\n",
      "\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1609 tasks      | elapsed: 70.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.520, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.524, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.505, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.538, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.494, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.486, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.488, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.508, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.480, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.508, total=   7.8s[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=nan, total=   1.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_10853/dense_378_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.485, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.505, total=   8.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.476, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.498, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.518, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.505, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.492, total=   8.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.512, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.556, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.480, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.485, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.482, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.512, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.477, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.488, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.518, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=   8.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.462, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.488, total=   7.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.502, total=   7.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.514, total=   7.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.563, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.514, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.569, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.520, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.544, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.533, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.577, total=   8.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.559, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.545, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1666 tasks      | elapsed: 71.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.550, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.572, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_10903/dense_370_loss/mul_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=nan, total=   0.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.560, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.532, total=   8.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.532, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.560, total=   9.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.502, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.578, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.473, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.492, total=   7.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.489, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.512, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.505, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.508, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.455, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.468, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.541, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.500, total=   8.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.483, total=   8.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.526, total=   9.4s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.480, total=   9.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.458, total=  10.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=   9.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.482, total=   9.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.523, total=   9.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=   8.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.512, total=   7.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.571, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.492, total=   9.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.498, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.536, total=   9.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.511, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.506, total=   9.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=   9.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.489, total=   7.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.491, total=  15.2s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=  15.5s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=  15.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.512, total=  15.8s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.514, total=  15.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.515, total=  15.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=  14.7s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.489, total=   7.3s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.488, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.517, total=   9.1s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=   9.6s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.518, total=   9.0s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.474, total=   8.9s\n",
      "[CV] batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.498, total=  10.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total=   9.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=  31.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.508, total=   9.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.491, total=   9.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=  10.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1725 tasks      | elapsed: 72.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.477, total=  10.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.514, total=  10.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.509, total=  10.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.517, total=   9.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=   9.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.485, total=   8.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.511, total=   9.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.535, total=  10.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.530, total=  12.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.526, total=  12.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.530, total=   9.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.556, total=   9.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.511, total=  13.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=   8.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.489, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.533, total=   8.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.536, total=   8.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=  12.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.511, total=  16.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.492, total=  14.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.563, total=  17.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.488, total=  23.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.505, total=  23.6s[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total=  16.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "\n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total=  22.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.536, total=  11.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.492, total=  11.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.541, total=  15.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.568, total=   7.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.536, total=   8.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.526, total=   8.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.523, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.518, total=  10.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.495, total=   9.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.503, total=  13.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.492, total=  13.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.535, total=  13.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_21993/acc/div_no_nan/ReadVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=nan, total=   1.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.514, total=   9.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  10.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.536, total=  10.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.536, total=  10.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.514, total=  15.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.532, total=  18.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.515, total=  19.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.535, total=  19.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.480, total=  23.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.572, total=  25.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.508, total=  23.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.502, total=  17.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  11.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  10.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.485, total=   7.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=   8.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=   9.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=  10.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.512, total=  13.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 74.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.532, total=  13.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.526, total=   9.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.511, total=   9.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.505, total=  14.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.518, total=  10.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.465, total=   9.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.542, total=   8.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.495, total=   9.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total=  10.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.482, total=  20.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.533, total=  24.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.505, total=  24.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.535, total=  19.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.523, total=  19.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.544, total=  23.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.533, total=  18.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.559, total=  17.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.560, total=  14.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.577, total=  15.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.556, total=  15.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.541, total=  18.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.563, total=  14.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.494, total=  18.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.538, total=  18.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.498, total=  18.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.505, total=  10.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.544, total=  11.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.575, total=  17.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.572, total=  16.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.541, total=  16.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.526, total=  16.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.529, total=  21.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  21.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.482, total=  30.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.556, total=  31.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.517, total=  19.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.548, total=  20.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=  35.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.541, total=  33.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.584, total=  34.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total=  34.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.506, total=  15.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.502, total=  26.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.514, total=  22.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.563, total=  17.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.520, total=  30.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.551, total=  21.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.520, total=  21.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.547, total=  13.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.502, total=  25.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.553, total=  26.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.575, total=  19.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.562, total=  19.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  19.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.535, total=  19.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.539, total=  19.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.535, total=  20.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.541, total=  34.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.509, total=  35.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.518, total=  20.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  18.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1845 tasks      | elapsed: 76.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.482, total=  30.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  35.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.529, total=  29.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.520, total=  29.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.491, total=  14.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.520, total=  14.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.483, total=  15.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.489, total=  17.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.520, total=  15.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.506, total=  17.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.535, total=  15.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.500, total=  12.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=  11.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=  11.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.539, total=  19.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=  19.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.470, total=  17.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.535, total=  17.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.508, total=  17.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.517, total=  25.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.500, total=  32.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.489, total=  34.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.527, total=  27.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.542, total=  32.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.508, total=  25.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.502, total=  33.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=  33.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=  38.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.521, total=  18.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=  22.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=  16.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.544, total=  15.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.515, total=  17.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.518, total=  22.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.565, total=  22.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=  22.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=  18.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=  18.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.521, total=  29.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.574, total=  30.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.536, total=  23.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.505, total=  26.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.556, total=  27.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.480, total=  31.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=  49.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.545, total=  49.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.566, total=  27.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.511, total=  25.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.539, total=  45.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.559, total=  44.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.530, total=  20.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=  45.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.505, total=  54.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.511, total=  20.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.553, total=  20.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.529, total=  23.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.533, total=  19.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.556, total=  18.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.556, total=  18.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.575, total=  19.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1906 tasks      | elapsed: 79.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.520, total=  18.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.514, total=  23.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.529, total=  32.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.509, total=  33.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.557, total=  22.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.535, total=  31.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.517, total=  25.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.544, total=  25.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.488, total=  48.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.477, total=  25.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.479, total=  27.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  49.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.542, total=  45.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.523, total=  46.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.517, total=  45.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.502, total=  55.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.533, total=  20.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.556, total=  20.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.523, total=  20.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  24.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.506, total=  19.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  19.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.480, total=  17.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.489, total=  17.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.485, total=  18.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.565, total=  18.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.503, total=  20.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.485, total=  31.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.535, total=  30.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.544, total=  22.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=  30.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=  30.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.551, total=  10.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.550, total=  10.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=  10.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.578, total=   9.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.559, total=  16.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.527, total= 1.0min\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.526, total= 1.0min\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.544, total=  56.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.518, total=  56.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.554, total=  11.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.514, total=  11.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_11183/dense_428_loss/mul'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=nan, total=   2.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.532, total=  12.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.511, total=  24.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.544, total=  55.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.556, total= 1.0min\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.544, total=   9.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=  10.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.485, total=  10.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.514, total=  10.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.532, total=  10.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.491, total=  15.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.498, total=  15.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=  15.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.563, total=  16.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total=  16.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.524, total=  11.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.495, total=  12.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.557, total=  19.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=  19.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.541, total=  10.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.517, total=  19.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed: 83.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.506, total=  10.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=  24.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.498, total=   9.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.480, total=   9.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.530, total=   9.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.541, total=  10.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.458, total=  12.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.486, total=  11.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.505, total=  14.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.562, total=  14.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.533, total=  13.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  13.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.535, total=  10.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.551, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.547, total=   8.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.532, total=   9.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  11.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  11.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.563, total=  23.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.547, total=  24.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.548, total=  23.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.529, total=  21.0s[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.511, total=  22.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=  25.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=   8.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  11.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_11229/dense_451_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   1.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=   7.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=   7.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  12.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.495, total=  10.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.506, total=  13.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=  10.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=  13.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.473, total=  13.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.505, total=  12.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.480, total=  11.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.494, total=   7.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=  12.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.505, total=  13.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=  20.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.465, total=  21.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.495, total=  19.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.416, total=  26.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=  26.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.492, total=  24.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.530, total=  17.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.568, total=  17.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.542, total=  11.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.544, total=  13.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.553, total=  14.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=  15.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.548, total=  14.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.527, total=  19.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.514, total=  18.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=  17.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=  13.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=  12.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.524, total=  18.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.571, total=  18.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.569, total=  18.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.520, total=  20.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed: 85.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=  21.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.514, total=  26.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.530, total=  35.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.547, total=  34.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.578, total=  18.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=  18.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.578, total=  31.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=  31.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.495, total=  38.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.498, total=  31.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.521, total=  15.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.550, total=  14.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.541, total=  18.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=  13.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.539, total=  16.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.518, total=  12.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  15.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=  12.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=  16.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.520, total=  12.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.548, total=  19.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total=  19.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.587, total=  15.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.526, total=  20.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.532, total=  19.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.529, total=  21.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.563, total=  36.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.482, total=  19.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.532, total=  36.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.526, total=  27.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.563, total=  41.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.535, total=  41.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.532, total=  46.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.550, total=  41.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.444, total=  22.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.489, total=  13.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  26.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.473, total=  26.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.518, total=  15.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.485, total=  13.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=  15.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=  16.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=  12.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.526, total=  12.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.494, total=  20.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.517, total=  20.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.539, total=  16.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total=  16.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.453, total=  20.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.523, total=  17.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total=  35.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.489, total=  34.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.557, total=  26.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.562, total=  26.8s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.485, total=  33.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.523, total=  34.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.523, total=  35.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.459, total=  39.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.533, total=  19.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.526, total=  22.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.574, total=  18.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.544, total=  18.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.548, total=  22.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.530, total=  18.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=  22.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2097 tasks      | elapsed: 88.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.523, total=  22.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.571, total=  17.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=  17.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.584, total=  23.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.539, total=  32.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.541, total=  32.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.550, total=  25.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.553, total=  25.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=  33.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.578, total=  26.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.485, total=  49.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.559, total=  50.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.523, total=  26.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.518, total=  48.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=  48.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.569, total=  20.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=  48.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.526, total=  23.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=  20.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.544, total=  20.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.547, total=  56.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.584, total=  21.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.557, total=  19.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.544, total=  21.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.520, total=  19.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  20.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.523, total=  23.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.536, total=  34.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.526, total=  33.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.530, total=  24.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.544, total=  24.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.541, total=  29.9s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.547, total=  34.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=  51.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.575, total=  54.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=  28.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.520, total=  28.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_22736/acc/div_no_nan/ReadVariableOp_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=nan, total=   1.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.566, total=  49.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.541, total=  50.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.529, total=  51.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.509, total=  21.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total= 1.0min\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_11374/dense_486_loss/Mean'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   1.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  25.2s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.477, total=  21.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.521, total=  24.1s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.459, total=  22.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.554, total=  17.3s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.495, total=  21.0s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=  17.7s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.488, total=  22.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.473, total=  33.6s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=  32.4s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.532, total=  24.5s\n",
      "[CV] batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.544, total=  32.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.505, total=  25.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.563, total=  12.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=  11.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=  11.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.491, total=  11.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.517, total=  51.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.551, total=  52.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.553, total=  11.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=  11.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2162 tasks      | elapsed: 92.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.542, total=  15.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.514, total=  15.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.514, total=  15.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.535, total=  52.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.480, total=  53.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.526, total=  59.0s[CV]  batch_size=16, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.587, total=  54.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.518, total=  16.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_22802/acc/Cast_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=nan, total=   3.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dropout_225_18/dropout/Shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   3.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=  10.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.502, total=   9.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.495, total=  23.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.550, total=  30.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.498, total=  36.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  36.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.527, total=  38.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.497, total=  45.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.556, total=  45.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=  44.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.518, total=  24.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total=  41.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.517, total=  29.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.517, total=  21.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.575, total=  21.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.529, total=  20.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.465, total=  20.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=  38.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.548, total=  13.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.545, total=  10.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.535, total=  14.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.517, total=  14.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.517, total=  15.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.517, total=  15.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.536, total=  21.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.498, total=  22.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.553, total=  20.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.545, total=  16.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_22868/acc/div_no_nan'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=nan, total=   2.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.526, total=  18.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.526, total=  17.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  16.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.471, total=  16.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.477, total=  15.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.593, total=  34.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  35.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.509, total=  13.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  13.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  13.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.489, total=  41.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.539, total=  42.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.517, total=  41.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=  17.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.489, total=  16.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  15.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.512, total=  14.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam [CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=  14.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "\n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.517, total=  10.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.473, total=  20.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=  20.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.512, total=  21.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=  23.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.526, total=  24.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.495, total=  28.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.541, total=  37.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.479, total=  40.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.559, total=  23.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2229 tasks      | elapsed: 95.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.527, total=  24.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=  37.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=  38.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.508, total=  43.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.474, total=  37.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.506, total=  20.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=  21.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.526, total=  18.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=  18.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.563, total=  22.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=  21.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.562, total=  22.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.575, total=  23.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.574, total=  23.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=  22.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.518, total=  37.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.517, total=  37.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=  37.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.524, total=  33.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=  33.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.477, total=  44.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.542, total=  25.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.529, total=  25.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.551, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.529, total=  24.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.557, total=  21.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.545, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.532, total=  21.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.502, total=  21.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.541, total= 1.4min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.550, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.523, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.560, total=  27.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.502, total=  25.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=  24.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.498, total=  23.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.581, total=  23.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.553, total=  21.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.517, total=  38.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.587, total=  39.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.517, total=  38.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.563, total=  31.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.514, total=  32.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.529, total=  42.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  24.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  23.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.557, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.559, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  23.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.497, total=  21.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.538, total=  21.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.489, total=  22.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.539, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.526, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.541, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.479, total=  27.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.486, total= 1.4min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.508, total=  34.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.494, total=  32.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.520, total=  33.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.550, total=  31.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.489, total=  31.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=  44.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=  46.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_11528/dense_549_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=nan, total=   1.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.467, total=  33.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2296 tasks      | elapsed: 100.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.517, total=  50.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.535, total=  43.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.514, total=  43.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.530, total=  32.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.482, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.547, total=  31.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.520, total=  33.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.526, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.569, total=  29.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.526, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.524, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=  29.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.547, total=  28.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.545, total=  33.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.544, total=  32.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=  29.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.539, total=  30.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.514, total=  29.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.498, total=  29.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.569, total=  55.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.544, total=  57.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.563, total=  50.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=  57.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.532, total=  53.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total= 1.1min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.557, total=  35.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.541, total=  34.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.542, total= 1.8min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.526, total= 1.8min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=  33.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.566, total=  30.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.541, total=  29.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.550, total=  29.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.547, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.548, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.494, total=  38.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.526, total= 2.1min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.541, total=  36.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.520, total=  34.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.542, total=  34.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.508, total=  29.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  29.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.575, total=  57.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.520, total=  57.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.508, total=  56.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.527, total=  51.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.559, total=  55.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=  59.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.485, total=  34.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.532, total=  33.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.545, total= 1.8min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.535, total= 1.8min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.450, total=  33.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.521, total=  32.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.462, total=  30.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=  31.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.542, total= 2.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.547, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.470, total=  38.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.505, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.511, total= 2.1min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.526, total=  39.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=  33.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.476, total=  33.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.556, total=  29.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.511, total=  30.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.542, total=  54.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2365 tasks      | elapsed: 109.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total=  54.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.506, total=  50.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.520, total=  58.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=  56.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.529, total= 1.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.488, total=  14.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=  14.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.520, total=  13.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.494, total=  13.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.547, total=  13.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=  14.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.557, total=  17.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.538, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.488, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=  18.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=  17.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.545, total=  17.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=  17.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.538, total=  16.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.560, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.532, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.544, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.511, total= 2.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.524, total=  26.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.545, total=  19.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  23.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=  24.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.553, total=  17.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=  18.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.509, total=  14.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=  14.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.508, total=  22.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.566, total=  55.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.553, total=  55.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=  55.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.539, total=  30.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.479, total=  53.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.486, total=  52.4s[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.517, total=  52.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=  13.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=nan, total=   3.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_23275/acc/Greater'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.508, total=   9.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.524, total=  17.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.605, total=  17.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=  19.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=  18.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  18.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.505, total=  21.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.482, total=  21.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total=  21.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.485, total=  13.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.541, total=  22.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=  26.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  15.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  13.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.511, total=  45.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.539, total=  46.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.488, total=  43.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.505, total=  14.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=  43.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=  42.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_594_18/Identity'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=nan, total=   3.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  48.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.503, total=  14.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=  11.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=  11.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_23330/acc/div_no_nan/ReadVariableOp_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=nan, total=   1.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.512, total=  19.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.485, total=  17.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 113.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=  20.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=  17.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=  17.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dropout_298_16/Identity'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=nan, total=   2.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.485, total=  17.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.485, total=  23.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.520, total=  21.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.420, total=  12.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.517, total=  16.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.491, total=  25.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.556, total=  23.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.550, total=  22.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.431, total=  42.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.523, total=  48.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=  44.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.502, total=  42.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.483, total=  49.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.539, total=  21.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.547, total=  20.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.495, total=  17.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.527, total=  17.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.538, total=  26.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=  27.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=  27.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.515, total=  29.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=  27.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=  39.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.536, total=  43.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.477, total=  40.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.503, total=  48.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.526, total=  50.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=  51.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.515, total=  24.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.514, total=  24.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.518, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.524, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.523, total=  20.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.542, total=  20.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total= 1.4min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.562, total=  21.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.538, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.535, total=  22.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.521, total=  24.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.556, total=  25.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.505, total=  24.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.503, total=  26.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.535, total=  27.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.526, total=  26.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.560, total=  41.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.560, total=  36.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.526, total=  39.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_23442/acc/Mean'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=nan, total=   1.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.502, total=  41.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=  37.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.514, total=  41.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.515, total=  25.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.489, total=  26.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=  22.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.488, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.538, total= 1.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.491, total=  22.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.532, total=  22.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  21.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.520, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.455, total=  26.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.477, total=  27.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=  26.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.535, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2505 tasks      | elapsed: 118.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.527, total=  29.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.492, total=  27.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.526, total=  23.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.483, total=  46.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=  52.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.491, total=  47.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.495, total=  48.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.505, total=  48.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.535, total=  53.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.532, total=  35.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.539, total=  37.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.508, total= 1.4min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=  30.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.545, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.542, total=  32.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.535, total=  32.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.480, total= 1.4min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.523, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.541, total=  30.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.471, total= 1.3min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.563, total=  37.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.574, total=  33.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=  34.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.539, total=  36.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=  35.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.580, total=  37.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.533, total= 1.1min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.541, total= 1.1min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.539, total=  56.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.502, total= 1.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.559, total=  59.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.556, total= 1.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.509, total=  36.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.544, total=  36.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.502, total= 1.8min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.533, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.523, total=  32.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.551, total=  33.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.554, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.541, total=  32.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.511, total=  33.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.526, total= 2.1min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.572, total=  40.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.550, total= 2.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.538, total=  39.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.535, total= 2.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.547, total=  35.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.566, total=  37.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=  36.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.544, total=  32.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.569, total=  58.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.563, total=  55.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.535, total= 1.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.529, total= 1.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.538, total=  58.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total= 1.1min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.476, total=  34.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  36.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.488, total= 1.8min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total= 1.9min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.538, total=  33.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.452, total=  32.1s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=  31.2s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=  31.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.509, total=  38.8s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.485, total= 2.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.526, total= 2.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total= 2.0min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.538, total= 2.2min\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.459, total=  39.5s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 127.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.511, total=  37.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.473, total=  36.6s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=  29.7s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.526, total=  30.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.461, total=  57.9s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=  56.4s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.505, total=  56.0s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.503, total=  51.3s\n",
      "[CV] batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.498, total=  54.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.473, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=   4.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.483, total= 1.0min\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.489, total=   4.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.485, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.506, total=   4.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.502, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=   4.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.521, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.520, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.505, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.485, total=   4.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.544, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.479, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.480, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.508, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.527, total=   4.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.533, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=   5.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.506, total= 1.9min\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.505, total= 1.9min\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.488, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.441, total=   4.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.508, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.512, total=   4.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.502, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.486, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.470, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.498, total=   4.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.544, total=   4.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.482, total=   4.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.505, total=   4.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.520, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.464, total=   4.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.498, total=   4.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.502, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.488, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.494, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.477, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.492, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.486, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.497, total=  13.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.520, total=  13.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.511, total=  13.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.508, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.515, total= 2.1min\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.509, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.495, total= 2.1min\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.517, total= 2.1min\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.461, total=  19.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=   5.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=16, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.565, total= 2.2min\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.515, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2649 tasks      | elapsed: 130.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   4.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.520, total=   5.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.512, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.485, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.532, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.512, total=   5.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=   5.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.491, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam [CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=   5.9s\n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.521, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.550, total=   6.8s[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.491, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.535, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.500, total=   7.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.535, total=   7.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.553, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=   7.7s[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.524, total=   7.5s\n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   0.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_11909/dense_656_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.530, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.565, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.520, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.554, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.523, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.542, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=   8.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.580, total=   8.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.512, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.535, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.512, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.520, total=   5.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.489, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.554, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.511, total=   8.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.530, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.492, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.505, total=   8.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.491, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.520, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.492, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.551, total=   4.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.489, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.465, total=   7.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.488, total=   8.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.486, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.488, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.520, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.498, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.488, total=   4.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.498, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.514, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.542, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=   8.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=   8.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.512, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=   4.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2722 tasks      | elapsed: 131.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.512, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=   8.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=   8.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.506, total=   7.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=   7.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.511, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.488, total=   4.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.505, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.502, total=   7.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.512, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.492, total=   8.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.566, total=  10.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.541, total=   9.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.505, total=  10.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.563, total=   8.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.526, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.551, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.541, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.575, total=   8.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.547, total=   8.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=   9.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.544, total=   8.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.560, total=   9.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.511, total=   8.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=   9.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.560, total=   8.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.535, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.536, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.547, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.524, total=   9.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.541, total=   8.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=   9.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.485, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.489, total=   7.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.506, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=   7.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.502, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.511, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=   8.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.482, total=   8.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=   9.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.521, total=   9.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.505, total=   9.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.477, total=   9.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.482, total=   9.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.502, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.492, total=   7.0s\n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.488, total=   6.8s[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.505, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.492, total=   7.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.459, total=   8.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.524, total=   9.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=   9.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.533, total=  17.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.495, total=  16.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.520, total=  17.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=  16.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.502, total=  14.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=  14.3s\n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.512, total=  14.2s[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   8.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.512, total=   9.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=   9.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.468, total=   9.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.512, total=   9.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   8.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=   8.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=  24.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.485, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2797 tasks      | elapsed: 132.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=   8.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=   9.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.449, total=   9.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.498, total=   9.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=   9.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.479, total=   9.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=   7.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.505, total=   8.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.539, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.533, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.514, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.495, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.486, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.527, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12044/dense_673_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=nan, total=   0.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.489, total=   4.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.542, total=   4.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.498, total=   5.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.494, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.498, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.566, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.553, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.512, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.486, total=   3.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.511, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.539, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.509, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.547, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.486, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.544, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.488, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.502, total=   3.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.495, total=   4.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.512, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.498, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.480, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.488, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.488, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.514, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.502, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.480, total=   3.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.515, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.524, total=   6.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.529, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.508, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.488, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.498, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=   3.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.518, total=   5.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.508, total=   5.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.486, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.512, total=   6.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=   4.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=   4.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=   6.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.514, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.498, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.515, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.512, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=   6.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=   5.7s[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=   6.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.506, total=   4.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2872 tasks      | elapsed: 133.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.488, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.520, total=   6.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.495, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.512, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.517, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.539, total=   4.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.547, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.514, total=   8.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.556, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.524, total=   8.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=   8.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.566, total=   8.5s[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=   8.0s\n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.521, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.544, total=   7.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.605, total=   8.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.494, total=   8.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.538, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.544, total=   8.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=   8.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=   5.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.515, total=   4.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.529, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.550, total=   7.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.544, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total=   9.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.500, total=   9.0s[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.515, total=   8.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.508, total=   8.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.502, total=   6.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.410, total=   4.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.498, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.514, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.485, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.524, total=   8.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.505, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.538, total=   8.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.492, total=   8.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.486, total=   7.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.494, total=   4.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.462, total=   4.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.497, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.483, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.505, total=   8.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.505, total=   8.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.485, total=   8.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.538, total=   8.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.498, total=   7.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.536, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.502, total=  16.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.486, total=  16.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=  15.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.483, total=  16.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.524, total=  16.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.515, total=  17.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  17.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  17.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.485, total=   6.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.505, total=   7.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=   7.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=   7.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.489, total=   8.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.488, total=   8.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=   8.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=   5.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.512, total=   4.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=   7.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.511, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=   8.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.518, total=   8.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.527, total=   9.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.502, total=   9.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 2949 tasks      | elapsed: 135.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.498, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.553, total=   7.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.548, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.538, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.518, total=   9.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.553, total=  10.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.553, total=   9.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.565, total=  10.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.539, total=  10.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.547, total=  10.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.520, total=   9.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.560, total=   7.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=   9.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.538, total=   9.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.527, total=  10.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.530, total=   9.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.523, total=  10.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=  10.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=   9.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=   9.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.530, total=   5.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.532, total=   7.7s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.556, total=   9.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=  10.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.536, total=  10.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.491, total=  10.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=  11.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.502, total=  10.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.511, total=   8.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.497, total=   6.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.508, total=   9.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.492, total=   9.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.503, total=  10.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  10.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=  10.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.497, total=  10.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.483, total=   9.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.489, total=   9.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12220/dense_686_loss/Mean'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12222/dense_711_loss/Log'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.491, total=   5.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.517, total=   6.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.535, total=   9.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.517, total=  10.5s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.554, total=  10.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  10.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.491, total=  10.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  10.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_24462/acc/div_no_nan/ReadVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=nan, total=   1.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.547, total=   8.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.480, total=   7.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=   8.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.505, total=   9.4s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=   9.9s\n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=  10.2s[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.483, total=  10.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.512, total=  10.1s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.505, total=   9.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=   9.8s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.488, total=   5.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   5.0s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=   9.3s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.488, total=  10.2s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.503, total=   9.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=  10.6s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.483, total=   9.9s\n",
      "[CV] batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.514, total=   8.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.488, total=   8.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=   7.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.551, total=   9.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.550, total=   9.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.495, total=   9.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.485, total=  11.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=  12.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.596, total=   6.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam [CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.502, total=  12.5s\n",
      "\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3026 tasks      | elapsed: 136.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=1, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=  12.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_24520/acc/Sum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=nan, total=   2.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_718_18/BiasAdd'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_718_18/Sigmoid'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=nan, total=   2.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=nan, total=   2.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.495, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.489, total=   9.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.485, total=  11.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.492, total=  12.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.548, total=  11.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.554, total=  16.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.580, total=  15.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=  11.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=  16.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.538, total=  11.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.575, total=  12.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.559, total=  10.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.508, total=   8.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.530, total=  11.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.538, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.491, total=   8.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.508, total=   7.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.547, total=  10.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.556, total=  15.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.538, total=  15.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.554, total=  15.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.502, total=   7.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.545, total=  10.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.575, total=   8.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.517, total=   9.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.498, total=   9.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.511, total=  12.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.574, total=  12.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.545, total=  12.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.511, total=   9.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.548, total=  13.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.526, total=  14.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.538, total=  14.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  18.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.548, total=  13.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total=  17.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.557, total=  18.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  16.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.541, total=   8.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.538, total=  18.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  18.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=  16.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  16.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  20.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  20.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=  16.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=   5.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.495, total=   6.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.512, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.502, total=   8.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.526, total=   8.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=  32.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.500, total=  14.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.498, total=  15.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.515, total=  13.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=  15.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.498, total=  11.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.514, total=  12.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.518, total=  11.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.538, total=  13.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.495, total=  13.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.491, total=  14.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.532, total=  14.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=  14.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.571, total=  14.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.539, total=  15.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.517, total=  13.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.551, total=   8.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.535, total=   8.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.559, total=   8.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.548, total=   9.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.566, total=  11.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.559, total=  13.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.565, total=  12.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3105 tasks      | elapsed: 138.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.520, total=  11.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.526, total=  15.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.527, total=  22.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.532, total=  22.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.505, total=  20.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.560, total=  20.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=  21.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.538, total=  21.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.530, total=  25.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total=  25.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.518, total=  12.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.535, total=  12.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.518, total=  20.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.565, total=  20.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12354/dense_711_loss/clip_by_value/Minimum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=nan, total=   1.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.529, total=  24.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=  19.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.533, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.483, total=  12.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.535, total=   8.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.450, total=   9.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.545, total=  11.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.526, total=  14.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.553, total=  12.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=  12.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.553, total=  14.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.560, total=  23.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.544, total=  22.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.526, total=  21.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.530, total=  19.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.498, total=  22.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.535, total=  21.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.547, total=  25.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.506, total=  27.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.485, total=  12.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.548, total=  21.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.474, total=  13.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.532, total=  21.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.532, total=  24.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.535, total=  19.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.526, total=  11.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.461, total=  10.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12381/dense_734_loss/clip_by_value/Minimum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   1.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.459, total=   9.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.514, total=   8.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.486, total=  11.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.541, total=  11.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.509, total=  14.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.471, total=  16.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.489, total=  15.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.491, total=  20.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=  19.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.526, total=  19.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.556, total=  21.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.502, total=  22.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.518, total=  23.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.556, total=  25.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.593, total=  26.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.506, total=  20.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.511, total=  20.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.538, total=  23.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.560, total=  16.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.520, total=  16.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.492, total=  19.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.527, total=  14.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.550, total=  16.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=  13.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.532, total=  14.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.551, total=  16.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.556, total=  14.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.517, total=  13.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.569, total=  14.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=  12.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.498, total=  16.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.542, total=  29.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.559, total=  29.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.541, total=  29.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.569, total=  29.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 141.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.562, total=  30.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.529, total=  31.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.547, total=  36.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.524, total=  37.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.548, total=  15.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.550, total=  16.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.545, total=  29.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.541, total=  28.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.509, total=  14.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=  34.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.526, total=  17.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.544, total=  27.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.544, total=  13.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.523, total=  12.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.530, total=  16.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.556, total=  15.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.548, total=  15.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.550, total=  15.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.568, total=  14.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.526, total=  18.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.557, total=  37.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.550, total=  37.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.536, total=  37.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.547, total=  39.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.529, total=  42.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.526, total=  45.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.548, total=  46.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.556, total=  46.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.578, total=  28.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.488, total=  17.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.541, total=  35.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.515, total=  15.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.544, total=  29.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=  18.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.541, total=  19.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.547, total=  27.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.505, total=  12.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  13.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.491, total=  14.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.470, total=  14.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=  17.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.477, total=  14.3s[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.517, total=  14.8s\n",
      "\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.483, total=  18.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.497, total=  29.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=  29.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.520, total=  30.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.515, total=  30.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.553, total=  30.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.505, total=  31.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.521, total=   7.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.536, total=  37.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=  37.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=   7.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.512, total=   7.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.511, total=   9.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.520, total=   8.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.529, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.524, total=  28.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.520, total=  24.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.520, total=  32.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=  24.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.488, total=   8.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.557, total=   8.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.544, total=   8.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=  10.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.526, total=   6.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.550, total=  10.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.521, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.553, total=  14.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.480, total=  15.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.502, total=  14.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.545, total=  15.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.526, total=  14.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.518, total=  15.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.523, total=  15.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total=  14.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.551, total=   7.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=   9.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.511, total=   9.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.477, total=  10.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.515, total=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed: 145.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.560, total=   8.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.502, total=   8.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12500/dense_751_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=nan, total=   2.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.535, total=   8.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.532, total=  12.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.521, total=   7.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.508, total=   7.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.514, total=   8.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.489, total=   9.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.476, total=  10.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.482, total=  12.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.502, total=  12.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.575, total=  15.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.514, total=  15.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.508, total=  16.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.489, total=  12.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.551, total=  12.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.538, total=  12.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.511, total=  11.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.515, total=  10.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.485, total=   8.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.483, total=  10.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.563, total=  14.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.550, total=  15.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.483, total=  15.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=   6.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_25054/acc/AssignAddVariableOp'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   2.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=   7.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.470, total=  11.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.512, total=  10.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.495, total=  10.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.480, total=  12.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=  12.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.515, total=  13.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=  10.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.512, total=  11.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.483, total=  12.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.471, total=  13.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.488, total=  14.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.505, total=  14.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.503, total=  13.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=  13.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.447, total=  15.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.514, total=  10.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.569, total=  12.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.547, total=  13.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.575, total=  10.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=  12.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.486, total=  11.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=  11.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.503, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.565, total=  10.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.536, total=   8.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.529, total=   8.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.502, total=  10.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.514, total=  10.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.488, total=  21.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.548, total=  24.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  25.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  24.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.520, total=  21.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.535, total=  21.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.482, total=  22.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.568, total=  21.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.503, total=  11.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.520, total=  14.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.545, total=  15.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.517, total=  14.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.533, total=  20.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.529, total=  30.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.483, total=  32.5s[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.553, total=  30.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.553, total=  17.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.542, total=  22.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.538, total=  21.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.517, total=  22.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.551, total=  11.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.520, total=  11.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3346 tasks      | elapsed: 147.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.550, total=  11.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.544, total=  28.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.569, total=  13.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.526, total=  22.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.532, total=  22.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.551, total=  23.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.517, total=  23.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.547, total=  26.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.590, total=  26.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.538, total=  24.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=  22.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=  13.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.495, total=  12.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.581, total=  18.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  12.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.485, total=  11.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.492, total=  10.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12596/dense_761_loss/add_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   1.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.535, total=  19.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.535, total=  19.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=   8.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.512, total=  13.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.508, total=  12.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.508, total=  12.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  16.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.486, total=  16.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.524, total=  24.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.502, total=  25.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.486, total=  23.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.488, total=  18.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.511, total=  21.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.523, total=  21.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.521, total=  25.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.514, total=  24.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.470, total=  21.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12616/dense_777_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.511, total=  20.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.569, total=  17.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.508, total=  21.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.517, total=  25.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=  17.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.569, total=  13.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=  14.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.544, total=  11.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.533, total=  17.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.545, total=  16.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.511, total=  15.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12627/dense_802_loss/Mean'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   1.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=  15.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.580, total=  19.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.511, total=  20.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.515, total=  30.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.556, total=  29.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.532, total=  32.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.514, total=  34.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.538, total=  33.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=  38.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.572, total=  39.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.526, total=  37.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.569, total=  27.5s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.532, total=  28.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.575, total=  17.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.529, total=  17.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.502, total=  15.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.575, total=  15.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.508, total=  17.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.571, total=  13.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.544, total=  27.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.524, total=  14.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.568, total=  15.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.550, total=  14.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.575, total=  14.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.526, total=  14.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.550, total=  14.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.521, total=  33.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total=  31.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.572, total=  28.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.550, total=  28.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.532, total=  31.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.535, total=  29.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.584, total=  36.6s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.550, total=  36.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.437, total=  18.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3429 tasks      | elapsed: 151.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  17.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.569, total=  30.4s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.523, total=  16.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.527, total=  15.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.544, total=  29.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.526, total=  30.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.544, total=  34.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=  13.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.505, total=  11.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=  12.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.470, total=  15.2s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.532, total=  15.3s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=  15.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.489, total=  19.9s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=  20.7s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.503, total=  32.8s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=  33.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.535, total=  32.1s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.563, total=  29.0s\n",
      "[CV] batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.495, total=  28.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.447, total=  29.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.539, total=   7.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.517, total=   8.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.509, total=  37.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.529, total=  38.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.520, total=   8.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.505, total=   9.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.503, total=   9.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.497, total=  28.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12692/dense_800_loss/weighted_loss/broadcast_weights/assert_broadcastable/values/shape'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=nan, total=   2.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.489, total=  10.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.508, total=  34.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.520, total=  28.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.527, total=  10.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=2, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.505, total=  28.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.548, total=  11.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.514, total=  15.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.547, total=  14.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.541, total=  14.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.557, total=  29.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.502, total=  32.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.486, total=  31.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.500, total=  33.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.498, total=  26.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.547, total=  26.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.575, total=  31.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.524, total=  12.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.568, total=   9.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.526, total=  35.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.492, total=   8.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.512, total=   8.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.517, total=  23.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.483, total=   9.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.541, total=   8.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.514, total=  25.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.548, total=  26.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.565, total=  26.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.518, total=   9.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.495, total=  12.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.536, total=  13.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.520, total=  16.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.514, total=  15.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  13.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.491, total=  21.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.508, total=  21.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.526, total=  20.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.521, total=  17.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.529, total=  18.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.492, total=  18.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.482, total=   7.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.545, total=  25.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.517, total=  26.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.511, total=   9.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.560, total=  23.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.532, total=  22.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.532, total=  22.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.514, total=  25.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=  10.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.495, total=  10.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.488, total=  11.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.508, total=  10.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_25484/acc/Identity'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   4.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_25490/acc/Cast_3'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=-1)]: Done 3512 tasks      | elapsed: 154.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=nan, total=   2.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=  16.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.488, total=  16.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.518, total=  16.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.514, total=  14.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.498, total=  17.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.509, total=  16.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.539, total=  21.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.492, total=  19.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.489, total=  21.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.517, total=  22.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.488, total=  23.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.532, total=  28.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.517, total=  28.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.566, total=  29.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.547, total=  25.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.517, total=  24.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.581, total=  13.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.571, total=  12.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12764/dense_860_loss/sub_2'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=nan, total=   3.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=  15.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.563, total=  16.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.553, total=  17.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.520, total=  19.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.530, total=  16.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.520, total=  15.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.556, total=  19.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.536, total=  21.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.535, total=  13.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.521, total=  32.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.502, total=  38.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.527, total=  38.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.517, total=  40.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.505, total=  38.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.532, total=  39.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.569, total=  48.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.536, total=  13.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.574, total=  14.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.511, total=  47.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.553, total=  11.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.572, total=  12.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.550, total=  12.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.502, total=  13.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.520, total=  44.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.560, total=  38.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.497, total=  15.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.498, total=  42.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.526, total=  43.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.508, total=  17.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.533, total=  16.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.502, total=  17.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.523, total=  15.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=  13.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.488, total=  23.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.583, total=  39.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.527, total=  38.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12801/dense_869_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=nan, total=   2.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total=  42.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.544, total=  39.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop [CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.541, total=  38.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.529, total=  45.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.485, total=  47.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  16.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.503, total=  16.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.477, total=  17.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.541, total=  40.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.515, total=  12.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.495, total=  11.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  14.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.476, total=  18.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.444, total=  18.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.565, total=  39.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.520, total=  40.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.529, total=  19.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.489, total=  17.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.509, total=  18.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12821/dense_838_loss/clip_by_value/Minimum'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=nan, total=   3.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.544, total=  13.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.527, total=  26.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.505, total=  49.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.505, total=  51.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.486, total=  49.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.514, total=  53.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.524, total= 1.0min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.529, total=  57.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.491, total=  42.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3597 tasks      | elapsed: 159.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.535, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.527, total=  21.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.529, total=  20.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.506, total=  16.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.544, total=  19.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.538, total=  16.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.544, total=  19.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.486, total=  43.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.489, total=  43.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.523, total=  24.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.476, total=  25.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.535, total=  21.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.575, total=  21.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.553, total=  22.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.541, total=  20.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.563, total=  56.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.539, total=  52.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.511, total=  56.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.532, total=  55.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.562, total=  52.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.526, total=  51.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.500, total= 1.0min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.492, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.526, total=  19.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.515, total=  22.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.550, total=  16.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.526, total=  17.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.533, total=  17.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.532, total=  17.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.521, total=  21.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.526, total=  24.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  25.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_25726/acc/Greater'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=nan, total=   2.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.521, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.544, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.477, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.551, total=  26.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_25730/acc/Size'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=nan, total=   4.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=  19.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.557, total=  56.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.529, total=  56.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.553, total=  57.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.578, total= 1.0min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total= 1.0min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.523, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.485, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.524, total=  19.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.492, total=  19.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.486, total=  18.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.485, total=  19.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.486, total=  20.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.523, total=  19.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.509, total=  21.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.523, total=  55.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.536, total=  57.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.541, total=  57.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.556, total=  24.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.497, total=  23.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.502, total=  25.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.495, total=  24.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.541, total=  22.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.529, total=  52.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.465, total=  50.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.530, total=  53.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.474, total=  53.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.536, total=  54.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.483, total=  53.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.509, total=  10.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.489, total=   9.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.545, total=   8.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.526, total=   8.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.529, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.533, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.514, total=   9.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=50, optimizer=adam, score=0.565, total=  10.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.523, total=  10.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.557, total=  11.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.539, total=   9.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.517, total=  10.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.511, total=   9.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=100, optimizer=adam, score=0.550, total=   9.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.515, total=  59.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.529, total= 1.0min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3682 tasks      | elapsed: 165.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.517, total=  20.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.485, total=  21.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.505, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.2, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.514, total= 1.0min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.536, total=  19.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.526, total=  21.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.502, total=  14.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=250, optimizer=adam, score=0.511, total=  13.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.559, total=  10.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.524, total=  10.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_12926/dense_893_loss/Log_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=nan, total=   1.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.479, total=   8.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.544, total=   8.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.548, total=  29.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.545, total=  28.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.517, total=  26.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=  31.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=adam, score=0.541, total=  28.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total=  29.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.471, total=   8.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.506, total=  10.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.517, total=  13.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.503, total=  14.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.556, total=  15.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.523, total=  15.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.483, total=  18.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.515, total=  33.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.489, total=  30.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.529, total=  32.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.548, total=  26.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.514, total=  27.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.512, total=   7.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.523, total=  34.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.511, total=  34.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.536, total=  36.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  10.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.498, total=  23.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.511, total=  23.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.511, total=  10.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.491, total=  25.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.520, total=  29.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.485, total=  11.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.498, total=  11.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'dense_888_22/Identity'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=nan, total=   3.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.489, total=  11.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.482, total=  16.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.511, total=  16.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.508, total=  15.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.517, total=  15.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.535, total=  18.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.518, total=  20.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.474, total=  19.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.544, total=  16.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.491, total=  22.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.514, total=  22.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.495, total=  21.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.515, total=  27.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.523, total=  27.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.491, total=  24.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.480, total=  22.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.495, total=  27.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.535, total=  14.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.512, total=  15.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=5, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.508, total=  19.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.491, total=  13.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.526, total=  15.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.523, total=  14.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=50, optimizer=adam, score=0.520, total=  15.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.563, total=  15.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.565, total=  17.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.505, total=  18.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.563, total=  16.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.574, total=  15.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=100, optimizer=adam, score=0.538, total=  15.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.560, total=  36.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.547, total=  37.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.508, total=  36.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.565, total=  37.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.554, total=  40.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=250, optimizer=adam, score=0.556, total=  38.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.533, total=  13.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.486, total=  14.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.572, total=  52.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.583, total=  51.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.477, total=  12.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.521, total=  12.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.508, total=  12.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.532, total=  12.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3769 tasks      | elapsed: 169.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.569, total=  42.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.541, total=  40.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.486, total=  47.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.001, nodes=500, optimizer=adam, score=0.520, total=  38.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.529, total=  16.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.536, total=  17.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.524, total=  17.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.505, total=  19.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.535, total=  17.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.511, total=  17.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.544, total=  36.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.488, total=  38.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.566, total=  34.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total=  38.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.556, total=  35.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.520, total=  37.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.437, total=  12.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  12.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.488, total=  51.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total=  52.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.514, total=  12.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.524, total=  11.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.502, total=  13.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.511, total=  13.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.548, total=  44.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.535, total=  41.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.565, total=  41.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.483, total=  49.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.485, total=  16.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.523, total=  16.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.512, total=  14.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.495, total=  13.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.520, total=  17.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.520, total=  14.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.491, total=  35.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.530, total=  40.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.508, total=  39.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.505, total=  42.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.532, total=  34.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_13043/dense_919_loss/add_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=nan, total=   2.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.474, total=  36.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.486, total=  42.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.494, total=  43.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.557, total=  21.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.544, total=  19.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=rmsprop, score=0.523, total=  20.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.491, total=  16.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.526, total=  16.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=50, optimizer=adam, score=0.517, total=  18.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.455, total=  46.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.529, total=  46.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.557, total=  24.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.571, total=  24.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=10, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.498, total=  52.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.566, total=  23.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=rmsprop, score=0.529, total=  23.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'loss_13060/dense_913_loss/mul_1'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=nan, total=   2.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.541, total=  18.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=100, optimizer=adam, score=0.532, total=  19.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.575, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.566, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.498, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=rmsprop, score=0.486, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=250, optimizer=adam, score=0.511, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.541, total=  18.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.509, total=  19.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.527, total= 1.4min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.498, total= 1.4min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=rmsprop, score=0.514, total= 1.5min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=rmsprop, score=0.492, total=  17.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.563, total=  18.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.514, total=  16.3s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=50, optimizer=adam, score=0.532, total=  16.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.539, total= 1.0min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.533, total=  21.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.541, total=  24.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=rmsprop, score=0.514, total=  25.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.541, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.001, nodes=500, optimizer=adam, score=0.508, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.536, total=  27.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.529, total=  25.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=100, optimizer=adam, score=0.535, total=  17.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.554, total=  46.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.538, total=  55.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.563, total=  56.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.538, total=  56.8s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed: 175.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=adam, score=0.526, total=  56.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=250, optimizer=rmsprop, score=0.523, total= 1.0min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.464, total=  18.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.498, total=  17.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.560, total= 1.3min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.526, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=rmsprop, score=0.517, total=  15.6s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.485, total=  16.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.495, total=  15.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=50, optimizer=adam, score=0.517, total=  16.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=rmsprop, score=0.520, total= 1.2min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.509, total=  23.5s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.581, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.492, total=  25.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=rmsprop, score=0.538, total=  24.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.532, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=0.0001, nodes=500, optimizer=adam, score=0.523, total= 1.1min\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.506, total=  24.2s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "KeyError: 'metrics_26215/acc/Size'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=nan, total=   2.7s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.474, total=  16.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=100, optimizer=adam, score=0.483, total=  12.4s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.524, total=  59.1s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.508, total=  59.9s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.523, total=  59.0s\n",
      "[CV] batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam \n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=rmsprop, score=0.532, total= 1.0min\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=250, optimizer=adam, score=0.468, total= 1.0min\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.557, total= 1.2min\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.523, total= 1.2min\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=rmsprop, score=0.547, total= 1.2min\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.521, total=  36.3s\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.559, total=  34.9s\n",
      "[CV]  batch_size=32, depth=3, dropout_rate=0.5, epochs=15, learning_rate=1e-05, nodes=500, optimizer=adam, score=0.477, total=  32.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 3888 out of 3888 | elapsed: 178.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.564004 using {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.526011 (0.010727) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.529005 (0.006067) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.538973 (0.019175) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.529020 (0.014639) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.536938 (0.044172) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.522004 (0.023468) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.503986 (0.011630) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.489034 (0.031788) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.479036 (0.025430) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.507013 (0.013443) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.525013 (0.017361) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.502023 (0.016974) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.509998 (0.006287) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.503006 (0.007455) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.515965 (0.026577) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.497989 (0.009191) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500012 (0.010461) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.503980 (0.015395) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.498987 (0.010412) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.530009 (0.008063) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.547991 (0.009678) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.504996 (0.013777) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.525007 (0.013233) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.527027 (0.020478) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.526023 (0.020383) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.533003 (0.012450) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.555969 (0.025028) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.485995 (0.022351) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.520011 (0.009212) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.514958 (0.030275) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.494000 (0.008582) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.533974 (0.018359) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.522010 (0.007200) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.527983 (0.017134) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.523008 (0.012412) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.506992 (0.010270) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.499011 (0.009187) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.491006 (0.007445) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.497018 (0.014112) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.502017 (0.015507) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.502011 (0.009191) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.492004 (0.006745) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.530989 (0.009151) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.554980 (0.014104) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.543987 (0.010356) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.556988 (0.009167) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.540013 (0.013475) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.542018 (0.015390) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.542995 (0.004250) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.509012 (0.018058) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.526002 (0.006299) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.497980 (0.014602) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.492975 (0.017839) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500971 (0.023873) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.501016 (0.011887) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499038 (0.027533) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.520985 (0.010566) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501990 (0.007167) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.510984 (0.014179) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.500012 (0.010461) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500012 (0.010461) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.498013 (0.010408) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.498987 (0.010412) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.489007 (0.006953) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.511026 (0.018423) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.514002 (0.003947) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.533986 (0.011594) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.549984 (0.011819) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.538979 (0.014981) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.536971 (0.023829) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.519025 (0.019156) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.517008 (0.005806) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.504993 (0.015518) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498013 (0.013434) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.504999 (0.004953) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.471960 (0.035143) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.492010 (0.011108) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.492004 (0.006745) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.492990 (0.015228) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510981 (0.013406) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.494036 (0.025452) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.500986 (0.011634) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.501978 (0.015967) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.489007 (0.006953) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.508997 (0.005337) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.508997 (0.005337) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.492004 (0.006745) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.493982 (0.012783) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.543972 (0.020057) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.534984 (0.014152) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.537972 (0.022602) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.552972 (0.023877) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.528001 (0.000746) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.538994 (0.007421) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.518980 (0.014154) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.549978 (0.016640) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.505991 (0.008022) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.518033 (0.023846) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.542968 (0.022577) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.519984 (0.011859) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.518009 (0.011702) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497947 (0.037762) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.506027 (0.021454) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.498016 (0.012855) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.503015 (0.010880) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.490005 (0.008154) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.502011 (0.009191) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.493023 (0.016962) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.492004 (0.006745) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.465999 (0.012283) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.500012 (0.010461) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.491003 (0.005337) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.526994 (0.011806) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.537984 (0.012811) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.532979 (0.020859) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.538011 (0.016663) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.518027 (0.024108) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.557989 (0.008070) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.545986 (0.011580) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.555978 (0.020517) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.495016 (0.011879) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.524003 (0.014868) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.519987 (0.026173) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.506998 (0.015999) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.486987 (0.015329) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.501990 (0.017432) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.497995 (0.015130) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.507007 (0.004955) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.504990 (0.007163) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.514002 (0.020891) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.492004 (0.006745) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.492004 (0.006745) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500012 (0.009240) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.491003 (0.005337) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.486999 (0.000725) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.533965 (0.026554) with: {'batch_size': 8, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.548000 (0.008582) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.540978 (0.019012) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.531972 (0.021519) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.519999 (0.004951) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.521959 (0.029344) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.515003 (0.005351) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.552001 (0.007397) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.522028 (0.020149) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.544014 (0.016760) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.519019 (0.014315) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.531987 (0.009461) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.534975 (0.018281) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.537999 (0.002537) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.532976 (0.018960) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.529997 (0.002077) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.499023 (0.017834) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.496979 (0.020895) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.491003 (0.027053) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.503015 (0.020173) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.507987 (0.023898) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.527000 (0.003678) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.488015 (0.020162) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.495025 (0.019124) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517976 (0.016973) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.508017 (0.014092) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.527006 (0.007474) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.534981 (0.014243) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.520038 (0.027122) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.542983 (0.015458) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.524036 (0.034511) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.533986 (0.018731) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.538973 (0.019175) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.526014 (0.010586) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.542983 (0.015458) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.530983 (0.012214) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.552981 (0.013570) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.532976 (0.016951) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.538985 (0.011626) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.544985 (0.014392) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.532041 (0.029926) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.503009 (0.013812) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.494000 (0.001226) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.518012 (0.013930) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.533015 (0.010921) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.520005 (0.006060) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.550005 (0.019944) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.507981 (0.019907) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.535005 (0.006072) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.537016 (0.017629) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.561981 (0.018113) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.499020 (0.021297) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.537978 (0.017706) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.505020 (0.014606) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.516007 (0.005540) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.552990 (0.009296) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.528963 (0.026096) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.549975 (0.017760) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.546981 (0.014227) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.528007 (0.004984) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.524974 (0.018696) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.547991 (0.007976) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.518986 (0.009939) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.518015 (0.010901) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.514988 (0.010444) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.543981 (0.016573) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.519004 (0.003105) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.549963 (0.026524) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.530977 (0.016388) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.547982 (0.028684) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.533030 (0.029757) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.514020 (0.014201) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.547976 (0.016930) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.507993 (0.005509) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.514985 (0.011657) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.529976 (0.017988) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.505973 (0.021439) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.531046 (0.033651) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.540987 (0.009449) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.517014 (0.011656) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.516984 (0.011863) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.527012 (0.022514) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.535011 (0.012544) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.518018 (0.013261) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.499011 (0.010699) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507019 (0.013653) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.517991 (0.018294) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.512012 (0.020256) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.512036 (0.034499) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.509003 (0.022170) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.507049 (0.035396) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.540972 (0.020652) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.519010 (0.036253) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.540981 (0.016577) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.544023 (0.017031) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.542998 (0.008688) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.552990 (0.007096) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.530983 (0.020922) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.523997 (0.005329) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.559976 (0.017948) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.520002 (0.018446) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.540987 (0.010359) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.547964 (0.025392) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.512024 (0.017015) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.551977 (0.018915) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.532991 (0.018287) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.533983 (0.017128) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.489001 (0.002547) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.511985 (0.012885) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.488003 (0.012439) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.494006 (0.004404) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.530977 (0.033590) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.524018 (0.022377) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.520994 (0.009558) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.528013 (0.009543) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.516960 (0.031288) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.525004 (0.025904) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.535964 (0.037937) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.545018 (0.015393) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.520949 (0.037309) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.545998 (0.001822) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.515036 (0.028804) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.528981 (0.030108) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.519993 (0.017854) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.542015 (0.010934) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.524995 (0.008145) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.561987 (0.011698) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.549984 (0.019498) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.548015 (0.016249) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.540969 (0.022384) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.523008 (0.010293) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517982 (0.014093) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.501987 (0.009180) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.476009 (0.018291) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.509998 (0.001860) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.487976 (0.017015) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.520008 (0.012410) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.540972 (0.020061) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.539012 (0.012101) with: {'batch_size': 8, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.535970 (0.021177) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.535026 (0.020317) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.524962 (0.027059) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.504022 (0.019064) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.532952 (0.034060) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.522999 (0.000674) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.509995 (0.008154) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.508020 (0.019539) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.516019 (0.013666) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.526979 (0.020865) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.498010 (0.011113) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.534966 (0.024000) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.512024 (0.018044) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.516028 (0.023958) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.508023 (0.020363) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498010 (0.007167) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.514020 (0.047516) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.525016 (0.014219) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.506009 (0.032505) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.505011 (0.018844) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.502997 (0.024610) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.544976 (0.018945) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.538976 (0.017294) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.521986 (0.009934) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.546996 (0.011374) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.513993 (0.010975) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.539971 (0.039946) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.501025 (0.019132) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.532005 (0.022356) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.537975 (0.020154) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.512006 (0.009579) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.534984 (0.011839) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.537019 (0.013474) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.544985 (0.018093) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.547985 (0.016160) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.513028 (0.028746) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.550988 (0.009174) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.524015 (0.012927) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.535026 (0.020317) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.498004 (0.003078) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.530012 (0.012092) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.508020 (0.015411) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.525013 (0.026195) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.524980 (0.019506) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.497974 (0.018410) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.542989 (0.009137) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.537016 (0.014233) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.518021 (0.019264) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.542995 (0.010404) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.516031 (0.022058) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.541982 (0.012715) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.539980 (0.017882) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.545983 (0.018950) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.538979 (0.015572) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.523991 (0.008002) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.533974 (0.020229) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.544008 (0.016931) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.547002 (0.003964) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.523002 (0.011128) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.549981 (0.030095) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.519013 (0.023912) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.487020 (0.015384) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.517985 (0.024469) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.497965 (0.031562) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.532958 (0.032548) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.544011 (0.016667) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.528004 (0.004662) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.534990 (0.019682) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.548009 (0.006425) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517029 (0.020510) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.534945 (0.039494) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.510996 (0.011386) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.510996 (0.004629) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.507022 (0.020584) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.537990 (0.013072) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.493005 (0.006038) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.538979 (0.014981) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.529970 (0.025083) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.494995 (0.004305) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.510987 (0.026177) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.525007 (0.015532) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.512956 (0.031088) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.504993 (0.004938) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.518977 (0.016945) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.526967 (0.023402) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.500977 (0.017834) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.500983 (0.014081) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.511985 (0.010860) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.482036 (0.027698) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.501993 (0.006962) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.506057 (0.043778) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.500989 (0.008147) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.527995 (0.015121) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.529014 (0.011670) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.532982 (0.015302) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.521030 (0.023919) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.531972 (0.026974) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.518998 (0.008693) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.554003 (0.019738) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.513990 (0.007150) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.506015 (0.014445) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.539024 (0.019051) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.519016 (0.011395) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.527977 (0.018944) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.538991 (0.006763) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.541961 (0.030100) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.529988 (0.018032) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.539965 (0.025150) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.503012 (0.010464) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.500959 (0.029373) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.491024 (0.020217) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.519978 (0.015561) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.484994 (0.009581) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.511002 (0.003946) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.496976 (0.017002) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.514985 (0.010855) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.520032 (0.022666) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517994 (0.007438) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.542980 (0.019487) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.529982 (0.020362) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.525954 (0.036160) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.518986 (0.010526) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.544994 (0.023665) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.524968 (0.022867) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.548000 (0.001228) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.528990 (0.007129) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.537987 (0.013399) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.522969 (0.022409) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.539971 (0.020576) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.540990 (0.007113) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.531007 (0.008888) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.531969 (0.026344) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.547970 (0.021996) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517943 (0.048442) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.503003 (0.031946) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.511952 (0.038558) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.517964 (0.025435) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.530980 (0.017892) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.535997 (0.005322) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.498004 (0.018605) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.513013 (0.009523) with: {'batch_size': 8, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.488021 (0.014817) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.533003 (0.003272) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.530983 (0.022977) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.505023 (0.018984) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.526029 (0.021801) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.554977 (0.016897) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.514002 (0.006295) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.513981 (0.014271) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.493014 (0.014811) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.505991 (0.011683) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.500015 (0.011676) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.505994 (0.011817) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.495013 (0.011761) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.504016 (0.012863) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.498987 (0.010412) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.496985 (0.022297) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.502014 (0.011638) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.479018 (0.012745) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.492004 (0.006745) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.508994 (0.005602) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.506992 (0.010270) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.516978 (0.015947) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499988 (0.010461) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.518974 (0.019337) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.540954 (0.032644) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.533983 (0.018960) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.547970 (0.021160) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.531966 (0.024004) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.548000 (0.011034) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.533971 (0.021721) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.541002 (0.006304) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.507972 (0.025393) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.504999 (0.000699) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.511976 (0.025001) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.475017 (0.020927) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.475973 (0.024114) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.513996 (0.004626) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.507960 (0.033704) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.501010 (0.013102) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.503992 (0.005777) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.499011 (0.010699) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.500986 (0.011634) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.492004 (0.006745) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.488000 (0.011034) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.504990 (0.007163) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.506003 (0.005346) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.534016 (0.011416) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.550002 (0.003966) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.538997 (0.007640) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.536959 (0.028910) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.525010 (0.011138) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.539983 (0.012201) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.526979 (0.015588) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.545959 (0.028897) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.508008 (0.005794) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.519007 (0.029840) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.497974 (0.020275) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.543954 (0.036137) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.512959 (0.029864) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.517026 (0.020294) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.544005 (0.012776) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.491989 (0.021103) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.492004 (0.006745) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.514005 (0.004316) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.500015 (0.011676) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.509998 (0.003935) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.506986 (0.013086) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.510999 (0.000691) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.505994 (0.014133) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.491003 (0.005337) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.546972 (0.030515) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.538002 (0.025787) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.542980 (0.019487) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.531969 (0.023058) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.510025 (0.017843) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.518965 (0.025179) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.535991 (0.016006) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.512998 (0.008694) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.502988 (0.012060) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.502982 (0.014112) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.503956 (0.033876) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.482024 (0.018004) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.494000 (0.006130) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.501013 (0.010412) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.494036 (0.032873) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.512000 (0.001226) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.492004 (0.006745) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.501990 (0.011113) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.487041 (0.029864) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.470045 (0.032122) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.504004 (0.006752) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.494995 (0.006048) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.547988 (0.009178) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.538002 (0.008706) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.529961 (0.030116) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.515009 (0.006834) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.542000 (0.008582) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.530009 (0.016043) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.542968 (0.022577) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.532991 (0.006771) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.520976 (0.018975) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.521998 (0.013556) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.496002 (0.008696) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.492004 (0.011387) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.494009 (0.008022) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.504987 (0.010404) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.516004 (0.030781) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501013 (0.010412) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.486999 (0.000725) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.496011 (0.007765) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.499017 (0.012970) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.496985 (0.014442) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.492004 (0.006745) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.492975 (0.022993) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.501013 (0.010412) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.537975 (0.020154) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.543975 (0.020146) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.556023 (0.017907) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.541997 (0.007639) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.534963 (0.027870) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.540981 (0.013364) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.536959 (0.029323) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.485012 (0.008544) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507996 (0.003070) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.488033 (0.037528) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.503003 (0.017294) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.477019 (0.014259) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.504022 (0.016711) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.525013 (0.033182) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.514979 (0.015604) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498993 (0.006965) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.502011 (0.009191) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.507996 (0.006745) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.511997 (0.017292) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.512024 (0.018044) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.496979 (0.017787) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.510999 (0.002547) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.494003 (0.014862) with: {'batch_size': 16, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.519010 (0.009373) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.510025 (0.020213) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.521992 (0.008316) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.544014 (0.010610) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.510978 (0.017739) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.524989 (0.023384) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.501013 (0.009506) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.540978 (0.017702) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.531996 (0.030775) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.527992 (0.005744) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.510007 (0.017866) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.508991 (0.009714) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.529994 (0.005580) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.519948 (0.038327) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.517002 (0.013562) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.508997 (0.005337) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.495010 (0.007163) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.516004 (0.011395) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.508020 (0.015411) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.489972 (0.021574) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.521980 (0.019509) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.526994 (0.016482) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.513031 (0.022459) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.544011 (0.010745) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.564004 (0.009064) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.510016 (0.019547) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.536974 (0.024278) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.536962 (0.028132) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.545974 (0.019301) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.515033 (0.030482) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.547964 (0.026775) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.521974 (0.019333) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.513007 (0.005536) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.538976 (0.026832) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.538988 (0.013881) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.552978 (0.022208) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.535997 (0.002068) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.525016 (0.012889) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510028 (0.020132) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.502985 (0.011672) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498007 (0.015520) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.520014 (0.011659) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.491992 (0.012402) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.517979 (0.016535) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.504034 (0.026436) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.496997 (0.005344) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.515974 (0.018385) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.523997 (0.012436) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.529008 (0.010298) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.534016 (0.021610) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.529014 (0.013125) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.525004 (0.038113) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.531996 (0.021026) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.523979 (0.016528) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.540001 (0.014731) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.534969 (0.023054) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.531001 (0.017180) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.534001 (0.017180) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.549975 (0.022931) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.524015 (0.010909) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.538982 (0.016794) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.502014 (0.011638) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.526985 (0.010839) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.485006 (0.009562) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.537004 (0.013789) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.495990 (0.011119) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.513028 (0.036487) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.511026 (0.020287) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.511008 (0.023973) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.536009 (0.013834) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.535017 (0.012058) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.545995 (0.006006) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.548971 (0.028313) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.532979 (0.016516) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.504013 (0.013440) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.510025 (0.019144) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.532970 (0.021181) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.531975 (0.017785) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.519996 (0.018601) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.494989 (0.010705) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.532002 (0.023339) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.495037 (0.034201) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.529997 (0.005326) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.542992 (0.008296) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.540978 (0.020533) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.528981 (0.015269) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498987 (0.010412) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.491003 (0.005337) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.497992 (0.008339) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.486013 (0.013422) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.500006 (0.004412) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.470054 (0.038280) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.485989 (0.014525) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.547017 (0.015556) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.540999 (0.009829) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.528001 (0.012282) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.537990 (0.007117) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.536012 (0.024805) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.538970 (0.021455) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.523994 (0.021261) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.528951 (0.034919) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.549972 (0.020049) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.533012 (0.012095) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.520982 (0.018514) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.515998 (0.003932) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.536989 (0.009144) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.548962 (0.026802) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.541979 (0.014775) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.548986 (0.011577) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.503021 (0.017787) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.468996 (0.018612) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.500983 (0.012970) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.504019 (0.016628) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.487994 (0.026095) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.529991 (0.006775) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.486975 (0.021513) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.510025 (0.017674) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.547991 (0.016000) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.550017 (0.017211) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.536989 (0.010662) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.549019 (0.016679) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.534996 (0.006729) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.561978 (0.015502) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.530045 (0.032206) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.519001 (0.004958) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.541964 (0.025401) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.546978 (0.016644) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.549966 (0.025438) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.534978 (0.015922) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.536000 (0.008582) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.538008 (0.005835) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.538964 (0.026105) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.544979 (0.015564) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498010 (0.015222) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.491971 (0.025230) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.510037 (0.028882) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.508020 (0.017935) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.530980 (0.014557) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.533947 (0.043417) with: {'batch_size': 16, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.538976 (0.017294) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.520029 (0.025244) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.522981 (0.013389) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.515998 (0.011121) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.524027 (0.024114) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.525999 (0.002542) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.516999 (0.000682) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.522948 (0.044830) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.532985 (0.012861) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.525981 (0.013385) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.528993 (0.022606) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.531987 (0.009138) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.532940 (0.043752) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.486975 (0.017848) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.493985 (0.010605) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.493005 (0.006038) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.508997 (0.007651) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500027 (0.024087) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.507996 (0.016184) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.509030 (0.025130) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.487985 (0.011691) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.539012 (0.013948) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.516010 (0.007984) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.546984 (0.021551) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.554980 (0.027203) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.519001 (0.002559) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.507984 (0.021579) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.536986 (0.013055) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.538994 (0.011800) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.532991 (0.006311) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.529973 (0.022638) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.518959 (0.029039) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.543963 (0.034159) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.539953 (0.033144) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.534972 (0.020660) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.533977 (0.033588) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.534996 (0.006729) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.499988 (0.010461) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.508011 (0.021103) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.502023 (0.016974) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.511017 (0.027309) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.504007 (0.008867) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.505038 (0.028188) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.515992 (0.012386) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.532002 (0.011130) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.542974 (0.022737) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.538994 (0.007421) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.516978 (0.016684) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.545977 (0.017776) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.538976 (0.017294) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.530989 (0.007727) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.539992 (0.010244) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.542986 (0.010494) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.551986 (0.010483) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.518024 (0.019025) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.525984 (0.014162) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.533959 (0.029327) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.535008 (0.016926) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.529985 (0.014407) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.530989 (0.018823) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.489004 (0.033220) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.493973 (0.024094) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.494024 (0.023263) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.514038 (0.032555) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.530989 (0.009151) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.512006 (0.011826) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.512024 (0.020242) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.544985 (0.011618) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.514026 (0.019381) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.523029 (0.021797) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.533977 (0.016925) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.535991 (0.007989) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.511988 (0.008548) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.541997 (0.010022) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.549984 (0.014135) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.494015 (0.016199) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.516007 (0.010994) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.510972 (0.021546) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.547943 (0.040865) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.508026 (0.022795) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.515030 (0.022883) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.521983 (0.012226) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.505017 (0.012016) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.505994 (0.004404) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.505002 (0.006292) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.499014 (0.011634) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.473989 (0.040000) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.479048 (0.033900) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.532041 (0.029111) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.526988 (0.022485) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.527000 (0.008582) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.526011 (0.007807) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.511976 (0.025001) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.525022 (0.017784) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.519001 (0.000733) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.529005 (0.006067) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517002 (0.003949) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.546004 (0.011406) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.527006 (0.021276) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.521018 (0.013265) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.528969 (0.023957) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.530971 (0.020588) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.515027 (0.020462) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.505991 (0.011683) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.503012 (0.020251) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.475020 (0.015368) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.514988 (0.015917) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.507004 (0.021033) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497006 (0.005608) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499988 (0.013914) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.512968 (0.030733) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.534996 (0.003035) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.538997 (0.003205) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.558996 (0.013762) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.551012 (0.020280) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.524992 (0.016898) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.551012 (0.008636) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.519987 (0.013417) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.545992 (0.008293) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.525016 (0.014219) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.533983 (0.017128) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.551980 (0.014528) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.539974 (0.022740) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.543975 (0.017768) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.539977 (0.017783) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.518030 (0.021534) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.516031 (0.022463) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.505029 (0.025227) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.488036 (0.026142) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.492984 (0.023714) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.500027 (0.021447) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.488027 (0.019213) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.494992 (0.008342) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.525019 (0.027969) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.508994 (0.009566) with: {'batch_size': 16, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.500027 (0.027359) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.516031 (0.021921) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.509003 (0.007659) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.514994 (0.007440) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.517032 (0.024202) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.489010 (0.013093) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.523997 (0.007646) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.526994 (0.005583) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.478991 (0.027717) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.499988 (0.010461) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.504034 (0.030254) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.502020 (0.015403) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.485021 (0.015015) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.489001 (0.009832) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.490997 (0.003249) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.509012 (0.009252) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.494033 (0.023431) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507999 (0.004953) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.491003 (0.005337) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.511997 (0.007650) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.499988 (0.010461) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.501016 (0.021586) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499988 (0.010461) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.492001 (0.004953) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.536015 (0.011722) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.519028 (0.019844) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.517017 (0.014103) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.541017 (0.012313) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.538008 (0.019254) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.551009 (0.020642) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.522010 (0.009376) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.506995 (0.012756) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.515962 (0.029002) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.508979 (0.015612) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.501010 (0.013102) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.520970 (0.025094) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.479992 (0.010291) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.502014 (0.013096) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.500012 (0.010461) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517976 (0.018004) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.501013 (0.010412) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.498987 (0.010412) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.497009 (0.006353) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.498987 (0.010412) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.506000 (0.003678) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.502014 (0.010554) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.501990 (0.007962) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.536971 (0.025178) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.533971 (0.021018) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.545995 (0.004246) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.550976 (0.017278) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.524965 (0.024810) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.546987 (0.010352) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.532997 (0.012434) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.525001 (0.012282) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.486001 (0.002546) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.506000 (0.003678) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.491009 (0.006345) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.500980 (0.017925) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.492010 (0.007954) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.495007 (0.006959) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499976 (0.028810) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.515983 (0.015487) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501013 (0.010412) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.507996 (0.006745) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.492981 (0.018185) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.508997 (0.005337) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.495010 (0.007163) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.478029 (0.021034) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499020 (0.014598) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.516978 (0.016684) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.504972 (0.020111) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.510984 (0.015784) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.508014 (0.016730) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.547982 (0.016784) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.502991 (0.011686) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.531993 (0.013203) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.514005 (0.024775) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.495007 (0.005513) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.496985 (0.012902) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.504016 (0.011374) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.490002 (0.008695) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.522007 (0.005547) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.512989 (0.007752) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.501013 (0.011767) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.503986 (0.013090) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498987 (0.010412) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498987 (0.010412) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.500012 (0.010461) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.508994 (0.007445) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.498987 (0.010412) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.509003 (0.007659) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499011 (0.010699) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.508997 (0.007651) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.532994 (0.014122) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.536012 (0.013945) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.537972 (0.020066) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.527006 (0.011834) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.551947 (0.040158) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.520026 (0.018759) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.520005 (0.006060) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.531031 (0.022079) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.507993 (0.005509) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.474064 (0.045587) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.517994 (0.018866) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.492007 (0.008857) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.479986 (0.013115) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.502005 (0.003535) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.507022 (0.022267) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.507972 (0.020697) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.494980 (0.014188) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.502979 (0.015620) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.497012 (0.008561) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.488000 (0.001226) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.501013 (0.010412) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.507996 (0.004631) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.504978 (0.016700) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.523005 (0.022354) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.545998 (0.006276) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.545027 (0.019755) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.534996 (0.011378) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.547988 (0.009178) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.517991 (0.009706) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.528999 (0.000665) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.526997 (0.005327) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.534999 (0.017176) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.501010 (0.007965) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.499002 (0.006290) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.514011 (0.010714) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.489993 (0.005532) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.508017 (0.012020) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.531978 (0.015926) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.506015 (0.028981) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.485998 (0.001886) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.500989 (0.010699) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.501013 (0.010412) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500012 (0.010461) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.499997 (0.012442) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.500012 (0.010461) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.491006 (0.007445) with: {'batch_size': 32, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.531981 (0.025805) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.526931 (0.048765) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.545992 (0.031154) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.543996 (0.004600) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.546972 (0.028687) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.548995 (0.008130) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.538008 (0.006788) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.500009 (0.006814) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.542998 (0.025781) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.529955 (0.032587) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.525981 (0.014255) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.536989 (0.009144) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.536980 (0.014129) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.541994 (0.004355) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498987 (0.010412) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.492004 (0.006745) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.492004 (0.003070) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.513001 (0.009835) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.494995 (0.006048) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.508994 (0.007445) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.516999 (0.017177) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.509018 (0.016845) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.542003 (0.022175) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.547997 (0.010020) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.543996 (0.013766) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.549984 (0.021548) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.520994 (0.011809) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.541982 (0.013179) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.524995 (0.006023) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.537019 (0.019949) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.511994 (0.021265) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.505973 (0.039266) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.535991 (0.018286) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.542983 (0.014031) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.520991 (0.016015) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.528022 (0.016743) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.537990 (0.007117) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.495010 (0.022004) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.478017 (0.025109) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.489981 (0.015318) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.506015 (0.014445) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.525007 (0.022622) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.561969 (0.023018) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.502997 (0.007654) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.542983 (0.017119) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.529002 (0.001902) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.534984 (0.025869) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.543975 (0.021447) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.547005 (0.008189) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.552984 (0.017548) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.528004 (0.013787) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.542998 (0.001825) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.540993 (0.010958) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.525016 (0.014219) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.537007 (0.013239) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.555007 (0.008907) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.544988 (0.012018) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.536000 (0.008582) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.548000 (0.006130) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.555978 (0.015510) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.514026 (0.021443) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.501987 (0.011764) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.491000 (0.006130) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.488018 (0.020378) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.506009 (0.009728) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.524009 (0.020631) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.517982 (0.015319) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.515992 (0.008322) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.517997 (0.005332) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.520008 (0.006766) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.518030 (0.025140) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.541985 (0.012850) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.517997 (0.029498) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.523979 (0.017755) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.516999 (0.004951) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.529979 (0.016520) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.507993 (0.022612) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.531972 (0.023902) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.493017 (0.015497) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.531957 (0.030429) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.491009 (0.008019) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.532982 (0.016800) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.531969 (0.034713) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.494980 (0.014188) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.495010 (0.007163) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.484014 (0.013077) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.500986 (0.011634) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.488977 (0.016986) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.479992 (0.023976) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.507004 (0.004644) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.549981 (0.014223) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.524950 (0.036970) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.523020 (0.029383) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.525990 (0.009325) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.520973 (0.019043) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.514026 (0.019381) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.511029 (0.039983) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.538005 (0.010443) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.526982 (0.012736) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.533030 (0.021555) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.531990 (0.011087) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.539989 (0.014485) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.546978 (0.017695) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.532982 (0.014074) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.546957 (0.031856) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.549969 (0.021828) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.497986 (0.010554) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.488003 (0.003230) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.499988 (0.010461) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.503980 (0.015395) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.507019 (0.014299) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.516996 (0.003058) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.496026 (0.018402) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.545977 (0.016182) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.541008 (0.028769) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.529985 (0.014407) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.528013 (0.019485) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.538967 (0.023385) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.547979 (0.015560) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.536962 (0.028132) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.548974 (0.033614) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.547023 (0.017895) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.549975 (0.020139) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.530009 (0.006854) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.551980 (0.015333) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.558975 (0.017747) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.545977 (0.017776) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.486049 (0.035957) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.509983 (0.012243) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.492004 (0.004631) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.505035 (0.025802) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.517014 (0.013112) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.501939 (0.047343) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.515006 (0.009581) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.507010 (0.009360) with: {'batch_size': 32, 'depth': 2, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.524986 (0.009930) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498996 (0.006750) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.544997 (0.003200) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.495996 (0.006752) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.533977 (0.025440) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.538964 (0.025641) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.541994 (0.021256) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.528004 (0.030783) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.512000 (0.023293) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.510993 (0.010977) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.525990 (0.009325) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.508017 (0.014092) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.513993 (0.015514) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.524980 (0.014146) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.540981 (0.013364) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.502020 (0.014184) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.497009 (0.008026) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.495007 (0.004938) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.504996 (0.011388) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.537972 (0.020656) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.517029 (0.023894) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.556976 (0.026815) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.545983 (0.017116) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.527998 (0.006282) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.512992 (0.008325) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.520994 (0.011809) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.532964 (0.025649) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.527968 (0.025118) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.554018 (0.015404) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.540969 (0.029356) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.502005 (0.004302) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.521989 (0.009162) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.536048 (0.038618) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.537010 (0.007221) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.518033 (0.023846) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.488986 (0.010566) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498984 (0.011887) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.483007 (0.034678) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.514005 (0.022351) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.514988 (0.009221) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.529005 (0.004333) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.488998 (0.001882) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.533006 (0.007479) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.529023 (0.016472) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.511035 (0.025221) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.555981 (0.014215) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.534972 (0.021515) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.542003 (0.014872) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.502002 (0.008698) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.513993 (0.027417) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.530015 (0.014470) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.529997 (0.003213) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.525004 (0.003113) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.545989 (0.012473) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.511026 (0.018423) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.532997 (0.007642) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.500977 (0.016430) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498013 (0.017341) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.522013 (0.023914) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.511014 (0.020888) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.507978 (0.030066) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.497962 (0.027097) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.521989 (0.012494) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.519004 (0.006761) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.2, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.507999 (0.014728) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.540996 (0.021024) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.531975 (0.017785) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.532994 (0.016480) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.509024 (0.017360) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.515980 (0.014577) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.524977 (0.016212) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.533989 (0.012483) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.498019 (0.032339) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.501996 (0.013778) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.527024 (0.021693) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.510996 (0.016183) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.527980 (0.014561) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.521986 (0.010522) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.500009 (0.008029) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.506995 (0.006038) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.491006 (0.005602) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.509027 (0.021458) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.511994 (0.028512) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.500009 (0.009723) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.510996 (0.011386) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.493002 (0.011123) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.524012 (0.009271) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.511020 (0.014197) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.543981 (0.027923) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.557995 (0.015111) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.537978 (0.022223) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.558004 (0.004688) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.546975 (0.042995) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.542974 (0.020217) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.498966 (0.024299) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.519999 (0.009831) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.522987 (0.013414) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.522999 (0.009831) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.518030 (0.022887) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.546981 (0.019869) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.499011 (0.018840) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.549001 (0.012284) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.483046 (0.033044) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.511988 (0.009225) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.509024 (0.017011) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.508997 (0.010031) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.513984 (0.011349) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.499008 (0.023969) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.492999 (0.004956) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 10, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.540984 (0.014145) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.511020 (0.014614) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.551995 (0.017509) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.545980 (0.014536) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.519945 (0.039132) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.512986 (0.011620) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.528990 (0.015205) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.514005 (0.019934) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.535973 (0.020395) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.528996 (0.011380) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.532997 (0.003211) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.537984 (0.012811) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "0.541979 (0.015568) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.534975 (0.017780) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.544964 (0.025632) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 0.0001, 'nodes': 500, 'optimizer': 'adam'}\n",
      "0.493029 (0.021757) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'rmsprop'}\n",
      "0.499014 (0.013093) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 50, 'optimizer': 'adam'}\n",
      "0.513004 (0.018608) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'rmsprop'}\n",
      "0.487982 (0.013253) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 100, 'optimizer': 'adam'}\n",
      "0.520997 (0.010028) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'rmsprop'}\n",
      "nan (nan) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 250, 'optimizer': 'adam'}\n",
      "0.541985 (0.014395) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'rmsprop'}\n",
      "0.518998 (0.033130) with: {'batch_size': 32, 'depth': 3, 'dropout_rate': 0.5, 'epochs': 15, 'learning_rate': 1e-05, 'nodes': 500, 'optimizer': 'adam'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100000\n",
      "800/800 [==============================] - 1s 1ms/sample - loss: 0.7049 - acc: 0.4712 - val_loss: 0.7033 - val_acc: 0.4700\n",
      "Epoch 2/100000\n",
      "800/800 [==============================] - 1s 768us/sample - loss: 0.6979 - acc: 0.5225 - val_loss: 0.6980 - val_acc: 0.5100\n",
      "Epoch 3/100000\n",
      "800/800 [==============================] - 1s 716us/sample - loss: 0.6837 - acc: 0.5688 - val_loss: 0.6922 - val_acc: 0.5250\n",
      "Epoch 4/100000\n",
      "800/800 [==============================] - 1s 732us/sample - loss: 0.6812 - acc: 0.5425 - val_loss: 0.6956 - val_acc: 0.5150\n",
      "Epoch 5/100000\n",
      "800/800 [==============================] - 1s 823us/sample - loss: 0.6847 - acc: 0.5462 - val_loss: 0.6929 - val_acc: 0.5100\n",
      "Epoch 6/100000\n",
      "800/800 [==============================] - 1s 726us/sample - loss: 0.6806 - acc: 0.5663 - val_loss: 0.6974 - val_acc: 0.5200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.82      0.57       357\n",
      "         1.0       0.63      0.23      0.34       489\n",
      "\n",
      "    accuracy                           0.48       846\n",
      "   macro avg       0.53      0.52      0.45       846\n",
      "weighted avg       0.55      0.48      0.44       846\n",
      "\n",
      "Test accuracy: 0.478\n"
     ]
    }
   ],
   "source": [
    "historylist_sp = []\n",
    "for i,params in enumerate(tqdm(test_params)): \n",
    "    bs = params.pop('batch_size')\n",
    "    model = create_model(**params)\n",
    "    params.update({'batch_size': bs})\n",
    "    history = model.fit(x_train_sp, y_train_sp,\n",
    "                        epochs=10000,\n",
    "                        batch_size=params['batch_size'],\n",
    "                        verbose=0,\n",
    "                        callbacks=[EarlyStopping(monitor='val_acc', patience=2, restore_best_weights=True)],\n",
    "                        validation_split=0.2)\n",
    "    historylist_sp.append(history)\n",
    "max_acc_sp = -1\n",
    "max_idx_sp = -1\n",
    "for i,hist in enumerate(historylist_sp):\n",
    "    if max(hist.history['val_acc']) > max_acc_sp: \n",
    "        max_acc_sp = max(hist.history['val_acc'])\n",
    "        max_idx_sp = i\n",
    "    \n",
    "print(\"Best val acc:\",max_acc_sp)\n",
    "print(\"For config: \",test_params[max_idx_sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = test_params[max_idx_sp].pop('batch_size')\n",
    "model_ff_sp = create_model(**test_params[max_idx_sp])\n",
    "test_params[max_idx_sp].update({'batch_size': bs})\n",
    "\n",
    "history_sp = model_ff_sp.fit(x_train_sp, y_train_sp,\n",
    "                               epochs=100000,\n",
    "                               batch_size = bs,\n",
    "                               verbose=1,\n",
    "                               callbacks = [EarlyStopping(monitor='val_acc', patience=10, restore_best_weights=True)],\n",
    "                               validation_split=0.2)\n",
    "savename_sp = \"nn_bs{}_n1{}_n2{}_dr{}_lr{}_opt{}\".format(test_params[max_idx_sp]['batch_size'],\n",
    "                                                          test_params[max_idx_sp]['nodes1'],\n",
    "                                                          test_params[max_idx_sp]['nodes2'],\n",
    "                                                          test_params[max_idx_sp]['dropout_rate'],\n",
    "                                                          test_params[max_idx_sp]['learning_rate'],\n",
    "                                                          test_params[max_idx_sp]['optimizer'])\n",
    "plot_results_nn(history_sp,model_ff_sp,x_test_sp, y_test_sp,save=True, name=savename_sp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network - GloVe embeddings as embedded layer\n",
    "Similar to the previous neural network, but with an embedded layer that is trained together with the weights in the feed-forward network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for custom 'MergeEmedding'-layer which averages \n",
    "# the embeddings over all words after the embedding layer \n",
    "def merge_embeddings(x):\n",
    "    # Sum the embeddings for every word slot. If this is zero, there is no word in this slot\n",
    "    non_zero = K.sum(K.cast(K.not_equal(K.sum(x,axis=2),0),tf.float32))\n",
    "    return K.sum(x,axis=1) / non_zero\n",
    "\n",
    "def merge_output_shape(input_shape):\n",
    "    return input_shape[0], input_shape[-1]\n",
    "\n",
    "\n",
    "def create_model_emb_ff(nodes1=100, nodes2=50, dropout_rate=0.3, optimizer='rmsprop',learning_rate=0.001):\n",
    "    if optimizer.lower() == 'rmsprop': \n",
    "        optimizer = RMSprop(learning_rate = learning_rate)\n",
    "    elif optimizer.lower() == 'adam':\n",
    "        optimizer = Adam(learning_rate = learning_rate)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size+1,\n",
    "                        output_dim=300,\n",
    "                        mask_zero=True,\n",
    "                        weights=[trainable_embeddings],\n",
    "                        input_length=maxlen))\n",
    "    model.add(Lambda(merge_embeddings, output_shape=merge_output_shape))\n",
    "    if nodes1 == 0: \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "        return model \n",
    "    model.add(Dense(nodes1))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    if nodes2 == 0: \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "        return model\n",
    "    model.add(Dense(nodes2))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] batch_size=4, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=4, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, score=0.488, total=  23.3s\n",
      "[CV] batch_size=4, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   23.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  batch_size=4, depth=1, dropout_rate=0.5, epochs=5, learning_rate=0.0001, nodes=100, score=0.474, total=  23.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   46.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   46.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.481000 using {'batch_size': 4, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100}\n",
      "0.481000 (0.007000) with: {'batch_size': 4, 'depth': 1, 'dropout_rate': 0.5, 'epochs': 5, 'learning_rate': 0.0001, 'nodes': 100}\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6947 - acc: 0.4837 - val_loss: 0.6921 - val_acc: 0.4900\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6938 - acc: 0.5000 - val_loss: 0.6905 - val_acc: 0.6000\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6936 - acc: 0.5150 - val_loss: 0.6904 - val_acc: 0.5850\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6922 - acc: 0.5225 - val_loss: 0.6896 - val_acc: 0.5200\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6918 - acc: 0.5200 - val_loss: 0.6906 - val_acc: 0.5050\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 9s 11ms/sample - loss: 0.6931 - acc: 0.5125 - val_loss: 0.6897 - val_acc: 0.5500\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6920 - acc: 0.5025 - val_loss: 0.6887 - val_acc: 0.5850\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6914 - acc: 0.5500 - val_loss: 0.6884 - val_acc: 0.5650\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6914 - acc: 0.5337 - val_loss: 0.6883 - val_acc: 0.5950\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6907 - acc: 0.5213 - val_loss: 0.6891 - val_acc: 0.5500\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6905 - acc: 0.5387 - val_loss: 0.6893 - val_acc: 0.5400\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6889 - acc: 0.5362 - val_loss: 0.6881 - val_acc: 0.6050\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6876 - acc: 0.5537 - val_loss: 0.6925 - val_acc: 0.4950\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6894 - acc: 0.5200 - val_loss: 0.6884 - val_acc: 0.5500\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6879 - acc: 0.5475 - val_loss: 0.6876 - val_acc: 0.5950\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6874 - acc: 0.5562 - val_loss: 0.6881 - val_acc: 0.5500\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6852 - acc: 0.5700 - val_loss: 0.6922 - val_acc: 0.4950\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 8s 10ms/sample - loss: 0.6848 - acc: 0.5638 - val_loss: 0.6925 - val_acc: 0.4950\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       771\n",
      "         1.0       0.07      0.03      0.04        75\n",
      "\n",
      "    accuracy                           0.88       846\n",
      "   macro avg       0.49      0.50      0.49       846\n",
      "weighted avg       0.84      0.88      0.86       846\n",
      "\n",
      "Test accuracy: 0.883\n"
     ]
    }
   ],
   "source": [
    "historylist_emb_1yr = []\n",
    "for i,params in enumerate(tqdm(test_params)): \n",
    "    bs = params.pop('batch_size')\n",
    "    model = create_model_emb_ff(**params)\n",
    "    params.update({'batch_size': bs})\n",
    "    history = model.fit(x_train_seq_1yr, y_train_1yr,\n",
    "                        epochs=10000,\n",
    "                        batch_size=params['batch_size'],\n",
    "                        verbose=0,\n",
    "                        callbacks=[EarlyStopping(monitor='val_acc', patience=2, restore_best_weights=True)],\n",
    "                        validation_split=0.2)\n",
    "    historylist_emb_1yr.append(history)\n",
    "max_acc_emb_1yr = -1\n",
    "max_idx_emb_1yr = -1\n",
    "for i,hist in enumerate(historylist_emb_1yr):\n",
    "    if max(hist.history['val_acc']) > max_acc_emb_1yr: \n",
    "        max_acc_emb_1yr = max(hist.history['val_acc'])\n",
    "        max_idx_emb_1yr = i\n",
    "    \n",
    "print(\"Best val acc:\",max_acc_emb_1yr)\n",
    "print(\"For config: \",test_params[max_idx_emb_1yr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = test_params[max_idx_emb_1yr].pop('batch_size')\n",
    "model_emb_1yr = create_model_emb_ff(**test_params[max_idx_emb_1yr])\n",
    "test_params[max_idx_emb_1yr].update({'batch_size': bs})\n",
    "\n",
    "history_emb_1yr = model_emb_1yr.fit(x_train_seq_1yr, y_train_1yr,\n",
    "                                    epochs=100000,\n",
    "                                    batch_size = bs,\n",
    "                                    verbose=1,\n",
    "                                    callbacks = [EarlyStopping(monitor='val_acc', patience=5, restore_best_weights=True)],\n",
    "                                    validation_split=0.2)\n",
    "savename_emb_1yr = \"nn_emb_bs{}_n1{}_n2{}_dr{}_lr{}_opt{}\".format(test_params[max_idx_emb_1yr]['batch_size'],\n",
    "                                                              test_params[max_idx_emb_1yr]['nodes1'],\n",
    "                                                              test_params[max_idx_emb_1yr]['nodes2'],\n",
    "                                                              test_params[max_idx_emb_1yr]['dropout_rate'],\n",
    "                                                              test_params[max_idx_emb_1yr]['learning_rate'],\n",
    "                                                              test_params[max_idx_emb_1yr]['optimizer'])\n",
    "plot_results_nn(history_emb_1yr,model_emb_1yr,x_test_1yr, y_test_1yr,save=True, name=savename_emb_1yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historylist_emb_3yr = []\n",
    "for i,params in enumerate(tqdm(test_params)): \n",
    "    bs = params.pop('batch_size')\n",
    "    model = create_model_emb_ff(**params)\n",
    "    params.update({'batch_size': bs})\n",
    "    history = model.fit(x_train_seq_3yr, y_train_3yr,\n",
    "                        epochs=10000,\n",
    "                        batch_size=params['batch_size'],\n",
    "                        verbose=0,\n",
    "                        callbacks=[EarlyStopping(monitor='val_acc', patience=2, restore_best_weights=True)],\n",
    "                        validation_split=0.2)\n",
    "    historylist_emb_3yr.append(history)\n",
    "max_acc_emb_3yr = -1\n",
    "max_idx_emb_3yr = -1\n",
    "for i,hist in enumerate(historylist_emb_3yr):\n",
    "    if max(hist.history['val_acc']) > max_acc_emb_3yr: \n",
    "        max_acc_emb_3yr = max(hist.history['val_acc'])\n",
    "        max_idx_emb_3yr = i\n",
    "    \n",
    "print(\"Best val acc:\",max_acc_emb_3yr)\n",
    "print(\"For config: \",test_params[max_idx_emb_3yr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = test_params[max_idx_emb_3yr].pop('batch_size')\n",
    "model_emb_3yr = create_model_emb_ff(**test_params[max_idx_emb_3yr])\n",
    "test_params[max_idx_emb_3yr].update({'batch_size': bs})\n",
    "\n",
    "history_emb_3yr = model_emb_3yr.fit(x_train_seq_3yr, y_train_3yr,\n",
    "                                    epochs=100000,\n",
    "                                    batch_size = bs,\n",
    "                                    verbose=1,\n",
    "                                    callbacks = [Earlystopping(monitor='val_acc', patience=5, restore_best_weights=True)],\n",
    "                                    validation_split=0.2)\n",
    "savename_emb_3yr = \"nn_emb_bs{}_n1{}_n2{}_dr{}_lr{}_opt{}\".format(test_params[max_idx_emb_3yr]['batch_size'],\n",
    "                                                              test_params[max_idx_emb_3yr]['nodes1'],\n",
    "                                                              test_params[max_idx_emb_3yr]['nodes2'],\n",
    "                                                              test_params[max_idx_emb_3yr]['dropout_rate'],\n",
    "                                                              test_params[max_idx_emb_3yr]['learning_rate'],\n",
    "                                                              test_params[max_idx_emb_3yr]['optimizer'])\n",
    "plot_results_nn(history_emb_3yr,model_emb_3yr,x_test_3yr, y_test_3yr,save=True, name=savename_emb_3yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S&P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historylist_emb_sp = []\n",
    "for i,params in enumerate(tqdm(test_params)): \n",
    "    bs = params.pop('batch_size')\n",
    "    model = create_model_emb_ff(**params)\n",
    "    params.update({'batch_size': bs})\n",
    "    history = model.fit(x_train_seq_sp, y_train_sp,\n",
    "                        epochs=10000,\n",
    "                        batch_size=params['batch_size'],\n",
    "                        verbose=0,\n",
    "                        callbacks=[EarlyStopping(monitor='val_acc', patience=2, restore_best_weights=True)],\n",
    "                        validation_split=0.2)\n",
    "    historylist_emb_sp.append(history)\n",
    "max_acc_emb_sp = -1\n",
    "max_idx_emb_sp = -1\n",
    "for i,hist in enumerate(historylist_emb_sp):\n",
    "    if max(hist.history['val_acc']) > max_acc_emb_sp: \n",
    "        max_acc_emb_sp = max(hist.history['val_acc'])\n",
    "        max_idx_emb_sp = i\n",
    "    \n",
    "print(\"Best val acc:\",max_acc_emb_sp)\n",
    "print(\"For config: \",test_params[max_idx_emb_sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = test_params[max_idx_emb_sp].pop('batch_size')\n",
    "model_emb_sp = create_model_emb_ff(**test_params[max_idx_emb_sp])\n",
    "test_params[max_idx_emb_sp].update({'batch_size': bs})\n",
    "\n",
    "history_emb_sp = model_emb_sp.fit(x_train_seq_sp, y_train_sp,\n",
    "                                    epochs=100000,\n",
    "                                    batch_size = bs,\n",
    "                                    verbose=1,\n",
    "                                    callbacks = [Earlystopping(monitor='val_acc', patience=5, restore_best_weights=True)],\n",
    "                                    validation_split=0.2)\n",
    "savename_emb_sp = \"nn_emb_bs{}_n1{}_n2{}_dr{}_lr{}_opt{}\".format(test_params[max_idx_emb_sp]['batch_size'],\n",
    "                                                              test_params[max_idx_emb_sp]['nodes1'],\n",
    "                                                              test_params[max_idx_emb_sp]['nodes2'],\n",
    "                                                              test_params[max_idx_emb_sp]['dropout_rate'],\n",
    "                                                              test_params[max_idx_emb_sp]['learning_rate'],\n",
    "                                                              test_params[max_idx_emb_sp]['optimizer'])\n",
    "plot_results_nn(history_emb_sp,model_emb_sp,x_test_sp, y_test_sp,save=True, name=savename_emb_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network - GloVe embeddings and Bidirectional LSTM\n",
    "The same embeddings as in the previous model, but with a bidircetional LSTM rather than a multi layer perceptron the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_lstm(nodes=128, dropout_rate=0.3, recurrent_dropout=0.3, optimizer='rmsprop',learning_rate=0.001):\n",
    "    if optimizer == 'rmsprop': \n",
    "        optimizer = RMSprop(learning_rate = learning_rate)\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate = learning_rate)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size+1,\n",
    "                        output_dim=300,\n",
    "                        mask_zero=True,\n",
    "                        weights=[trainable_embeddings],\n",
    "                        input_length=maxlen))\n",
    "    model.add(Bidirectional(LSTM(nodes, recurrent_dropout=recurrent_dropout)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39966.666666666664"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "479600 / 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 year rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 2327s 3s/sample - loss: 0.7242 - acc: 0.5225 - val_loss: 0.6996 - val_acc: 0.4950\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 2571s 3s/sample - loss: 0.6495 - acc: 0.6438 - val_loss: 0.7020 - val_acc: 0.5350\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 2312s 3s/sample - loss: 0.5846 - acc: 0.7613 - val_loss: 0.7125 - val_acc: 0.5250\n"
     ]
    }
   ],
   "source": [
    "earlystop_lstm = EarlyStopping(monitor='val_acc',\n",
    "                               patience=2,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "lstm_1yr_mod = create_model_lstm() \n",
    "lstm_1yr_hist = lstm_1yr_mod.fit(x_train_1yr_seq, y_train_1yr,\n",
    "                                 epochs=10,\n",
    "                                 validation_split=0.2, \n",
    "                                 verbose=1,\n",
    "                                 batch_size=64,\n",
    "                                 callbacks=[earlystop_lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a cross-validation to find good values of hyperparameters\n",
    "lstm_mod = KerasClassifier(build_fn=create_model_lstm, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [8,32,64]\n",
    "batch_size = [4]\n",
    "epochs = [4,5]\n",
    "epochs = [5]\n",
    "nodes = [100,250]\n",
    "nodes = [100]\n",
    "dropout_rates = [0.3,0.5]\n",
    "dropout_rates = [0.5]\n",
    "learning_rates = [1e-3, 1e-3, 1e-4, 1e-5]\n",
    "learning_rates = [1e-4]\n",
    "\n",
    "optimizers = ['rmsprop','adam']\n",
    "lstm_param_grid = dict(batch_size=batch_size, \n",
    "                         epochs=epochs, \n",
    "                         nodes=nodes, \n",
    "                         dropout_rate=dropout_rates, \n",
    "                       \n",
    "                         learning_rate=learning_rates)\n",
    "lstm_grid = GridSearchCV(estimator=lstm_mod,\n",
    "                           param_grid=lstm_param_grid, \n",
    "                           n_jobs=1, \n",
    "                           cv=2, \n",
    "                           verbose=10)\n",
    "with parallel_backend('threading'):    # This is a bug work-around mentioned in https://github.com/scikit-learn/scikit-learn/issues/12546\n",
    "    lstm_grid_result = lstm_grid.fit(x_train_1yr_seq, y_train_1yr)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (lstm_grid_result.best_score_, lstm_grid_result.best_params_))\n",
    "means = lstm_grid_result.cv_results_['mean_test_score']\n",
    "stds = lstm_grid_result.cv_results_['std_test_score']\n",
    "params = lstm_grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "model_1yr_lstm = create_model_lstm(nodes=nn_emb_grid_result.best_params_['nodes'],\n",
    "                                    depth=nn_emb_grid_result.best_params_['depth'],\n",
    "                                    dropout_rate=nn_emb_grid_result.best_params_['dropout_rate'],\n",
    "                                    learning_rate=nn_emb_grid_result.best_params_['learning_rate'])\n",
    "\n",
    "history_1yr_lstm = model_1yr_lstm.fit(x_train_1yr_seq, y_train_1yr,\n",
    "                                    validation_split=0.2,\n",
    "                                    epochs=20,\n",
    "                                    batch_size=nn_emb_grid_result.best_params_['batch_size'],\n",
    "                                    callbacks=[earlystop],\n",
    "                                    verbose=1)\n",
    "\n",
    "plot_results_nn(history_1yr_lstm,\n",
    "                model_1yr_lstm,\n",
    "                x_test_1yr_seq,\n",
    "                y_test_1yr,\n",
    "                save=True,\n",
    "                name='lstm_1yr_n{}_de{}_dr{}_lr{}'.format(lstm_grid_result.best_params_['nodes'],\n",
    "                                                            lstm_grid_result.best_params_['depth'],\n",
    "                                                            lstm_grid_result.best_params_['dropout_rate'],\n",
    "                                                            lstm_grid_result.best_params_['learning_rate']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lstm1 = 128\n",
    "n_lstm2 = 128\n",
    "n_dense = 50\n",
    "dr_rate = 0.3\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=vocab_size+1,\n",
    "                        output_dim=300,\n",
    "                        mask_zero=True,\n",
    "                        weights=[trainable_embeddings],\n",
    "                       trainable=True))\n",
    "lstm_model.add(Bidirectional(LSTM(n_lstm1, recurrent_dropout=0.2)))\n",
    "lstm_model.add(Dropout(dr_rate))\n",
    "lstm_model.add(Dense(n_dense))\n",
    "lstm_model.add(Dropout(dr_rate))\n",
    "lstm_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(optimizer='rmsprop', metrics=['acc'], loss='binary_crossentropy')\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_history = lstm_model.fit(x_train_pad, y_train,\n",
    "                            batch_size=64,\n",
    "                            validation_split=0.2,\n",
    "                            epochs=10,\n",
    "                            callbacks=[earlystop])\n",
    "save = False\n",
    "\n",
    "if save: \n",
    "    plot_results_nn(lstm_history, lstm_model, x_test_pad, y_test,save=save,name='lstm_l1{}_l2{}_d{}_dr{}'.format(n_lstm1,\n",
    "                                                                                                          n_lstm2,\n",
    "                                                                                                          n_dense,\n",
    "                                                                                                          dr_rate))\n",
    "else: \n",
    "    plot_results_nn(lstm_history, lstm_model, x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gru1 = 20\n",
    "n_gru2 = 20\n",
    "n_dense = 50\n",
    "dr_rate = 0.3\n",
    "\n",
    "gru_model = Sequential()\n",
    "gru_model.add(Embedding(input_dim=vocab_size+1,\n",
    "                        output_dim=300,\n",
    "                        mask_zero=True,\n",
    "                        weights=[trainable_embeddings],\n",
    "                       trainable=True))\n",
    "gru_model.add(Bidirectional(GRU(n_gru1, recurrent_dropout=0.2, return_sequences=True)))\n",
    "gru_model.add(Dropout(dr_rate))\n",
    "gru_model.add(Bidirectional(GRU(n_gru2)))\n",
    "gru_model.add(Dropout(dr_rate))\n",
    "gru_model.add(Dense(n_dense))\n",
    "gru_model.add(Dropout(dr_rate))\n",
    "gru_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "gru_model.compile(optimizer='rmsprop', metrics=['acc'], loss='binary_crossentropy')\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_history = gru_model.fit(x_train_pad, y_train,\n",
    "                            batch_size=64,\n",
    "                            validation_split=0.2,\n",
    "                            epochs=4)\n",
    "save = False\n",
    "\n",
    "if save: \n",
    "    plot_results_nn(gru_history, gru_model, x_test_pad, y_test,save=save,name='gru_l1{}_l2{}_d{}_dr{}'.format(n_gru1,\n",
    "                                                                                                          n_gru2,\n",
    "                                                                                                          n_dense,\n",
    "                                                                                                          dr_rate))\n",
    "else: \n",
    "    plot_results_nn(gru_history, gru_model, x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The following results were achieved on the independent test set on the IMDB dataset. Pre-trained GloVe-embeddings were used and \n",
    "\n",
    "| Model |  Test Accuracy (%) | Hyperparameters |\n",
    "| :----- | --------------- | --- | \n",
    "| Random Classifier | 50.3 | N/A |\n",
    "| Logistic Regression | 85.2  | N/A |\n",
    "| Linear Discriminant Analysis | 85.3  | N/A |\n",
    "| Support Vector Machine | 84.1 | N/A |\n",
    "| Random Forest | 80.9  | n_estimators=5000, max_depth=50 |\n",
    "| XGBoost | __86.1__ | n_estimators=500 |\n",
    "| Multi Layer Perceptron (Pre-trained) | 85.2 | batch_size=16,depth=3,dropout_rate=0.2,nodes=250 |\n",
    "| Multi Layer Perceptron (Cont. training) |  | batch_size=16,depth=3,dropout_rate=0.2,nodes=250 |\n",
    "| LSTM | | n_lstm1=20, n_lstm2=20, nodes=50,dropout_rate=0.3 | \n",
    "\n",
    "XGBoost gives the best performance on the test set when using GloVe-embeddings. The LSTM-approach takes a lot longer to train, and it is therefore harder to conduct a decent hyperparameter search. The LSTM is the only approach that takes the order of the words into account, which could potentially give a better performance if optimized well.\n",
    "\n",
    "For comparison, the table below displays state-of-the-art models for the IMDB classification task. \n",
    "\n",
    "| Model |\tAccuracy (%) |\tPaper / Source|\n",
    "|:----- | ---------- | -------------- |  \n",
    "| XLNet (Yang et al., 2019) |\t__96.21__ |\tXLNet: Generalized Autoregressive Pretraining for Language Understanding|\n",
    "| BERT_large+ITPT (Sun et al., 2019) \t|95.79 |\tHow to Fine-Tune BERT for Text Classification?|\n",
    "| BERT_base+ITPT (Sun et al., 2019) |\t95.63 |\tHow to Fine-Tune BERT for Text Classification?|\n",
    "| ULMFiT (Howard and Ruder, 2018) |\t95.4 |\tUniversal Language Model Fine-tuning for Text Classification|\n",
    "| Block-sparse LSTM (Gray et al., 2017) |\t94.99 |\tGPU Kernels for Block-Sparse Weights|\n",
    "| oh-LSTM (Johnson and Zhang, 2016)| \t94.1| \tSupervised and Semi-Supervised Text Categorization using LSTM for Region Embeddings |\n",
    "| Virtual adversarial training (Miyato et al., 2016) |\t94.1 \t|Adversarial Training Methods for Semi-Supervised Text Classification |\n",
    "| BCN+Char+CoVe (McCann et al., 2017) |\t91.8 |\tLearned in Translation: Contextualized Word Vectors |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
