{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.read_pickle(r\"./Datasets/data/financial_headlines_20061020-20131119.pkl\")\n",
    "df = pd.DataFrame(news_data)\n",
    "df.set_index('date',inplace=True)\n",
    "financial_data = pd.read_pickle(r\"./Datasets/data/stock_data.pkl\")\n",
    "oneyearrate = financial_data['1 YEAR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2010,1,1)\n",
    "end_date = datetime(2012,1,1)\n",
    "titles = df.loc[start_date.strftime(\"%Y-%m-%d\") : end_date.strftime(\"%Y-%m-%d\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_news(news,period):\n",
    "    \"\"\"Merges news headlines over a period of days as one single list of words,\n",
    "    tokenized by word_tokenize() in nltk. \n",
    "    \n",
    "    Parameters: \n",
    "    news (DataFrame): News data of headlines (str) indexed by datetime.   \n",
    "    period (int): Number of days in each period. \n",
    "    \n",
    "    Returns: \n",
    "    DataFrame of lists of words indexed by datetime.\n",
    "    \"\"\"\n",
    "    delta = timedelta(days=period)\n",
    "    t1 = news.index[0]\n",
    "    t2 = t1 + delta\n",
    "    end_date = news.index[-1]\n",
    "    data = pd.DataFrame({'titles': [], 'date': []})\n",
    "    while(t2 < end_date):\n",
    "        period_words = []\n",
    "        titles = list([word_tokenize(title) for title in news.loc[t1.strftime(\"%Y-%m-%d\") : t2.strftime(\"%Y-%m-%d\")]['title']])\n",
    "        for title in titles: \n",
    "            for word in title: \n",
    "                period_words.append(word)\n",
    "        data = data.append({'date': t1, 'titles': period_words},ignore_index=True)\n",
    "        t1 = t2\n",
    "        t2 = t2 + delta    \n",
    "    titles = list([word_tokenize(t) for t in news.loc[t1.strftime(\"%Y-%m-%d\") : end_date.strftime(\"%Y-%m-%d\")]['title']])\n",
    "    for title in titles: \n",
    "            for word in title: \n",
    "                period_words.append(word)\n",
    "    data = data.append({'date': t1, 'titles': period_words},ignore_index=True)\n",
    "    data.set_index('date',inplace=True)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conc = concat_news(titles,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Använda för att göra tf ifd tokenizing? \n",
    "# keras.preprocessing.text.Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
