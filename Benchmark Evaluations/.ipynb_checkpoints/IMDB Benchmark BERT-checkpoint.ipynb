{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tqdm import trange\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONEDRIVE_PATH = Path(r\"C:\\Users\\gusta\\Kidbrooke Advisory Ab\\KidbrookeOneDrive - Gustaf Backman exjobb\")\n",
    "\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_path = ONEDRIVE_PATH / 'Benchmark Datasets/IMDB Dataset.csv'\n",
    "imdb = pd.read_csv(imdb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "bert_module =  hub.Module(bert_path)\n",
    "tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                      tokenization_info[\"do_lower_case\"],])\n",
    "tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 50000/50000 [02:50<00:00, 292.70it/s]\n"
     ]
    }
   ],
   "source": [
    "max_length = 512\n",
    "\n",
    "# Remove line breaks (<br />) and tokenize\n",
    "x = np.zeros((len(imdb), max_length))\n",
    "input_ids = np.zeros((len(imdb),max_length))\n",
    "input_masks = np.zeros((len(imdb),max_length))\n",
    "segment_ids = np.zeros((len(imdb),max_length))\n",
    "\n",
    "for i in trange(len(imdb)):\n",
    "    text = imdb.iloc[i]['review'].replace('<br />', ' ').lower()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if len(tokens) > max_length - 2:\n",
    "        tokens = tokens[:max_length - 2]\n",
    "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    if len(token_ids) > max_length:\n",
    "        token_ids = token_ids[:max_length]\n",
    "        mask = [1] * max_length\n",
    "    else: \n",
    "        mask = [1] * len(token_ids) + [0] * (max_length - len(token_ids))\n",
    "        token_ids = token_ids + [0] * (max_length - len(token_ids))\n",
    "    \n",
    "    current_segment_id = 0\n",
    "    segments = []\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == '[SEP]':\n",
    "            current_segment_id = 1\n",
    "    while len(segments) < max_length: \n",
    "        segments.append(0)\n",
    "    assert len(token_ids) == max_length, \"Wrong length of ids\"\n",
    "    assert len(segments) == max_length, \"Wrong length of segments.\"\n",
    "    assert len(mask) == max_length, \"Wrong length of masks.\"\n",
    "    \n",
    "    input_ids[i] = np.asarray(token_ids)\n",
    "    segment_ids[i] = segments\n",
    "    input_masks[i] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 50000/50000 [02:53<00:00, 287.92it/s]\n"
     ]
    }
   ],
   "source": [
    "compare_ids = np.zeros((len(imdb), max_length))\n",
    "compare_mask = np.zeros((len(imdb), max_length))\n",
    "compare_seg = np.zeros((len(imdb), max_length))\n",
    "for i in trange(len(imdb)): \n",
    "    text = imdb.iloc[i]['review'].replace('<br />', ' ').lower()\n",
    "    compare_ids[i], compare_mask[i], compare_seg[i] = convert_single_example(tokenizer, text, max_length)\n",
    "    if not np.all(compare_ids[i] == input_ids[i]):\n",
    "        print(\"ids at {} doesn't match.\".format(i))\n",
    "    if not np.all(compare_mask[i] == input_masks[i]):\n",
    "        print(\"mask at {} doesn't match.\".format(i))\n",
    "    if not np.all(compare_seg[i] == segment_ids[i]):\n",
    "        print(\"segment at {} doesn't match.\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 50000/50000 [00:04<00:00, 11925.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assign labels to variables for convenience\n",
    "y = np.zeros((50000))\n",
    "for i in trange(len(y)): \n",
    "    if imdb.iloc[i]['sentiment'] == 'positive':\n",
    "        y[i] = 1\n",
    "\n",
    "train_ids = input_ids[:20000]\n",
    "train_seg = segment_ids[:20000]\n",
    "train_mask = input_masks[:20000]\n",
    "\n",
    "val_ids = input_ids[20000:25000]\n",
    "val_seg = segment_ids[20000:25000]\n",
    "val_mask = input_masks[20000:25000]\n",
    "\n",
    "test_ids = input_ids[25000:]\n",
    "test_seg = segment_ids[25000:]\n",
    "test_mask = input_masks[25000:]\n",
    "\n",
    "y_train = y[:20000]\n",
    "y_val = y[20000:25000]\n",
    "y_test = y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_id (InputLayer)           [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segment (InputLayer)      [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_2 (BertLayer)        (None, 768)          110104890   input_id[0][0]                   \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 input_segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          196864      bert_layer_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            257         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 14,963,457\n",
      "Non-trainable params: 95,338,554\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "in_ids = keras.layers.Input(shape=(max_length,), dtype=tf.int32,name='input_id')\n",
    "in_mask = keras.layers.Input(shape=(max_length,),dtype=tf.int32,name='input_mask')\n",
    "in_seg = keras.layers.Input(shape=(max_length,),dtype=tf.int32, name='input_segment')\n",
    "\n",
    "bert_inputs = [in_ids, in_mask, in_seg]\n",
    "bert_output = BertLayer(n_fine_tune_layers=2,pooling='first')(bert_inputs)\n",
    "\n",
    "dense_layer = keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "dropout_layer = keras.layers.Dropout(0.1)(dense_layer)\n",
    "\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "model = keras.models.Model(inputs=bert_inputs, outputs=output_layer)\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate=2e-5)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.local_variables_initializer())\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())\n",
    "K.set_session(sess)\n",
    "\n",
    "# Dictionary for storing stats\n",
    "history = {'loss': [],\n",
    "          'acc': [],\n",
    "          'val_loss': [],\n",
    "          'val_acc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "20000/20000 [==============================] - 30884s 2s/sample - loss: 0.1874 - acc: 0.9284 - val_loss: 0.2218 - val_acc: 0.9154\n"
     ]
    }
   ],
   "source": [
    "temp_hist = model.fit([train_ids, train_mask, train_seg], y_train,\n",
    "                      validation_data=([val_ids, val_mask, val_seg], y_val), \n",
    "                      epochs=1,                                                                                                                   \n",
    "                      batch_size=32)\n",
    "\n",
    "for metric in history: \n",
    "    history[metric].append(temp_hist.history[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('050520_3epoch_2trlay.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history['val_loss'],label='val_loss')\n",
    "plt.plot(history['loss'],label='loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = model.predict([test_ids[:10], test_mask[:10], test_seg[:10]])\n",
    "pr2 = m.predict([test_ids[:10], test_mask[:10], test_seg[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_weights('Model Weights/050520_1epoch_2trlay.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_id (InputLayer)           [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_segment (InputLayer)      [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_3 (BertLayer)        (None, 768)          110104890   input_id[0][0]                   \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 input_segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          196864      bert_layer_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            257         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 14,963,457\n",
      "Non-trainable params: 95,338,554\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "in_ids = keras.layers.Input(shape=(max_length,), dtype=tf.int32,name='input_id')\n",
    "in_mask = keras.layers.Input(shape=(max_length,),dtype=tf.int32,name='input_mask')\n",
    "in_seg = keras.layers.Input(shape=(max_length,),dtype=tf.int32, name='input_segment')\n",
    "\n",
    "bert_inputs = [in_ids, in_mask, in_seg]\n",
    "bert_output = BertLayer(n_fine_tune_layers=2,pooling='first')(bert_inputs)\n",
    "\n",
    "dense_layer = keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "dropout_layer = keras.layers.Dropout(0.1)(dense_layer)\n",
    "\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "m = keras.models.Model(inputs=bert_inputs, outputs=output_layer)\n",
    "\n",
    "adam = keras.optimizers.Adam(learning_rate=2e-5)\n",
    "m.compile(loss='binary_crossentropy', optimizer=adam, metrics=['acc'])\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Layers with arguments in `__init__` must override `get_config`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f01edf396d9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'050520_1epoch_2trlay.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \"\"\"\n\u001b[0;32m   1170\u001b[0m     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1171\u001b[1;33m                       signatures)\n\u001b[0m\u001b[0;32m   1172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures)\u001b[0m\n\u001b[0;32m    107\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m    108\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[1;32m--> 109\u001b[1;33m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[0;32m    110\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[0mmodel_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[1;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[0;32m    158\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m   metadata = dict(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[1;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[0;32m    155\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class_name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m     \u001b[0mmodel_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mget_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# From the earliest layers on.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m       \u001b[0mlayer_class_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 886\u001b[1;33m       \u001b[0mlayer_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[0mfiltered_inbound_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\nlpenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mget_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[1;31m# or that `get_config` has been overridden:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_is_default'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       raise NotImplementedError('Layers with arguments in `__init__` must '\n\u001b[0m\u001b[0;32m    581\u001b[0m                                 'override `get_config`.')\n\u001b[0;32m    582\u001b[0m     \u001b[1;31m# TODO(reedwm): Handle serializing self._dtype_policy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Layers with arguments in `__init__` must override `get_config`."
     ]
    }
   ],
   "source": [
    "model.save('050520_1epoch_2trlay.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
